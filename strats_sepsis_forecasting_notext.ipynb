{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "XXs5pMOVDxPw",
    "outputId": "774cca6e-6f38-4e4a-ee73-dfd004340c62",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf. __version__)\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "# from tensorflow.keras import models\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#from google.colab import files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "#import smart_cond as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/mimic_notext.pkl\", \"rb\") as pfile:\n",
    "    raw_data = pickle.load(pfile)\n",
    "mimic = raw_data[0]\n",
    "meta = raw_data[1]\n",
    "train_ind = raw_data[2]\n",
    "valid_ind = raw_data[3]\n",
    "test_ind = raw_data[4]\n",
    "data = mimic\n",
    "oc = meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = oc['SUBJECT_ID'].tolist()\n",
    "labels = oc['in_hospital_sepsis'].tolist()\n",
    "\n",
    "new_patient_ids = []\n",
    "new_labels = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "  # print(i)\n",
    "  if ids[i] in new_patient_ids:\n",
    "    continue\n",
    "  else:\n",
    "    new_patient_ids.append(ids[i])\n",
    "    new_labels.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23587\n",
      "31708\n",
      "7371\n",
      "9894\n",
      "5897\n",
      "7803\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, x_test, y, y_test = train_test_split(new_patient_ids, new_labels, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "# train\n",
    "train_ind = []\n",
    "\n",
    "ts_ind = oc['ts_ind'].tolist()\n",
    "# ids = ids\n",
    "\n",
    "for i in range(len(ts_ind)):\n",
    "  if ids[i] in x_train:\n",
    "    train_ind.append(ts_ind[i])\n",
    "\n",
    "# number of train patients\n",
    "print(len(x_train))\n",
    "# number of train instances\n",
    "print(len(train_ind))\n",
    "# to np.array\n",
    "train_ind = np.array(train_ind)\n",
    "\n",
    "test_ind = []\n",
    "\n",
    "for i in range(len(ts_ind)):\n",
    "  if ids[i] in x_test:\n",
    "    test_ind.append(ts_ind[i])\n",
    "\n",
    "# number of test patients\n",
    "print(len(x_test))\n",
    "# number of test instances\n",
    "print(len(test_ind))\n",
    "# to np.array\n",
    "test_ind = np.array(test_ind)\n",
    "\n",
    "valid_ind = []\n",
    "\n",
    "for i in range(len(ts_ind)):\n",
    "  if ids[i] in x_val:\n",
    "    valid_ind.append(ts_ind[i])\n",
    "\n",
    "# number of test patients\n",
    "print(len(x_val))\n",
    "# number of test instances\n",
    "print(len(valid_ind))\n",
    "# to np.array\n",
    "valid_ind = np.array(valid_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# # Read data.\\n# data_path = './../mimic_iii_preprocessed.pkl'\\n# data, oc, train_ind, valid_ind, test_ind = pickle.load(open(data_path, 'rb'))\\n# Filter labeled data in first 24h.\\ndata = data.loc[data.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\\ndata = data.loc[(data.hour>=0)&(data.hour<=24)]\\noc = oc.loc[oc.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\\n# Fix age.\\ndata.loc[(data.variable=='o:age')&(data.value>200), 'value'] = 91.4\\n# Get y and N.\\ny = np.array(oc.sort_values(by='ts_ind')['sepsis_label']).astype('float32')\\nN = data.ts_ind.max() + 1\\n# Get static data with mean fill and missingness indicator.\\nstatic_varis = ['o:age', 'o:gender']\\nii = data.variable.isin(static_varis)\\nstatic_data = data.loc[ii]\\ndata = data.loc[~ii]\\ndef inv_list(l, start=0):\\n    d = {}\\n    for i in range(len(l)):\\n        d[l[i]] = i+start\\n    return d\\nstatic_var_to_ind = inv_list(static_varis)\\nD = len(static_varis)\\ndemo = np.zeros((N, D))\\nfor row in tqdm(static_data.itertuples()):\\n    demo[row.ts_ind, static_var_to_ind[row.variable]] = row.value\\n# Normalize static data.\\nmeans = demo.mean(axis=0, keepdims=True)\\nstds = demo.std(axis=0, keepdims=True)\\nstds = (stds==0)*1 + (stds!=0)*stds\\ndemo = (demo-means)/stds\\n# Trim to max len.\\n#data = data.sample(frac=1)\\ndata = data.groupby('ts_ind').head(880)\\n# Get N, V, var_to_ind.\\nN = data.ts_ind.max() + 1\\nvaris = sorted(list(set(data.variable)))\\nV = len(varis)\\ndef inv_list(l, start=0):\\n    d = {}\\n    for i in range(len(l)):\\n        d[l[i]] = i+start\\n    return d\\nvar_to_ind = inv_list(varis, start=1)\\ndata['vind'] = data.variable.map(var_to_ind)\\ndata = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\\n# Add obs index.\\ndata = data.sort_values(by=['ts_ind']).reset_index(drop=True)\\ndata = data.reset_index().rename(columns={'index':'obs_ind'})\\ndata = data.merge(data.groupby('ts_ind').agg({'obs_ind':'min'}).reset_index().rename(columns={                                                             'obs_ind':'first_obs_ind'}), on='ts_ind')\\ndata['obs_ind'] = data['obs_ind'] - data['first_obs_ind']\\n# Find max_len.\\nmax_len = data.obs_ind.max()+1\\nprint ('max_len', max_len)\\n# Generate times_ip and values_ip matrices.\\ntimes_inp = np.zeros((N, max_len), dtype='float32')\\nvalues_inp = np.zeros((N, max_len), dtype='float32')\\nvaris_inp = np.zeros((N, max_len), dtype='int32')\\nfor row in tqdm(data.itertuples()):\\n    ts_ind = row.ts_ind\\n    l = row.obs_ind\\n    times_inp[ts_ind, l] = row.hour\\n    values_inp[ts_ind, l] = row.value\\n    varis_inp[ts_ind, l] = row.vind\\ndata.drop(columns=['obs_ind', 'first_obs_ind'], inplace=True)\\n# Generate 3 sets of inputs and outputs.\\ntrain_ip = [ip[train_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\\nvalid_ip = [ip[valid_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\\ntest_ip = [ip[test_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\\ndel times_inp, values_inp, varis_inp\\ntrain_op = y[train_ind]\\nvalid_op = y[valid_ind]\\ntest_op = y[test_ind]\\ndel y\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dont need data preperation for classification task\n",
    "\"\"\"\n",
    "# # Read data.\n",
    "# data_path = './../mimic_iii_preprocessed.pkl'\n",
    "# data, oc, train_ind, valid_ind, test_ind = pickle.load(open(data_path, 'rb'))\n",
    "# Filter labeled data in first 24h.\n",
    "data = data.loc[data.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "data = data.loc[(data.hour>=0)&(data.hour<=24)]\n",
    "oc = oc.loc[oc.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "# Fix age.\n",
    "data.loc[(data.variable=='o:age')&(data.value>200), 'value'] = 91.4\n",
    "# Get y and N.\n",
    "y = np.array(oc.sort_values(by='ts_ind')['sepsis_label']).astype('float32')\n",
    "N = data.ts_ind.max() + 1\n",
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['o:age', 'o:gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "demo = np.zeros((N, D))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[row.ts_ind, static_var_to_ind[row.variable]] = row.value\n",
    "# Normalize static data.\n",
    "means = demo.mean(axis=0, keepdims=True)\n",
    "stds = demo.std(axis=0, keepdims=True)\n",
    "stds = (stds==0)*1 + (stds!=0)*stds\n",
    "demo = (demo-means)/stds\n",
    "# Trim to max len.\n",
    "#data = data.sample(frac=1)\n",
    "data = data.groupby('ts_ind').head(880)\n",
    "# Get N, V, var_to_ind.\n",
    "N = data.ts_ind.max() + 1\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Add obs index.\n",
    "data = data.sort_values(by=['ts_ind']).reset_index(drop=True)\n",
    "data = data.reset_index().rename(columns={'index':'obs_ind'})\n",
    "data = data.merge(data.groupby('ts_ind').agg({'obs_ind':'min'}).reset_index().rename(columns={ \\\n",
    "                                                            'obs_ind':'first_obs_ind'}), on='ts_ind')\n",
    "data['obs_ind'] = data['obs_ind'] - data['first_obs_ind']\n",
    "# Find max_len.\n",
    "max_len = data.obs_ind.max()+1\n",
    "print ('max_len', max_len)\n",
    "# Generate times_ip and values_ip matrices.\n",
    "times_inp = np.zeros((N, max_len), dtype='float32')\n",
    "values_inp = np.zeros((N, max_len), dtype='float32')\n",
    "varis_inp = np.zeros((N, max_len), dtype='int32')\n",
    "for row in tqdm(data.itertuples()):\n",
    "    ts_ind = row.ts_ind\n",
    "    l = row.obs_ind\n",
    "    times_inp[ts_ind, l] = row.hour\n",
    "    values_inp[ts_ind, l] = row.value\n",
    "    varis_inp[ts_ind, l] = row.vind\n",
    "data.drop(columns=['obs_ind', 'first_obs_ind'], inplace=True)\n",
    "# Generate 3 sets of inputs and outputs.\n",
    "train_ip = [ip[train_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "valid_ip = [ip[valid_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "test_ip = [ip[test_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "del times_inp, values_inp, varis_inp\n",
    "train_op = y[train_ind]\n",
    "valid_op = y[valid_ind]\n",
    "test_op = y[test_ind]\n",
    "del y\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "C8VrWUiiwBBy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "mape = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "def get_res(y_true, y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    minrp = np.minimum(precision, recall).max()\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    return [roc_auc, pr_auc, minrp]\n",
    "\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "#class_weights = compute_class_weight(class_weight='balanced', classes=[0,1], y=train_op)\n",
    "def mortality_loss(y_true, y_pred):\n",
    "    sample_weights = (1-y_true)*class_weights[0] + y_true*class_weights[1]\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "    return K.mean(sample_weights*bce, axis=-1)\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "# var_weights = np.sum(fore_train_op[:, V:], axis=0)\n",
    "# var_weights[var_weights==0] = var_weights.max()\n",
    "# var_weights = var_weights.max()/var_weights\n",
    "# var_weights = var_weights.reshape((1, V))\n",
    "def forecast_loss(y_true, y_pred):\n",
    "    return K.sum(y_true[:,V:]*(y_true[:,:V]-y_pred)**2, axis=-1)\n",
    "\n",
    "def mape_fore(y_true, y_pred):\n",
    "    truth = y_true[:,V:]\n",
    "    pred = y_pred\n",
    "    return mape(truth, pred)\n",
    "\n",
    "                                          \n",
    "def get_min_loss(weight):\n",
    "    def min_loss(y_true, y_pred):\n",
    "        return weight*y_pred\n",
    "    return min_loss\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def __init__(self, validation_data, batch_size):\n",
    "        self.val_x, self.val_y = validation_data\n",
    "        self.batch_size = batch_size\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.val_x, verbose=0, batch_size=self.batch_size)\n",
    "        if type(y_pred)==type([]):\n",
    "            y_pred = y_pred[0]\n",
    "        precision, recall, thresholds = precision_recall_curve(self.val_y, y_pred)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        roc_auc = roc_auc_score(self.val_y, y_pred)\n",
    "        logs['custom_metric'] = pr_auc + roc_auc\n",
    "        print ('val_aucs:', pr_auc, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "isIVij5VwFhk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Embedding, Activation, Dropout, Softmax, Layer, InputSpec, Input, Dense, Lambda, TimeDistributed, Concatenate, Add\n",
    "from tensorflow.keras import initializers, regularizers, constraints, Model\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow import nn\n",
    "import smart_cond_mod as sc\n",
    "\n",
    "\n",
    "class CVE(Layer):\n",
    "    def __init__(self, hid_units, output_dim):\n",
    "        self.hid_units = hid_units\n",
    "        self.output_dim = output_dim\n",
    "        super(CVE, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W1 = self.add_weight(name='CVE_W1',\n",
    "                            shape=(1, self.hid_units),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        self.b1 = self.add_weight(name='CVE_b1',\n",
    "                            shape=(self.hid_units,),\n",
    "                            initializer='zeros',\n",
    "                            trainable=True)\n",
    "        self.W2 = self.add_weight(name='CVE_W2',\n",
    "                            shape=(self.hid_units, self.output_dim),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        super(CVE, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = K.expand_dims(x, axis=-1)\n",
    "        x = K.dot(K.tanh(K.bias_add(K.dot(x, self.W1), self.b1)), self.W2)\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape + (self.output_dim,)\n",
    "\n",
    "\n",
    "class Attention(Layer):\n",
    "\n",
    "    def __init__(self, hid_dim):\n",
    "        self.hid_dim = hid_dim\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        self.W = self.add_weight(shape=(d, self.hid_dim), name='Att_W',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hid_dim,), name='Att_b',\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        self.u = self.add_weight(shape=(self.hid_dim,1), name='Att_u',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask, mask_value=-1e30):\n",
    "        attn_weights = K.dot(K.tanh(K.bias_add(K.dot(x,self.W), self.b)), self.u)\n",
    "        mask = K.expand_dims(mask, axis=-1)\n",
    "        attn_weights = mask*attn_weights + (1-mask)*mask_value\n",
    "        attn_weights = K.softmax(attn_weights, axis=-2)\n",
    "        return attn_weights\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1] + (1,)\n",
    "\n",
    "\n",
    "class Transformer(Layer):\n",
    "\n",
    "    def __init__(self, N=2, h=8, dk=None, dv=None, dff=None, dropout=0):\n",
    "        self.N, self.h, self.dk, self.dv, self.dff, self.dropout = N, h, dk, dv, dff, dropout\n",
    "        self.epsilon = K.epsilon() * K.epsilon()\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        if self.dk==None:\n",
    "            self.dk = d//self.h\n",
    "        if self.dv==None:\n",
    "            self.dv = d//self.h\n",
    "        if self.dff==None:\n",
    "            self.dff = 2*d\n",
    "        self.Wq = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wq',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wk = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wk',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wv = self.add_weight(shape=(self.N, self.h, d, self.dv), name='Wv',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wo = self.add_weight(shape=(self.N, self.dv*self.h, d), name='Wo',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.W1 = self.add_weight(shape=(self.N, d, self.dff), name='W1',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b1 = self.add_weight(shape=(self.N, self.dff), name='b1',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.W2 = self.add_weight(shape=(self.N, self.dff, d), name='W2',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b2 = self.add_weight(shape=(self.N, d), name='b2',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.gamma = self.add_weight(shape=(2*self.N,), name='gamma',\n",
    "                                 initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(shape=(2*self.N,), name='beta',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        super(Transformer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask, mask_value=-1e-30):\n",
    "        mask = K.expand_dims(mask, axis=-2)\n",
    "        for i in range(self.N):\n",
    "            # MHA\n",
    "            mha_ops = []\n",
    "            for j in range(self.h):\n",
    "                q = K.dot(x, self.Wq[i,j,:,:])\n",
    "                k = K.permute_dimensions(K.dot(x, self.Wk[i,j,:,:]), (0,2,1))\n",
    "                v = K.dot(x, self.Wv[i,j,:,:])\n",
    "                A = K.batch_dot(q,k)\n",
    "                # Mask unobserved steps.\n",
    "                A = mask*A + (1-mask)*mask_value\n",
    "                # Mask for attention dropout.\n",
    "                def dropped_A():\n",
    "                    dp_mask = K.cast((K.random_uniform(shape=array_ops.shape(A))>=self.dropout), K.floatx())\n",
    "                    return A*dp_mask + (1-dp_mask)*mask_value\n",
    "                A = sc.smart_cond(K.learning_phase(), dropped_A, lambda: array_ops.identity(A))\n",
    "                A = K.softmax(A, axis=-1)\n",
    "                mha_ops.append(K.batch_dot(A,v))\n",
    "            conc = K.concatenate(mha_ops, axis=-1)\n",
    "            proj = K.dot(conc, self.Wo[i,:,:])\n",
    "            # Dropout.\n",
    "            proj = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(proj, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(proj))\n",
    "            # Add & LN\n",
    "            x = x+proj\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i] + self.beta[2*i]\n",
    "            # FFN\n",
    "            ffn_op = K.bias_add(K.dot(K.relu(K.bias_add(K.dot(x, self.W1[i,:,:]), self.b1[i,:])),\n",
    "                           self.W2[i,:,:]), self.b2[i,:,])\n",
    "            # Dropout.\n",
    "            ffn_op = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(ffn_op, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(ffn_op))\n",
    "            # Add & LN\n",
    "            x = x+ffn_op\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i+1] + self.beta[2*i+1]\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "def build_strats(D, max_len, V, d, N, he, dropout, forecast=False):\n",
    "    demo = Input(shape=(D,))\n",
    "    demo_enc = Dense(2*d, activation='tanh')(demo)\n",
    "    demo_enc = Dense(d, activation='tanh')(demo_enc)\n",
    "    varis = Input(shape=(max_len,))\n",
    "    values = Input(shape=(max_len,))\n",
    "    times = Input(shape=(max_len,))\n",
    "    varis_emb = Embedding(V+1, d)(varis)\n",
    "    cve_units = int(np.sqrt(d))\n",
    "    values_emb = CVE(cve_units, d)(values)\n",
    "    times_emb = CVE(cve_units, d)(times)\n",
    "    comb_emb = Add()([varis_emb, values_emb, times_emb]) # b, L, d\n",
    "#     demo_enc = Lambda(lambda x:K.expand_dims(x, axis=-2))(demo_enc) # b, 1, d\n",
    "#     comb_emb = Concatenate(axis=-2)([demo_enc, comb_emb]) # b, L+1, d\n",
    "    mask = Lambda(lambda x:K.clip(x,0,1))(varis) # b, L\n",
    "#     mask = Lambda(lambda x:K.concatenate((K.ones_like(x)[:,0:1], x), axis=-1))(mask) # b, L+1\n",
    "    cont_emb = Transformer(N, he, dk=None, dv=None, dff=None, dropout=dropout)(comb_emb, mask=mask)\n",
    "    attn_weights = Attention(2*d)(cont_emb, mask=mask)\n",
    "    fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([cont_emb, attn_weights])\n",
    "    conc = Concatenate(axis=-1)([fused_emb, demo_enc])\n",
    "    fore_op = Dense(V)(conc)\n",
    "    op = Dense(1, activation='sigmoid')(fore_op)\n",
    "    model = Model([demo, times, values, varis], op)\n",
    "    if forecast:\n",
    "        fore_model = Model([demo, times, values, varis], fore_op)\n",
    "        return [model, fore_model]\n",
    "    return model\n",
    "\n",
    "# To tune:\n",
    "# 1. Transformer parameters. (N, h, dropout)\n",
    "# 2. Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbYsD4V556kT"
   },
   "source": [
    "## get forecast on test patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sfu0I5Q4ECl-"
   },
   "source": [
    "### Load test data into matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_hours = 4\n",
    "pred_window = 2 # hours that the output vector represents. 1 because i want to learn to predict 1 hour many times, 2 to test standard strats config\n",
    "obs_windows = [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKK7sW-455hs",
    "outputId": "c637236a-199d-4e54-90e5-2d38698a359d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 107546.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# take test patients.\n",
    "data = data.merge(oc[['ts_ind', 'SUBJECT_ID']], on='ts_ind', how='left')\n",
    "test_sub = oc.loc[oc.ts_ind.isin(test_ind[:10])].SUBJECT_ID.unique()\n",
    "data = data.loc[data.SUBJECT_ID.isin(test_sub[:10])]\n",
    "oc = oc.loc[oc.SUBJECT_ID.isin(test_sub[:10])]\n",
    "data.drop(columns=['SUBJECT_ID'], inplace=True)\n",
    "# Fix age.\n",
    "data.loc[(data.variable=='Age')&(data.value>200), 'value'] = 91.4\n",
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['Age', 'Gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "N = data.ts_ind.max()+1\n",
    "demo = np.zeros((N, D))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[row.ts_ind, static_var_to_ind[row.variable]] = row.value\n",
    "# Normalize static data.\n",
    "means = demo.mean(axis=0, keepdims=True)\n",
    "stds = demo.std(axis=0, keepdims=True)\n",
    "stds = (stds==0)*1 + (stds!=0)*stds\n",
    "demo = (demo-means)/stds\n",
    "\n",
    "# Get variable indices.\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Find max_len.\n",
    "fore_max_len = 880\n",
    "# Get forecast inputs and outputs.\n",
    "fore_times_ip = []\n",
    "fore_values_ip = []\n",
    "fore_varis_ip = []\n",
    "fore_op = []\n",
    "fore_inds = []\n",
    "def f(x):\n",
    "    mask = [0 for i in range(V)]\n",
    "    values = [0 for i in range(V)]\n",
    "    for vv in x:\n",
    "        v = int(vv[0])-1\n",
    "        mask[v] = 1\n",
    "        values[v] = vv[1]\n",
    "    return values+mask\n",
    "def pad(x):\n",
    "    return x+[0]*(V+V*forecast_hours-len(x))\n",
    "\n",
    "for w in tqdm(obs_windows):\n",
    "    pred_data = data.loc[(data.hour>=w)&(data.hour<=w+pred_window)]\n",
    "    pred_data = pred_data.groupby(['ts_ind', 'vind']).agg({'value':'first'}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data[['vind', 'value']].values.tolist()\n",
    "    pred_data = pred_data.groupby('ts_ind').agg({'vind_value':list}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data['vind_value'].apply(f)\n",
    "    obs_data = data.loc[(data.hour<w)&(data.hour>=w-24)]\n",
    "    obs_data = obs_data.loc[obs_data.ts_ind.isin(pred_data.ts_ind)]\n",
    "    obs_data = obs_data.groupby('ts_ind').head(fore_max_len)\n",
    "    obs_data = obs_data.groupby('ts_ind').agg({'vind':list, 'hour':list, 'value':list}).reset_index()\n",
    "    obs_data = obs_data.merge(pred_data, on='ts_ind')\n",
    "    for col in ['vind', 'hour', 'value']:\n",
    "        obs_data[col] = obs_data[col].apply(pad)\n",
    "    fore_op.append(np.array(list(obs_data.vind_value)))\n",
    "    fore_inds.append(np.array(list(obs_data.ts_ind)))\n",
    "    fore_times_ip.append(np.array(list(obs_data.hour)))\n",
    "    fore_values_ip.append(np.array(list(obs_data.value)))\n",
    "    fore_varis_ip.append(np.array(list(obs_data.vind)))\n",
    "\n",
    "del data\n",
    "fore_times_ip = np.concatenate(fore_times_ip, axis=0)\n",
    "fore_values_ip = np.concatenate(fore_values_ip, axis=0)\n",
    "fore_varis_ip = np.concatenate(fore_varis_ip, axis=0)\n",
    "fore_op = np.concatenate(fore_op, axis=0)\n",
    "fore_inds = np.concatenate(fore_inds, axis=0)\n",
    "fore_demo = demo[fore_inds]\n",
    "\n",
    "fore_test_ip = [fore_demo, fore_times_ip, fore_values_ip, fore_varis_ip]\n",
    "fore_test_op = fore_op\n",
    "\n",
    "# release RAM\n",
    "del fore_times_ip, fore_values_ip, fore_varis_ip, demo, fore_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415 [ 6  8 11 17 18 19 21 22 22 22 22 22 22 23 23 23 28 28 29 29 30 30 33 34\n",
      " 35 35 35 35 35 35 37 39 47 47 47 47 47 47 48 49 50 51 57 57 57 57 57 57\n",
      " 64 65 66 69 70 71 71 71 71 72 72 72 72 72 72 74 77 77 77 79 79 80 81  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0] 10\n"
     ]
    }
   ],
   "source": [
    "x = fore_test_ip[3]\n",
    "print(len(x[0]),x[0], len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def repeat_prediction(first_input, y_preds, relative_time, max_seq_len, len_vari=V):\n",
    "    \n",
    "    # build new input with prediction added as \"newest data\"\n",
    "    # take highest \"time\" and add number of forecasting steps -> time of new forecast\n",
    "    preds_time = (first_input[1].max(axis=1, keepdims=True))+relative_time\n",
    "    #print(\"predstime\", preds_time)\n",
    "    # all features are predicted at that same \"new\" time\n",
    "    preds_time = np.repeat(preds_time, len_vari, axis=1)\n",
    "    #print(\"predstime\", preds_time)\n",
    "    # each variable is predicted\n",
    "    preds_varid = np.linspace(1, len_vari, num=V)\n",
    "    #print(\"varid\", preds_varid)\n",
    "    # repeat for each time already predicted\n",
    "    preds_varid = np.tile(preds_varid, (len(preds_time), 1))\n",
    "    #print(\"varid\", preds_varid)\n",
    "    # take the original demographics, as it does not change\n",
    "    preds_demo = first_input[0]\n",
    "    new_data = [preds_demo, preds_time, y_preds, preds_varid]\n",
    "    \n",
    "    \n",
    "    new_fore_ip = [first_input[0]]\n",
    "    if relative_time == 0:\n",
    "        for i in range(1,4):\n",
    "            new_fore_ip.append(np.append(first_input[i][:,:len_vari], new_data[i], axis=1)) #only take existing values w/o padding and combine with prediction\n",
    "        print(len(new_fore_ip[1][0]))\n",
    "    else:\n",
    "        for i in range(1,4):\n",
    "            new_fore_ip.append(np.append(first_input[i][:,:len_vari*(relative_time+1)], new_data[i], axis=1)) #only take existing values w/o padding and combine with prediction\n",
    "        print(len(new_fore_ip[1][0]))\n",
    "\n",
    "\n",
    "    f = np.zeros((len(new_fore_ip[1]),(max_seq_len-len(new_fore_ip[1][0])))) # padding\n",
    "    for i in range(1,4):\n",
    "        new_fore_ip[i] = np.append(new_fore_ip[i],f, axis=1) # add padding\n",
    "    \n",
    "    #return to predict again, this time with new data, containing previous predictions and so on\n",
    "    return new_fore_ip, new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovxJ-7-yEG0I"
   },
   "source": [
    "### get test `y_preds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for matplotlib purposes\n",
    "start_ip = fore_test_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = start_ip[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fore_test_ip = start_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvz1y8m--5HK",
    "outputId": "07ce8037-8437-4878-f361-87e502f5dcee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 415)]                0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 415)]                0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 415)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 415, 50)              4200      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " cve (CVE)                   (None, 415, 50)              364       ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " cve_1 (CVE)                 (None, 415, 50)              364       ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 415, 50)              0         ['embedding[0][0]',           \n",
      "                                                                     'cve[0][0]',                 \n",
      "                                                                     'cve_1[0][0]']               \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 415)                  0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " transformer (Transformer)   (None, 415, 50)              39508     ['add[0][0]',                 \n",
      "                                                                     'lambda[0][0]']              \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 415, 1)               5200      ['transformer[0][0]',         \n",
      "                                                                     'lambda[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 100)                  300       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)           (None, 50)                   0         ['transformer[0][0]',         \n",
      "                                                                     'attention[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 50)                   5050      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 100)                  0         ['lambda_1[0][0]',            \n",
      "                                                                     'dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 83)                   8383      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 63369 (247.54 KB)\n",
      "Trainable params: 63369 (247.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Initializing from scratch.\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "166\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "249\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "332\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nhours = []\\nmax_hours = []\\n# get hours\\nfor time in start_ip[1]:\\n  hour = max(time)\\n  max_hours.append(hour)\\n\\n  for obs_window in obs_windows:\\n    if hour < obs_window:\\n      hour = obs_window\\n      break\\n\\n  hours.append(hour)\\n\\n# get patient ids\\ntest_patient_ids = []\\ntest_sepsis_labels = []\\n\\n# sub_ids = oc['SUBJECT_ID'].tolist()\\n# ts_ind = oc['ts_ind'].tolist()\\n# sepsis = oc['in_hospital_sepsis'].tolist()\\n\\n# for ind in val_inds:\\n#    for i in range(len(sub_ids)):\\n#      if ts_ind[i] == ind:\\n#        val_sepsis_labels.append(sepsis[i])\\n#        val_patient_ids.append(sub_ids[i])\\n#        break\\n\\nfor ind in tqdm(fore_inds):\\n  test_sepsis_labels.append(np.unique(oc[oc['ts_ind']==ind]['in_hospital_sepsis']).item())\\n  test_patient_ids.append(np.unique(oc[oc['ts_ind']==ind]['SUBJECT_ID']).item())\\n\\ntest_data = pd.DataFrame(\\n    {'ts_ind': fore_inds,\\n     'obs_window': hours,\\n     'SUBJECT_ID': test_patient_ids,\\n     'sepsis_label': test_sepsis_labels,\\n     'forecasting_pred': pd.Series(predictions.tolist()),\\n     'forecasting_test_op': pd.Series(fore_op.tolist())\\n    })\\n\\n# dump to pkl\\npickle.dump([test_data, var_to_ind], open('STraTS_4-15_masked_transformer_4-24_forecast','wb'))\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fore_savepath = './STraTS_4-15_masked_data_transformer_testt'\n",
    "\n",
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 32, len(fore_test_op), 5\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "model, fore_model =  build_strats(D, V+(V*forecast_hours), V, d, N, he, dropout, forecast=True)\n",
    "print(fore_model.summary())\n",
    "# fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "lossfunction = forecast_loss\n",
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "fore_model.compile(loss=lossfunction, optimizer=opt)\n",
    "\n",
    "# initialize checkpoint manager\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=fore_model)\n",
    "manager = tf.train.CheckpointManager(ckpt, f'{fore_savepath}', max_to_keep=3)\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "\n",
    "# forecasting\n",
    "for i in range(0, forecast_hours):\n",
    "    # predict and save prediction\n",
    "    test_y_preds = fore_model.predict(fore_test_ip)\n",
    "\n",
    "    # during 1st run, initialize cumulated predictions\n",
    "    if i == 0:\n",
    "        predictions = test_y_preds\n",
    "        \n",
    "    # during following runs, concatenate predictions\n",
    "    else:\n",
    "        predictions = np.concatenate((predictions,test_y_preds), axis=1)\n",
    "        \n",
    "    # build new input consisting of original input + hourly predictions appended\n",
    "    fore_test_ip, n_data_ = repeat_prediction(fore_test_ip,test_y_preds, i, max_seq_len=V+(V*forecast_hours))  \n",
    "    \n",
    "    # add V to sequence length as it is the length of prediction, to keep track\n",
    "\n",
    "\"\"\"\n",
    "hours = []\n",
    "max_hours = []\n",
    "# get hours\n",
    "for time in start_ip[1]:\n",
    "  hour = max(time)\n",
    "  max_hours.append(hour)\n",
    "\n",
    "  for obs_window in obs_windows:\n",
    "    if hour < obs_window:\n",
    "      hour = obs_window\n",
    "      break\n",
    "\n",
    "  hours.append(hour)\n",
    "\n",
    "# get patient ids\n",
    "test_patient_ids = []\n",
    "test_sepsis_labels = []\n",
    "\n",
    "# sub_ids = oc['SUBJECT_ID'].tolist()\n",
    "# ts_ind = oc['ts_ind'].tolist()\n",
    "# sepsis = oc['in_hospital_sepsis'].tolist()\n",
    "\n",
    "# for ind in val_inds:\n",
    "#    for i in range(len(sub_ids)):\n",
    "#      if ts_ind[i] == ind:\n",
    "#        val_sepsis_labels.append(sepsis[i])\n",
    "#        val_patient_ids.append(sub_ids[i])\n",
    "#        break\n",
    "\n",
    "for ind in tqdm(fore_inds):\n",
    "  test_sepsis_labels.append(np.unique(oc[oc['ts_ind']==ind]['in_hospital_sepsis']).item())\n",
    "  test_patient_ids.append(np.unique(oc[oc['ts_ind']==ind]['SUBJECT_ID']).item())\n",
    "\n",
    "test_data = pd.DataFrame(\n",
    "    {'ts_ind': fore_inds,\n",
    "     'obs_window': hours,\n",
    "     'SUBJECT_ID': test_patient_ids,\n",
    "     'sepsis_label': test_sepsis_labels,\n",
    "     'forecasting_pred': pd.Series(predictions.tolist()),\n",
    "     'forecasting_test_op': pd.Series(fore_op.tolist())\n",
    "    })\n",
    "\n",
    "# dump to pkl\n",
    "pickle.dump([test_data, var_to_ind], open('STraTS_4-15_masked_transformer_4-24_forecast','wb'))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150   -0.530090\n",
      "151    1.575771\n",
      "152    0.858949\n",
      "153   -0.310377\n",
      "154    0.428438\n",
      "155   -1.133890\n",
      "156    0.864915\n",
      "157    0.661443\n",
      "158   -0.606896\n",
      "159    0.347655\n",
      "160    0.366879\n",
      "161   -0.426487\n",
      "162    0.000974\n",
      "163    0.140145\n",
      "164    1.115678\n",
      "165   -0.959354\n",
      "166   -0.044851\n",
      "167    0.060840\n",
      "168    0.682699\n",
      "169   -1.439977\n",
      "170   -0.308817\n",
      "171    0.140238\n",
      "172   -0.983397\n",
      "173   -0.519898\n",
      "174   -0.360838\n",
      "175   -0.086720\n",
      "176   -0.202925\n",
      "177   -1.100451\n",
      "178    0.866807\n",
      "179    0.132619\n",
      "180    1.706447\n",
      "181    0.021675\n",
      "182   -0.018953\n",
      "183   -0.226438\n",
      "184   -0.032558\n",
      "185   -0.474229\n",
      "186   -0.417515\n",
      "187   -0.727073\n",
      "188   -0.412518\n",
      "189   -0.626417\n",
      "190   -0.124638\n",
      "191   -0.408152\n",
      "192   -0.237336\n",
      "193    1.600364\n",
      "194    0.686340\n",
      "195   -1.135021\n",
      "196    0.510228\n",
      "197   -0.529614\n",
      "198   -0.279778\n",
      "199   -0.089563\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#[preds_demo, preds_time, y_preds, preds_varid]\n",
    "i = 2\n",
    "#h = fore_test_ip[i]\n",
    "#h = pd.DataFrame(h)\n",
    "#print(h.iloc[0][100:200])\n",
    "x = fore_test_ip[i]\n",
    "x = pd.DataFrame(x)\n",
    "print(x.iloc[0][150:200])\n",
    "#y = n_data_[i]\n",
    "#print(len(y[0]),y[0], len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2862</th>\n",
       "      <th>2863</th>\n",
       "      <th>2864</th>\n",
       "      <th>2865</th>\n",
       "      <th>2866</th>\n",
       "      <th>2867</th>\n",
       "      <th>2868</th>\n",
       "      <th>2869</th>\n",
       "      <th>2870</th>\n",
       "      <th>2871</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.334275</td>\n",
       "      <td>-0.512236</td>\n",
       "      <td>0.406903</td>\n",
       "      <td>-1.019767</td>\n",
       "      <td>1.256110</td>\n",
       "      <td>-0.676131</td>\n",
       "      <td>0.762475</td>\n",
       "      <td>0.861151</td>\n",
       "      <td>0.861151</td>\n",
       "      <td>0.519934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.327616</td>\n",
       "      <td>-0.299017</td>\n",
       "      <td>-0.266831</td>\n",
       "      <td>1.181628</td>\n",
       "      <td>0.584069</td>\n",
       "      <td>-0.551301</td>\n",
       "      <td>0.022152</td>\n",
       "      <td>-0.475407</td>\n",
       "      <td>0.052665</td>\n",
       "      <td>-0.286301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.325079</td>\n",
       "      <td>-0.325079</td>\n",
       "      <td>-0.325079</td>\n",
       "      <td>-0.776693</td>\n",
       "      <td>-1.049667</td>\n",
       "      <td>-1.049667</td>\n",
       "      <td>-1.459128</td>\n",
       "      <td>0.657743</td>\n",
       "      <td>0.679176</td>\n",
       "      <td>0.679176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.084480</td>\n",
       "      <td>0.269058</td>\n",
       "      <td>1.368780</td>\n",
       "      <td>-0.594784</td>\n",
       "      <td>-0.409003</td>\n",
       "      <td>-0.776693</td>\n",
       "      <td>0.679176</td>\n",
       "      <td>0.515222</td>\n",
       "      <td>1.058598</td>\n",
       "      <td>-0.769985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.664902</td>\n",
       "      <td>0.464381</td>\n",
       "      <td>2.907784</td>\n",
       "      <td>-1.377245</td>\n",
       "      <td>-2.445678</td>\n",
       "      <td>0.325597</td>\n",
       "      <td>-0.517001</td>\n",
       "      <td>0.532169</td>\n",
       "      <td>0.532169</td>\n",
       "      <td>1.611830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.762475</td>\n",
       "      <td>0.656421</td>\n",
       "      <td>0.519934</td>\n",
       "      <td>0.451690</td>\n",
       "      <td>-0.094258</td>\n",
       "      <td>0.679176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.041950</td>\n",
       "      <td>0.246960</td>\n",
       "      <td>-0.094258</td>\n",
       "      <td>0.042229</td>\n",
       "      <td>0.792908</td>\n",
       "      <td>-0.298988</td>\n",
       "      <td>0.679176</td>\n",
       "      <td>0.679176</td>\n",
       "      <td>0.515222</td>\n",
       "      <td>0.515222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.236197</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.084480</td>\n",
       "      <td>-0.746624</td>\n",
       "      <td>0.022152</td>\n",
       "      <td>-0.286301</td>\n",
       "      <td>-0.342221</td>\n",
       "      <td>-0.517001</td>\n",
       "      <td>-0.341712</td>\n",
       "      <td>-0.389053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.517001</td>\n",
       "      <td>0.929395</td>\n",
       "      <td>1.202369</td>\n",
       "      <td>0.246960</td>\n",
       "      <td>-0.026014</td>\n",
       "      <td>-0.162501</td>\n",
       "      <td>-0.913180</td>\n",
       "      <td>-1.186154</td>\n",
       "      <td>-1.459128</td>\n",
       "      <td>0.679176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.588177</td>\n",
       "      <td>0.451690</td>\n",
       "      <td>0.656421</td>\n",
       "      <td>0.679176</td>\n",
       "      <td>0.515222</td>\n",
       "      <td>1.058598</td>\n",
       "      <td>0.496954</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>0.387912</td>\n",
       "      <td>-0.847678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2872 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.334275 -0.512236  0.406903 -1.019767  1.256110 -0.676131  0.762475   \n",
       "1 -0.327616 -0.299017 -0.266831  1.181628  0.584069 -0.551301  0.022152   \n",
       "2 -0.325079 -0.325079 -0.325079 -0.776693 -1.049667 -1.049667 -1.459128   \n",
       "3  0.084480  0.269058  1.368780 -0.594784 -0.409003 -0.776693  0.679176   \n",
       "4 -0.664902  0.464381  2.907784 -1.377245 -2.445678  0.325597 -0.517001   \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.762475  0.656421  0.519934   \n",
       "6  2.041950  0.246960 -0.094258  0.042229  0.792908 -0.298988  0.679176   \n",
       "7 -0.236197  0.001778  0.084480 -0.746624  0.022152 -0.286301 -0.342221   \n",
       "8 -0.517001  0.929395  1.202369  0.246960 -0.026014 -0.162501 -0.913180   \n",
       "9  0.588177  0.451690  0.656421  0.679176  0.515222  1.058598  0.496954   \n",
       "\n",
       "       7         8         9     ...  2862  2863  2864  2865  2866  2867  \\\n",
       "0  0.861151  0.861151  0.519934  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1 -0.475407  0.052665 -0.286301  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2  0.657743  0.679176  0.679176  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3  0.515222  1.058598 -0.769985  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4  0.532169  0.532169  1.611830  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "5  0.451690 -0.094258  0.679176  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "6  0.679176  0.515222  0.515222  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "7 -0.517001 -0.341712 -0.389053  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "8 -1.186154 -1.459128  0.679176  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9  0.006264  0.387912 -0.847678  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   2868  2869  2870  2871  \n",
       "0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0  \n",
       "5   0.0   0.0   0.0   0.0  \n",
       "6   0.0   0.0   0.0   0.0  \n",
       "7   0.0   0.0   0.0   0.0  \n",
       "8   0.0   0.0   0.0   0.0  \n",
       "9   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[10 rows x 2872 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(predictions[0]))\n",
    "4*83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_22 (InputLayer)       [(None, 4072)]               0         []                            \n",
      "                                                                                                  \n",
      " input_23 (InputLayer)       [(None, 4072)]               0         []                            \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)       [(None, 4072)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)     (None, 4072, 50)             6700      ['input_22[0][0]']            \n",
      "                                                                                                  \n",
      " cve_10 (CVE)                (None, 4072, 50)             364       ['input_23[0][0]']            \n",
      "                                                                                                  \n",
      " cve_11 (CVE)                (None, 4072, 50)             364       ['input_24[0][0]']            \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 4072, 50)             0         ['embedding_5[0][0]',         \n",
      "                                                                     'cve_10[0][0]',              \n",
      "                                                                     'cve_11[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_10 (Lambda)          (None, 4072)                 0         ['input_22[0][0]']            \n",
      "                                                                                                  \n",
      " transformer_5 (Transformer  (None, 4072, 50)             39508     ['add_5[0][0]',               \n",
      " )                                                                   'lambda_10[0][0]']           \n",
      "                                                                                                  \n",
      " input_21 (InputLayer)       [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " attention_5 (Attention)     (None, 4072, 1)              5200      ['transformer_5[0][0]',       \n",
      "                                                                     'lambda_10[0][0]']           \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 100)                  300       ['input_21[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_11 (Lambda)          (None, 50)                   0         ['transformer_5[0][0]',       \n",
      "                                                                     'attention_5[0][0]']         \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, 50)                   5050      ['dense_20[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 100)                  0         ['lambda_11[0][0]',           \n",
      " )                                                                   'dense_21[0][0]']            \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, 133)                  13433     ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 70919 (277.03 KB)\n",
      "Trainable params: 70919 (277.03 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Restored from ./STraTS_20-124_masked_transformer/ckpt-18\n",
      "302/302 [==============================] - 81s 268ms/step\n",
      "302/302 [==============================] - 81s 268ms/step\n",
      "302/302 [==============================] - 81s 268ms/step\n",
      "302/302 [==============================] - 81s 268ms/step\n",
      "302/302 [==============================] - 81s 268ms/step\n",
      "302/302 [==============================] - 81s 268ms/step\n",
      "302/302 [==============================] - 81s 268ms/step\n",
      "302/302 [==============================] - 81s 268ms/step\n",
      "302/302 [==============================] - 81s 268ms/step\n",
      "302/302 [==============================] - 81s 269ms/step\n",
      "302/302 [==============================] - 81s 269ms/step\n",
      "302/302 [==============================] - 81s 269ms/step\n",
      "302/302 [==============================] - 81s 269ms/step\n",
      "302/302 [==============================] - 81s 269ms/step\n",
      "302/302 [==============================] - 81s 269ms/step\n",
      "302/302 [==============================] - 80s 267ms/step\n",
      "302/302 [==============================] - 80s 267ms/step\n",
      "302/302 [==============================] - 80s 267ms/step\n",
      "302/302 [==============================] - 80s 267ms/step\n",
      "302/302 [==============================] - 80s 267ms/step\n",
      "302/302 [==============================] - 81s 268ms/step\n",
      "302/302 [==============================] - 81s 268ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9657/9657 [00:05<00:00, 1641.71it/s]\n"
     ]
    }
   ],
   "source": [
    "fore_savepath = './STraTS_20-124_masked_transformer'\n",
    "\n",
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 32, len(fore_test_op), 5\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "model, fore_model =  build_strats(D, fore_max_len+V*forecast_hours, V, d, N, he, dropout, forecast=True)\n",
    "print(fore_model.summary())\n",
    "# fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "lossfunction = forecast_loss\n",
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "fore_model.compile(loss=lossfunction, optimizer=opt)\n",
    "\n",
    "# initialize checkpoint manager\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=fore_model)\n",
    "manager = tf.train.CheckpointManager(ckpt, f'{fore_savepath}', max_to_keep=3)\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "# for matplotlib purposes\n",
    "start_ip = fore_test_ip\n",
    "# set initial seq_len so we can \"count\" where we are during the repeated forecasting process\n",
    "seq_len = 880\n",
    "# forecasting\n",
    "for i in range(0, forecast_hours):\n",
    "    # predict and save prediction\n",
    "    test_y_preds = fore_model.predict(fore_test_ip)\n",
    "\n",
    "    # during 1st run, initialize cumulated predictions\n",
    "    if i == 0:\n",
    "        predictions = test_y_preds\n",
    "        \n",
    "    # during following runs, concatenate predictions\n",
    "    else:\n",
    "        predictions = np.concatenate((predictions,test_y_preds), axis=1)\n",
    "        \n",
    "    # build new input consisting of original input + hourly predictions appended\n",
    "    fore_test_ip = repeat_prediction(fore_test_ip,test_y_preds, i, seq_len, max_seq_len=fore_max_len+V*forecast_hours)  \n",
    "    \n",
    "    # add V to sequence length as it is the length of prediction, to keep track\n",
    "    seq_len+=V \n",
    "\n",
    "hours = []\n",
    "max_hours = []\n",
    "# get hours\n",
    "for time in start_ip[1]:\n",
    "  hour = max(time)\n",
    "  max_hours.append(hour)\n",
    "\n",
    "  for obs_window in obs_windows:\n",
    "    if hour < obs_window:\n",
    "      hour = obs_window\n",
    "      break\n",
    "\n",
    "  hours.append(hour)\n",
    "\n",
    "# get patient ids\n",
    "test_patient_ids = []\n",
    "test_sepsis_labels = []\n",
    "\n",
    "# sub_ids = oc['SUBJECT_ID'].tolist()\n",
    "# ts_ind = oc['ts_ind'].tolist()\n",
    "# sepsis = oc['in_hospital_sepsis'].tolist()\n",
    "\n",
    "# for ind in val_inds:\n",
    "#    for i in range(len(sub_ids)):\n",
    "#      if ts_ind[i] == ind:\n",
    "#        val_sepsis_labels.append(sepsis[i])\n",
    "#        val_patient_ids.append(sub_ids[i])\n",
    "#        break\n",
    "\n",
    "for ind in tqdm(fore_inds):\n",
    "  test_sepsis_labels.append(np.unique(oc[oc['ts_ind']==ind]['in_hospital_sepsis']).item())\n",
    "  test_patient_ids.append(np.unique(oc[oc['ts_ind']==ind]['SUBJECT_ID']).item())\n",
    "\n",
    "test_data = pd.DataFrame(\n",
    "    {'ts_ind': fore_inds,\n",
    "     'obs_window': hours,\n",
    "     'SUBJECT_ID': test_patient_ids,\n",
    "     'sepsis_label': test_sepsis_labels,\n",
    "     'forecasting_pred': pd.Series(predictions.tolist()),\n",
    "     'forecasting_test_op': pd.Series(fore_op.tolist())\n",
    "    })\n",
    "\n",
    "# dump to pkl\n",
    "pickle.dump([test_data, var_to_ind], open('STraTS_20-124_masked_transformer_4-24-2_forecast.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5X90MM8AykJ"
   },
   "source": [
    "### `var_to_ind` mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4y5phcjA2CB",
    "outputId": "4f2d4fd6-9eaa-40da-b0ee-a4594b0221d7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "var_to_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = []\n",
    "max_hours = []\n",
    "# get hours\n",
    "for time in start_ip[1]:\n",
    "  hour = max(time)\n",
    "  max_hours.append(hour)\n",
    "\n",
    "  for obs_window in obs_windows:\n",
    "    if hour < obs_window:\n",
    "      hour = obs_window\n",
    "      break\n",
    "\n",
    "  hours.append(hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtslJ4tuD7NV"
   },
   "source": [
    "### patient ids, sepsis labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "o76JpXf9D6iJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3923/3923 [15:12<00:00,  4.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# get patient ids\n",
    "test_patient_ids = []\n",
    "test_sepsis_labels = []\n",
    "\n",
    "# sub_ids = oc['SUBJECT_ID'].tolist()\n",
    "# ts_ind = oc['ts_ind'].tolist()\n",
    "# sepsis = oc['in_hospital_sepsis'].tolist()\n",
    "\n",
    "# for ind in val_inds:\n",
    "#    for i in range(len(sub_ids)):\n",
    "#      if ts_ind[i] == ind:\n",
    "#        val_sepsis_labels.append(sepsis[i])\n",
    "#        val_patient_ids.append(sub_ids[i])\n",
    "#        break\n",
    "\n",
    "for ind in tqdm(fore_inds):\n",
    "  test_sepsis_labels.append(np.unique(oc[oc['ts_ind']==ind]['in_hospital_sepsis']).item())\n",
    "  test_patient_ids.append(np.unique(oc[oc['ts_ind']==ind]['SUBJECT_ID']).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200011.0,\n",
       " 200079.0,\n",
       " 200224.0,\n",
       " 200232.0,\n",
       " 200281.0,\n",
       " 200297.0,\n",
       " 200298.0,\n",
       " 200364.0,\n",
       " 200379.0,\n",
       " 200386.0,\n",
       " 200387.0,\n",
       " 200392.0,\n",
       " 200430.0,\n",
       " 200450.0,\n",
       " 200509.0,\n",
       " 200557.0,\n",
       " 200566.0,\n",
       " 200637.0,\n",
       " 200661.0,\n",
       " 200677.0,\n",
       " 200686.0,\n",
       " 200748.0,\n",
       " 200754.0,\n",
       " 200824.0,\n",
       " 200845.0,\n",
       " 200873.0,\n",
       " 200893.0,\n",
       " 200902.0,\n",
       " 200931.0,\n",
       " 200932.0,\n",
       " 200934.0,\n",
       " 200947.0,\n",
       " 200961.0,\n",
       " 200993.0,\n",
       " 201001.0,\n",
       " 201018.0,\n",
       " 201020.0,\n",
       " 201024.0,\n",
       " 201028.0,\n",
       " 201043.0,\n",
       " 201160.0,\n",
       " 201164.0,\n",
       " 201173.0,\n",
       " 201184.0,\n",
       " 201211.0,\n",
       " 201220.0,\n",
       " 201261.0,\n",
       " 201264.0,\n",
       " 201271.0,\n",
       " 201326.0,\n",
       " 201371.0,\n",
       " 201400.0,\n",
       " 201401.0,\n",
       " 201444.0,\n",
       " 201466.0,\n",
       " 201483.0,\n",
       " 201543.0,\n",
       " 201569.0,\n",
       " 201584.0,\n",
       " 201585.0,\n",
       " 201587.0,\n",
       " 201756.0,\n",
       " 201866.0,\n",
       " 201876.0,\n",
       " 201877.0,\n",
       " 201951.0,\n",
       " 201970.0,\n",
       " 201982.0,\n",
       " 202010.0,\n",
       " 202019.0,\n",
       " 202032.0,\n",
       " 202057.0,\n",
       " 202063.0,\n",
       " 202129.0,\n",
       " 202211.0,\n",
       " 202214.0,\n",
       " 202237.0,\n",
       " 202248.0,\n",
       " 202256.0,\n",
       " 202268.0,\n",
       " 202287.0,\n",
       " 202291.0,\n",
       " 202293.0,\n",
       " 202304.0,\n",
       " 202309.0,\n",
       " 202351.0,\n",
       " 202368.0,\n",
       " 202385.0,\n",
       " 202403.0,\n",
       " 202414.0,\n",
       " 202419.0,\n",
       " 202487.0,\n",
       " 202565.0,\n",
       " 202575.0,\n",
       " 202588.0,\n",
       " 202589.0,\n",
       " 202607.0,\n",
       " 202624.0,\n",
       " 202642.0,\n",
       " 202660.0,\n",
       " 202666.0,\n",
       " 202693.0,\n",
       " 202762.0,\n",
       " 202791.0,\n",
       " 202797.0,\n",
       " 202803.0,\n",
       " 202807.0,\n",
       " 202853.0,\n",
       " 202860.0,\n",
       " 202967.0,\n",
       " 202985.0,\n",
       " 202989.0,\n",
       " 202990.0,\n",
       " 203009.0,\n",
       " 203011.0,\n",
       " 203015.0,\n",
       " 203017.0,\n",
       " 203032.0,\n",
       " 203041.0,\n",
       " 203055.0,\n",
       " 203085.0,\n",
       " 203099.0,\n",
       " 203119.0,\n",
       " 203140.0,\n",
       " 203155.0,\n",
       " 203177.0,\n",
       " 203181.0,\n",
       " 203193.0,\n",
       " 203236.0,\n",
       " 203237.0,\n",
       " 203250.0,\n",
       " 203266.0,\n",
       " 203274.0,\n",
       " 203277.0,\n",
       " 203286.0,\n",
       " 203297.0,\n",
       " 203312.0,\n",
       " 203319.0,\n",
       " 203335.0,\n",
       " 203381.0,\n",
       " 203383.0,\n",
       " 203399.0,\n",
       " 203401.0,\n",
       " 203413.0,\n",
       " 203478.0,\n",
       " 203493.0,\n",
       " 203504.0,\n",
       " 203553.0,\n",
       " 203554.0,\n",
       " 203590.0,\n",
       " 203596.0,\n",
       " 203624.0,\n",
       " 203625.0,\n",
       " 203643.0,\n",
       " 203694.0,\n",
       " 203761.0,\n",
       " 203765.0,\n",
       " 203838.0,\n",
       " 203853.0,\n",
       " 203872.0,\n",
       " 203911.0,\n",
       " 203930.0,\n",
       " 203970.0,\n",
       " 203971.0,\n",
       " 203984.0,\n",
       " 204030.0,\n",
       " 204036.0,\n",
       " 204040.0,\n",
       " 204042.0,\n",
       " 204084.0,\n",
       " 204094.0,\n",
       " 204104.0,\n",
       " 204128.0,\n",
       " 204169.0,\n",
       " 204181.0,\n",
       " 204182.0,\n",
       " 204208.0,\n",
       " 204212.0,\n",
       " 204239.0,\n",
       " 204253.0,\n",
       " 204288.0,\n",
       " 204293.0,\n",
       " 204366.0,\n",
       " 204415.0,\n",
       " 204449.0,\n",
       " 204543.0,\n",
       " 204549.0,\n",
       " 204566.0,\n",
       " 204575.0,\n",
       " 204580.0,\n",
       " 204636.0,\n",
       " 204661.0,\n",
       " 204673.0,\n",
       " 204682.0,\n",
       " 204699.0,\n",
       " 204717.0,\n",
       " 204726.0,\n",
       " 204742.0,\n",
       " 204796.0,\n",
       " 204806.0,\n",
       " 204850.0,\n",
       " 204878.0,\n",
       " 204883.0,\n",
       " 204884.0,\n",
       " 204904.0,\n",
       " 204908.0,\n",
       " 204910.0,\n",
       " 204964.0,\n",
       " 204986.0,\n",
       " 205006.0,\n",
       " 205042.0,\n",
       " 205050.0,\n",
       " 205108.0,\n",
       " 205158.0,\n",
       " 205159.0,\n",
       " 205172.0,\n",
       " 205258.0,\n",
       " 205291.0,\n",
       " 205293.0,\n",
       " 205296.0,\n",
       " 205347.0,\n",
       " 205381.0,\n",
       " 205447.0,\n",
       " 205457.0,\n",
       " 205464.0,\n",
       " 205484.0,\n",
       " 205502.0,\n",
       " 205557.0,\n",
       " 205643.0,\n",
       " 205670.0,\n",
       " 205709.0,\n",
       " 205731.0,\n",
       " 205747.0,\n",
       " 205773.0,\n",
       " 205780.0,\n",
       " 205783.0,\n",
       " 205826.0,\n",
       " 205844.0,\n",
       " 205865.0,\n",
       " 205878.0,\n",
       " 205880.0,\n",
       " 205899.0,\n",
       " 205911.0,\n",
       " 205918.0,\n",
       " 205933.0,\n",
       " 205969.0,\n",
       " 205980.0,\n",
       " 205987.0,\n",
       " 206005.0,\n",
       " 206008.0,\n",
       " 206032.0,\n",
       " 206042.0,\n",
       " 206076.0,\n",
       " 206118.0,\n",
       " 206128.0,\n",
       " 206141.0,\n",
       " 206189.0,\n",
       " 206211.0,\n",
       " 206222.0,\n",
       " 206225.0,\n",
       " 206294.0,\n",
       " 206358.0,\n",
       " 206396.0,\n",
       " 206426.0,\n",
       " 206439.0,\n",
       " 206442.0,\n",
       " 206449.0,\n",
       " 206496.0,\n",
       " 206520.0,\n",
       " 206551.0,\n",
       " 206563.0,\n",
       " 206664.0,\n",
       " 206665.0,\n",
       " 206675.0,\n",
       " 206704.0,\n",
       " 206750.0,\n",
       " 206763.0,\n",
       " 206765.0,\n",
       " 206887.0,\n",
       " 206910.0,\n",
       " 206928.0,\n",
       " 206932.0,\n",
       " 206964.0,\n",
       " 207015.0,\n",
       " 207020.0,\n",
       " 207032.0,\n",
       " 207064.0,\n",
       " 207076.0,\n",
       " 207161.0,\n",
       " 207170.0,\n",
       " 207185.0,\n",
       " 207188.0,\n",
       " 207247.0,\n",
       " 207270.0,\n",
       " 207287.0,\n",
       " 207289.0,\n",
       " 207313.0,\n",
       " 207316.0,\n",
       " 207337.0,\n",
       " 207344.0,\n",
       " 207356.0,\n",
       " 207362.0,\n",
       " 207379.0,\n",
       " 207392.0,\n",
       " 207403.0,\n",
       " 207484.0,\n",
       " 207492.0,\n",
       " 207500.0,\n",
       " 207501.0,\n",
       " 207609.0,\n",
       " 207636.0,\n",
       " 207673.0,\n",
       " 207685.0,\n",
       " 207713.0,\n",
       " 207743.0,\n",
       " 207791.0,\n",
       " 207796.0,\n",
       " 207813.0,\n",
       " 207822.0,\n",
       " 207827.0,\n",
       " 207832.0,\n",
       " 207880.0,\n",
       " 207902.0,\n",
       " 207918.0,\n",
       " 207920.0,\n",
       " 207958.0,\n",
       " 207962.0,\n",
       " 207990.0,\n",
       " 208028.0,\n",
       " 208031.0,\n",
       " 208148.0,\n",
       " 208184.0,\n",
       " 208226.0,\n",
       " 208249.0,\n",
       " 208256.0,\n",
       " 208336.0,\n",
       " 208378.0,\n",
       " 208390.0,\n",
       " 208400.0,\n",
       " 208433.0,\n",
       " 208438.0,\n",
       " 208441.0,\n",
       " 208457.0,\n",
       " 208460.0,\n",
       " 208507.0,\n",
       " 208532.0,\n",
       " 208568.0,\n",
       " 208589.0,\n",
       " 208604.0,\n",
       " 208634.0,\n",
       " 208646.0,\n",
       " 208688.0,\n",
       " 208693.0,\n",
       " 208694.0,\n",
       " 208704.0,\n",
       " 208745.0,\n",
       " 208751.0,\n",
       " 208761.0,\n",
       " 208784.0,\n",
       " 208821.0,\n",
       " 208861.0,\n",
       " 208919.0,\n",
       " 208935.0,\n",
       " 208941.0,\n",
       " 208977.0,\n",
       " 208982.0,\n",
       " 209012.0,\n",
       " 209028.0,\n",
       " 209125.0,\n",
       " 209127.0,\n",
       " 209130.0,\n",
       " 209148.0,\n",
       " 209180.0,\n",
       " 209181.0,\n",
       " 209226.0,\n",
       " 209315.0,\n",
       " 209351.0,\n",
       " 209445.0,\n",
       " 209449.0,\n",
       " 209473.0,\n",
       " 209489.0,\n",
       " 209560.0,\n",
       " 209611.0,\n",
       " 209613.0,\n",
       " 209633.0,\n",
       " 209635.0,\n",
       " 209637.0,\n",
       " 209669.0,\n",
       " 209702.0,\n",
       " 209727.0,\n",
       " 209736.0,\n",
       " 209742.0,\n",
       " 209758.0,\n",
       " 209797.0,\n",
       " 209800.0,\n",
       " 209818.0,\n",
       " 209831.0,\n",
       " 209864.0,\n",
       " 209878.0,\n",
       " 209884.0,\n",
       " 210007.0,\n",
       " 210024.0,\n",
       " 210097.0,\n",
       " 210103.0,\n",
       " 210109.0,\n",
       " 210132.0,\n",
       " 210165.0,\n",
       " 210184.0,\n",
       " 210204.0,\n",
       " 210288.0,\n",
       " 210289.0,\n",
       " 210293.0,\n",
       " 210306.0,\n",
       " 210308.0,\n",
       " 210388.0,\n",
       " 210393.0,\n",
       " 210408.0,\n",
       " 210483.0,\n",
       " 210493.0,\n",
       " 210558.0,\n",
       " 210603.0,\n",
       " 210654.0,\n",
       " 210674.0,\n",
       " 210738.0,\n",
       " 210833.0,\n",
       " 210881.0,\n",
       " 210909.0,\n",
       " 210947.0,\n",
       " 210956.0,\n",
       " 210968.0,\n",
       " 211030.0,\n",
       " 211099.0,\n",
       " 211104.0,\n",
       " 211139.0,\n",
       " 211148.0,\n",
       " 211156.0,\n",
       " 211171.0,\n",
       " 211233.0,\n",
       " 211237.0,\n",
       " 211270.0,\n",
       " 211271.0,\n",
       " 211288.0,\n",
       " 211298.0,\n",
       " 211357.0,\n",
       " 211377.0,\n",
       " 211396.0,\n",
       " 211465.0,\n",
       " 211522.0,\n",
       " 211547.0,\n",
       " 211552.0,\n",
       " 211575.0,\n",
       " 211660.0,\n",
       " 211685.0,\n",
       " 211720.0,\n",
       " 211757.0,\n",
       " 211813.0,\n",
       " 211815.0,\n",
       " 211840.0,\n",
       " 211849.0,\n",
       " 211885.0,\n",
       " 211913.0,\n",
       " 211930.0,\n",
       " 211950.0,\n",
       " 212014.0,\n",
       " 212055.0,\n",
       " 212060.0,\n",
       " 212071.0,\n",
       " 212079.0,\n",
       " 212108.0,\n",
       " 212109.0,\n",
       " 212198.0,\n",
       " 212205.0,\n",
       " 212213.0,\n",
       " 212226.0,\n",
       " 212232.0,\n",
       " 212243.0,\n",
       " 212245.0,\n",
       " 212249.0,\n",
       " 212264.0,\n",
       " 212283.0,\n",
       " 212374.0,\n",
       " 212379.0,\n",
       " 212399.0,\n",
       " 212409.0,\n",
       " 212430.0,\n",
       " 212438.0,\n",
       " 212466.0,\n",
       " 212507.0,\n",
       " 212514.0,\n",
       " 212522.0,\n",
       " 212535.0,\n",
       " 212542.0,\n",
       " 212543.0,\n",
       " 212592.0,\n",
       " 212593.0,\n",
       " 212598.0,\n",
       " 212606.0,\n",
       " 212644.0,\n",
       " 212662.0,\n",
       " 212673.0,\n",
       " 212715.0,\n",
       " 212753.0,\n",
       " 212766.0,\n",
       " 212777.0,\n",
       " 212787.0,\n",
       " 212790.0,\n",
       " 212809.0,\n",
       " 212827.0,\n",
       " 212829.0,\n",
       " 212833.0,\n",
       " 212834.0,\n",
       " 212883.0,\n",
       " 212925.0,\n",
       " 212944.0,\n",
       " 212953.0,\n",
       " 213015.0,\n",
       " 213083.0,\n",
       " 213107.0,\n",
       " 213142.0,\n",
       " 213149.0,\n",
       " 213170.0,\n",
       " 213175.0,\n",
       " 213207.0,\n",
       " 213225.0,\n",
       " 213236.0,\n",
       " 213237.0,\n",
       " 213243.0,\n",
       " 213250.0,\n",
       " 213280.0,\n",
       " 213287.0,\n",
       " 213295.0,\n",
       " 213323.0,\n",
       " 213385.0,\n",
       " 213394.0,\n",
       " 213485.0,\n",
       " 213502.0,\n",
       " 213522.0,\n",
       " 213545.0,\n",
       " 213553.0,\n",
       " 213587.0,\n",
       " 213662.0,\n",
       " 213663.0,\n",
       " 213664.0,\n",
       " 213693.0,\n",
       " 213742.0,\n",
       " 213791.0,\n",
       " 213792.0,\n",
       " 213824.0,\n",
       " 213829.0,\n",
       " 213879.0,\n",
       " 213880.0,\n",
       " 213932.0,\n",
       " 214006.0,\n",
       " 214047.0,\n",
       " 214058.0,\n",
       " 214110.0,\n",
       " 214122.0,\n",
       " 214126.0,\n",
       " 214153.0,\n",
       " 214163.0,\n",
       " 214168.0,\n",
       " 214245.0,\n",
       " 214252.0,\n",
       " 214277.0,\n",
       " 214293.0,\n",
       " 214307.0,\n",
       " 214336.0,\n",
       " 214408.0,\n",
       " 214435.0,\n",
       " 214441.0,\n",
       " 214469.0,\n",
       " 214486.0,\n",
       " 214502.0,\n",
       " 214534.0,\n",
       " 214564.0,\n",
       " 214569.0,\n",
       " 214573.0,\n",
       " 214575.0,\n",
       " 214602.0,\n",
       " 214640.0,\n",
       " 214668.0,\n",
       " 214678.0,\n",
       " 214692.0,\n",
       " 214791.0,\n",
       " 214798.0,\n",
       " 214818.0,\n",
       " 214832.0,\n",
       " 214864.0,\n",
       " 214872.0,\n",
       " 214873.0,\n",
       " 214879.0,\n",
       " 214902.0,\n",
       " 214909.0,\n",
       " 214969.0,\n",
       " 214989.0,\n",
       " 215006.0,\n",
       " 215010.0,\n",
       " 215024.0,\n",
       " 215031.0,\n",
       " 215068.0,\n",
       " 215080.0,\n",
       " 215090.0,\n",
       " 215106.0,\n",
       " 215147.0,\n",
       " 215181.0,\n",
       " 215187.0,\n",
       " 215218.0,\n",
       " 215233.0,\n",
       " 215240.0,\n",
       " 215251.0,\n",
       " 215258.0,\n",
       " 215291.0,\n",
       " 215323.0,\n",
       " 215347.0,\n",
       " 215398.0,\n",
       " 215414.0,\n",
       " 215425.0,\n",
       " 215444.0,\n",
       " 215461.0,\n",
       " 215466.0,\n",
       " 215482.0,\n",
       " 215497.0,\n",
       " 215534.0,\n",
       " 215586.0,\n",
       " 215624.0,\n",
       " 215676.0,\n",
       " 215694.0,\n",
       " 215713.0,\n",
       " 215717.0,\n",
       " 215750.0,\n",
       " 215768.0,\n",
       " 215787.0,\n",
       " 215789.0,\n",
       " 215824.0,\n",
       " 215833.0,\n",
       " 215839.0,\n",
       " 215843.0,\n",
       " 215876.0,\n",
       " 215884.0,\n",
       " 215893.0,\n",
       " 216105.0,\n",
       " 216151.0,\n",
       " 216152.0,\n",
       " 216176.0,\n",
       " 216183.0,\n",
       " 216185.0,\n",
       " 216186.0,\n",
       " 216250.0,\n",
       " 216252.0,\n",
       " 216259.0,\n",
       " 216265.0,\n",
       " 216281.0,\n",
       " 216287.0,\n",
       " 216330.0,\n",
       " 216395.0,\n",
       " 216408.0,\n",
       " 216494.0,\n",
       " 216545.0,\n",
       " 216577.0,\n",
       " 216578.0,\n",
       " 216579.0,\n",
       " 216676.0,\n",
       " 216720.0,\n",
       " 216726.0,\n",
       " 216731.0,\n",
       " 216840.0,\n",
       " 216851.0,\n",
       " 216861.0,\n",
       " 216862.0,\n",
       " 216867.0,\n",
       " 216869.0,\n",
       " 216876.0,\n",
       " 216896.0,\n",
       " 216898.0,\n",
       " 216910.0,\n",
       " 216955.0,\n",
       " 217035.0,\n",
       " 217036.0,\n",
       " 217046.0,\n",
       " 217081.0,\n",
       " 217145.0,\n",
       " 217161.0,\n",
       " 217169.0,\n",
       " 217196.0,\n",
       " 217245.0,\n",
       " 217277.0,\n",
       " 217279.0,\n",
       " 217299.0,\n",
       " 217320.0,\n",
       " 217342.0,\n",
       " 217355.0,\n",
       " 217356.0,\n",
       " 217377.0,\n",
       " 217392.0,\n",
       " 217398.0,\n",
       " 217410.0,\n",
       " 217450.0,\n",
       " 217462.0,\n",
       " 217482.0,\n",
       " 217517.0,\n",
       " 217552.0,\n",
       " 217601.0,\n",
       " 217672.0,\n",
       " 217720.0,\n",
       " 217758.0,\n",
       " 217780.0,\n",
       " 217790.0,\n",
       " 217813.0,\n",
       " 217826.0,\n",
       " 217828.0,\n",
       " 217840.0,\n",
       " 217864.0,\n",
       " 217923.0,\n",
       " 217929.0,\n",
       " 217968.0,\n",
       " 217986.0,\n",
       " 217994.0,\n",
       " 218027.0,\n",
       " 218043.0,\n",
       " 218110.0,\n",
       " 218149.0,\n",
       " 218158.0,\n",
       " 218163.0,\n",
       " 218266.0,\n",
       " 218298.0,\n",
       " 218313.0,\n",
       " 218377.0,\n",
       " 218384.0,\n",
       " 218394.0,\n",
       " 218444.0,\n",
       " 218463.0,\n",
       " 218480.0,\n",
       " 218511.0,\n",
       " 218569.0,\n",
       " 218589.0,\n",
       " 218597.0,\n",
       " 218630.0,\n",
       " 218635.0,\n",
       " 218660.0,\n",
       " 218721.0,\n",
       " 218744.0,\n",
       " 218791.0,\n",
       " 218802.0,\n",
       " 218816.0,\n",
       " 218829.0,\n",
       " 218853.0,\n",
       " 218868.0,\n",
       " 218884.0,\n",
       " 218896.0,\n",
       " 218906.0,\n",
       " 218916.0,\n",
       " 218974.0,\n",
       " 218988.0,\n",
       " 219002.0,\n",
       " 219003.0,\n",
       " 219019.0,\n",
       " 219029.0,\n",
       " 219050.0,\n",
       " 219057.0,\n",
       " 219060.0,\n",
       " 219119.0,\n",
       " 219124.0,\n",
       " 219132.0,\n",
       " 219133.0,\n",
       " 219134.0,\n",
       " 219211.0,\n",
       " 219236.0,\n",
       " 219254.0,\n",
       " 219256.0,\n",
       " 219269.0,\n",
       " 219307.0,\n",
       " 219411.0,\n",
       " 219432.0,\n",
       " 219454.0,\n",
       " 219478.0,\n",
       " 219479.0,\n",
       " 219481.0,\n",
       " 219530.0,\n",
       " 219537.0,\n",
       " 219540.0,\n",
       " 219566.0,\n",
       " 219604.0,\n",
       " 219605.0,\n",
       " 219610.0,\n",
       " 219671.0,\n",
       " 219672.0,\n",
       " 219687.0,\n",
       " 219703.0,\n",
       " 219751.0,\n",
       " 219756.0,\n",
       " 219775.0,\n",
       " 219793.0,\n",
       " 219804.0,\n",
       " 219831.0,\n",
       " 219860.0,\n",
       " 219935.0,\n",
       " 219940.0,\n",
       " 219943.0,\n",
       " 219948.0,\n",
       " 219958.0,\n",
       " 219988.0,\n",
       " 220011.0,\n",
       " 220015.0,\n",
       " 220175.0,\n",
       " 220177.0,\n",
       " 220197.0,\n",
       " 220269.0,\n",
       " 220279.0,\n",
       " 220301.0,\n",
       " 220302.0,\n",
       " 220333.0,\n",
       " 220366.0,\n",
       " 220369.0,\n",
       " 220394.0,\n",
       " 220409.0,\n",
       " 220419.0,\n",
       " 220487.0,\n",
       " 220511.0,\n",
       " 220530.0,\n",
       " 220569.0,\n",
       " 220576.0,\n",
       " 220609.0,\n",
       " 220614.0,\n",
       " 220635.0,\n",
       " 220644.0,\n",
       " 220650.0,\n",
       " 220657.0,\n",
       " 220700.0,\n",
       " 220701.0,\n",
       " 220720.0,\n",
       " 220723.0,\n",
       " 220770.0,\n",
       " 220774.0,\n",
       " 220845.0,\n",
       " 220848.0,\n",
       " 220861.0,\n",
       " 220967.0,\n",
       " 221000.0,\n",
       " 221002.0,\n",
       " 221028.0,\n",
       " 221035.0,\n",
       " 221102.0,\n",
       " 221103.0,\n",
       " 221121.0,\n",
       " 221157.0,\n",
       " 221195.0,\n",
       " 221218.0,\n",
       " 221235.0,\n",
       " 221251.0,\n",
       " 221261.0,\n",
       " 221280.0,\n",
       " 221386.0,\n",
       " 221411.0,\n",
       " 221414.0,\n",
       " 221444.0,\n",
       " 221455.0,\n",
       " 221467.0,\n",
       " 221494.0,\n",
       " 221510.0,\n",
       " 221517.0,\n",
       " 221523.0,\n",
       " 221531.0,\n",
       " 221563.0,\n",
       " 221597.0,\n",
       " 221616.0,\n",
       " 221650.0,\n",
       " 221716.0,\n",
       " 221779.0,\n",
       " 221829.0,\n",
       " 221832.0,\n",
       " 221879.0,\n",
       " 221889.0,\n",
       " 221917.0,\n",
       " 221919.0,\n",
       " 221926.0,\n",
       " 221951.0,\n",
       " 221966.0,\n",
       " 221992.0,\n",
       " 222015.0,\n",
       " 222016.0,\n",
       " 222085.0,\n",
       " 222107.0,\n",
       " 222114.0,\n",
       " 222163.0,\n",
       " 222205.0,\n",
       " 222212.0,\n",
       " 222279.0,\n",
       " 222378.0,\n",
       " 222381.0,\n",
       " 222386.0,\n",
       " 222435.0,\n",
       " 222474.0,\n",
       " 222511.0,\n",
       " 222561.0,\n",
       " 222595.0,\n",
       " 222614.0,\n",
       " 222643.0,\n",
       " 222645.0,\n",
       " 222649.0,\n",
       " 222674.0,\n",
       " 222702.0,\n",
       " 222710.0,\n",
       " 222738.0,\n",
       " 222792.0,\n",
       " 222793.0,\n",
       " 222817.0,\n",
       " 222827.0,\n",
       " 222829.0,\n",
       " 222831.0,\n",
       " 222835.0,\n",
       " 222912.0,\n",
       " 222928.0,\n",
       " 222939.0,\n",
       " 222959.0,\n",
       " 222997.0,\n",
       " 223023.0,\n",
       " 223029.0,\n",
       " 223032.0,\n",
       " 223058.0,\n",
       " 223166.0,\n",
       " 223181.0,\n",
       " 223202.0,\n",
       " 223228.0,\n",
       " 223244.0,\n",
       " 223256.0,\n",
       " 223313.0,\n",
       " 223322.0,\n",
       " 223351.0,\n",
       " 223379.0,\n",
       " 223407.0,\n",
       " 223511.0,\n",
       " 223523.0,\n",
       " 223567.0,\n",
       " 223600.0,\n",
       " 223615.0,\n",
       " 223616.0,\n",
       " 223630.0,\n",
       " 223632.0,\n",
       " 223671.0,\n",
       " 223672.0,\n",
       " 223699.0,\n",
       " 223708.0,\n",
       " 223724.0,\n",
       " 223740.0,\n",
       " 223769.0,\n",
       " 223783.0,\n",
       " 223830.0,\n",
       " 223837.0,\n",
       " 223871.0,\n",
       " 223875.0,\n",
       " 223912.0,\n",
       " 223922.0,\n",
       " 223940.0,\n",
       " 223956.0,\n",
       " 223996.0,\n",
       " 224053.0,\n",
       " 224098.0,\n",
       " 224102.0,\n",
       " 224155.0,\n",
       " 224257.0,\n",
       " 224299.0,\n",
       " 224319.0,\n",
       " 224323.0,\n",
       " 224324.0,\n",
       " 224326.0,\n",
       " 224330.0,\n",
       " 224335.0,\n",
       " 224353.0,\n",
       " 224379.0,\n",
       " 224409.0,\n",
       " 224436.0,\n",
       " 224451.0,\n",
       " 224452.0,\n",
       " 224453.0,\n",
       " 224462.0,\n",
       " 224532.0,\n",
       " 224554.0,\n",
       " 224579.0,\n",
       " 224589.0,\n",
       " 224645.0,\n",
       " 224646.0,\n",
       " 224686.0,\n",
       " 224695.0,\n",
       " 224722.0,\n",
       " 224750.0,\n",
       " 224759.0,\n",
       " 224800.0,\n",
       " 224808.0,\n",
       " 224824.0,\n",
       " 224833.0,\n",
       " 224861.0,\n",
       " 224867.0,\n",
       " 224868.0,\n",
       " 224889.0,\n",
       " 224899.0,\n",
       " 224911.0,\n",
       " 224931.0,\n",
       " 224945.0,\n",
       " 224966.0,\n",
       " 224986.0,\n",
       " ...]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_patient_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDZ_Lg3zEamZ"
   },
   "source": [
    "### output to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "c7MMTyvAEaDJ"
   },
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(\n",
    "    {'ts_ind': fore_inds,\n",
    "     'obs_window': hours,\n",
    "     'SUBJECT_ID': test_patient_ids,\n",
    "     'sepsis_label': test_sepsis_labels,\n",
    "     'forecasting_pred': pd.Series(predictions.tolist()),\n",
    "     'forecasting_test_op': pd.Series(fore_op.tolist())\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "z8KDW8G1JQDH",
    "outputId": "da355acf-decd-4988-a359-9f12fc054542"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>obs_window</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>sepsis_label</th>\n",
       "      <th>forecasting_pred</th>\n",
       "      <th>forecasting_test_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>200011.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.056995153427124, -0.6347951292991638, -0.50...</td>\n",
       "      <td>[0.8400016372490969, -0.8902682310165556, -1.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>200079.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.806349515914917, -0.38487932085990906, -0....</td>\n",
       "      <td>[-0.0195401924382678, 0.0097278901485559, 0.46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>200224.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9422867894172668, 0.5341206789016724, 0.036...</td>\n",
       "      <td>[1.0171875777582011, -0.8952046714397234, 1.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>200232.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.37082815170288086, -0.16450455784797668, 0...</td>\n",
       "      <td>[-0.2787221349873852, 0.9900714985358582, 1.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>200281.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.14169426262378693, 1.6773834228515625, -0....</td>\n",
       "      <td>[0.2396417501108494, 4.45897965129093, -0.2576...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>43327</td>\n",
       "      <td>4</td>\n",
       "      <td>299861.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.1628892421722412, 1.0943489074707031, -0.9...</td>\n",
       "      <td>[-1.833813790282089, 1.0654825453348815, -1.56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>43348</td>\n",
       "      <td>4</td>\n",
       "      <td>299911.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1815841943025589, 0.9949281215667725, 0.455...</td>\n",
       "      <td>[-0.0195401924382678, 1.9704151069231617, 0.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>43367</td>\n",
       "      <td>4</td>\n",
       "      <td>299955.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.37157684564590454, -0.3972075581550598, 0.7...</td>\n",
       "      <td>[1.0716606948959595, -0.6428363572216266, 0.97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>43378</td>\n",
       "      <td>4</td>\n",
       "      <td>299976.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.459381639957428, 1.2800699472427368, -0.71...</td>\n",
       "      <td>[-0.0519379352569075, 0.6130162645407418, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>43387</td>\n",
       "      <td>4</td>\n",
       "      <td>299999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.37880903482437134, 0.09668580442667007, -0...</td>\n",
       "      <td>[-0.5379040775365025, -0.2165052502485139, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3923 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ts_ind  obs_window  SUBJECT_ID  sepsis_label  \\\n",
       "0          5           4    200011.0             1   \n",
       "1         38           4    200079.0             0   \n",
       "2         98           4    200224.0             0   \n",
       "3        103           4    200232.0             0   \n",
       "4        121           4    200281.0             0   \n",
       "...      ...         ...         ...           ...   \n",
       "3918   43327           4    299861.0             0   \n",
       "3919   43348           4    299911.0             0   \n",
       "3920   43367           4    299955.0             1   \n",
       "3921   43378           4    299976.0             0   \n",
       "3922   43387           4    299999.0             0   \n",
       "\n",
       "                                       forecasting_pred  \\\n",
       "0     [1.056995153427124, -0.6347951292991638, -0.50...   \n",
       "1     [-1.806349515914917, -0.38487932085990906, -0....   \n",
       "2     [0.9422867894172668, 0.5341206789016724, 0.036...   \n",
       "3     [-0.37082815170288086, -0.16450455784797668, 0...   \n",
       "4     [-0.14169426262378693, 1.6773834228515625, -0....   \n",
       "...                                                 ...   \n",
       "3918  [-1.1628892421722412, 1.0943489074707031, -0.9...   \n",
       "3919  [0.1815841943025589, 0.9949281215667725, 0.455...   \n",
       "3920  [0.37157684564590454, -0.3972075581550598, 0.7...   \n",
       "3921  [-0.459381639957428, 1.2800699472427368, -0.71...   \n",
       "3922  [-0.37880903482437134, 0.09668580442667007, -0...   \n",
       "\n",
       "                                    forecasting_test_op  \n",
       "0     [0.8400016372490969, -0.8902682310165556, -1.5...  \n",
       "1     [-0.0195401924382678, 0.0097278901485559, 0.46...  \n",
       "2     [1.0171875777582011, -0.8952046714397234, 1.33...  \n",
       "3     [-0.2787221349873852, 0.9900714985358582, 1.19...  \n",
       "4     [0.2396417501108494, 4.45897965129093, -0.2576...  \n",
       "...                                                 ...  \n",
       "3918  [-1.833813790282089, 1.0654825453348815, -1.56...  \n",
       "3919  [-0.0195401924382678, 1.9704151069231617, 0.17...  \n",
       "3920  [1.0716606948959595, -0.6428363572216266, 0.97...  \n",
       "3921  [-0.0519379352569075, 0.6130162645407418, -0.3...  \n",
       "3922  [-0.5379040775365025, -0.2165052502485139, 0.0...  \n",
       "\n",
       "[3923 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "XHcDei3KFgjp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dump to pkl\n",
    "pickle.dump([test_data, var_to_ind], open('strats_base_test.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuClass": "premium",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
