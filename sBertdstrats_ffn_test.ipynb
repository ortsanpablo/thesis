{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "# from tensorflow.keras import models\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'a:action', 'm:charttime',\n",
      "       'm:icustayid', 'm:presumed_onset', 'o:Arterial_BE',\n",
      "       'o:Arterial_lactate', 'o:Arterial_pH', 'o:BUN', 'o:Calcium',\n",
      "       'o:Chloride', 'o:Creatinine', 'o:DiaBP', 'o:FiO2_1', 'o:GCS',\n",
      "       'o:Glucose', 'o:HCO3', 'o:HR', 'o:Hb', 'o:INR', 'o:Magnesium',\n",
      "       'o:MeanBP', 'o:PT', 'o:PTT', 'o:PaO2_FiO2', 'o:Platelets_count',\n",
      "       'o:Potassium', 'o:RR', 'o:SGOT', 'o:SGPT', 'o:SIRS', 'o:SOFA',\n",
      "       'o:Shock_Index', 'o:Sodium', 'o:SpO2', 'o:SysBP', 'o:Temp_C',\n",
      "       'o:Total_bili', 'o:WBC_count', 'o:Weight_kg', 'o:age',\n",
      "       'o:cumulated_balance', 'o:gender', 'o:input_4hourly', 'o:input_total',\n",
      "       'o:max_dose_vaso', 'o:mechvent', 'o:output_4hourly', 'o:output_total',\n",
      "       'o:paCO2', 'o:paO2', 'o:re_admission', 'r:reward', 'step', 'traj',\n",
      "       'sepsis_label', 'hour', 'clean_text', 'sBert:0', 'sBert:1', 'sBert:2',\n",
      "       'sBert:3', 'sBert:4', 'sBert:5', 'sBert:6', 'sBert:7', 'sBert:8',\n",
      "       'sBert:9', 'sBert:10', 'sBert:11', 'sBert:12', 'sBert:13', 'sBert:14',\n",
      "       'sBert:15', 'sBert:16', 'sBert:17', 'sBert:18', 'sBert:19', 'sBert:20',\n",
      "       'sBert:21', 'sBert:22', 'sBert:23', 'sBert:24', 'sBert:25', 'sBert:26',\n",
      "       'sBert:27', 'sBert:28', 'sBert:29', 'sBert:30', 'sBert:31'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>o:Arterial_BE</th>\n",
       "      <td>-10.902151</td>\n",
       "      <td>25.890943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o:Arterial_lactate</th>\n",
       "      <td>-1.551057</td>\n",
       "      <td>20.392145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o:Arterial_pH</th>\n",
       "      <td>-72.425298</td>\n",
       "      <td>6.610118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o:BUN</th>\n",
       "      <td>-7.955757</td>\n",
       "      <td>4.094832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o:Calcium</th>\n",
       "      <td>-11.464160</td>\n",
       "      <td>15.463885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m:icustayid</th>\n",
       "      <td>200003.000000</td>\n",
       "      <td>299999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepsis_label</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o:age</th>\n",
       "      <td>-2.775468</td>\n",
       "      <td>1.616612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o:gender</th>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              min            max\n",
       "o:Arterial_BE          -10.902151      25.890943\n",
       "o:Arterial_lactate      -1.551057      20.392145\n",
       "o:Arterial_pH          -72.425298       6.610118\n",
       "o:BUN                   -7.955757       4.094832\n",
       "o:Calcium              -11.464160      15.463885\n",
       "...                           ...            ...\n",
       "m:icustayid         200003.000000  299999.000000\n",
       "sepsis_label             0.000000       1.000000\n",
       "hour                     0.000000      78.000000\n",
       "o:age                   -2.775468       1.616612\n",
       "o:gender                -0.500000       0.500000\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab = pd.read_csv(\"lab_sBert_concat_fulldata.csv\")\n",
    "print(lab.columns)\n",
    "#hours = pd.read_csv(\"lab_hours.csv\")\n",
    "#lab[\"hour\"] = hours[\"hour\"]\n",
    "targets = lab[[\"m:icustayid\", \"sepsis_label\", \"hour\", \"o:age\", \"o:gender\"]]\n",
    "rows = lab.drop(columns=[\"clean_text\",\"Unnamed: 0.2\",\"Unnamed: 0.1\",\"Unnamed: 0\", \"o:age\", \"o:gender\",\"m:icustayid\", \"sepsis_label\", \"hour\",\"m:charttime\", \"traj\", \"step\", \"r:reward\", \"a:action\",\"Unnamed: 0\", \"Unnamed: 0.1\", \"m:presumed_onset\", \"o:cumulated_balance\", \"o:re_admission\", \"o:output_4hourly\", \"o:output_total\", \"o:PaO2_FiO2\", \"o:input_total\"])\n",
    "scaler = StandardScaler()\n",
    "rows[rows.columns] = scaler.fit_transform(rows[rows.columns])\n",
    "rows[\"m:icustayid\"] = targets[\"m:icustayid\"]\n",
    "rows[\"sepsis_label\"] = targets[\"sepsis_label\"]\n",
    "rows[\"hour\"] = targets[\"hour\"]\n",
    "rows[\"o:age\"] = targets[\"o:age\"]\n",
    "rows[\"o:gender\"] = targets[\"o:gender\"]\n",
    "\n",
    "\n",
    "min_max = pd.DataFrame({\"min\": rows.min(), \"max\": rows.max()})\n",
    "min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o:Arterial_BE\n",
      "o:Arterial_lactate\n",
      "o:Arterial_pH\n",
      "o:BUN\n",
      "o:Calcium\n",
      "o:Chloride\n",
      "o:Creatinine\n",
      "o:DiaBP\n",
      "o:FiO2_1\n",
      "o:GCS\n",
      "o:Glucose\n",
      "o:HCO3\n",
      "o:HR\n",
      "o:Hb\n",
      "o:INR\n",
      "o:Magnesium\n",
      "o:MeanBP\n",
      "o:PT\n",
      "o:PTT\n",
      "o:Platelets_count\n",
      "o:Potassium\n",
      "o:RR\n",
      "o:SGOT\n",
      "o:SGPT\n",
      "o:SIRS\n",
      "o:SOFA\n",
      "o:Shock_Index\n",
      "o:Sodium\n",
      "o:SpO2\n",
      "o:SysBP\n",
      "o:Temp_C\n",
      "o:Total_bili\n",
      "o:WBC_count\n",
      "o:Weight_kg\n",
      "o:input_4hourly\n",
      "o:max_dose_vaso\n",
      "o:mechvent\n",
      "o:paCO2\n",
      "o:paO2\n",
      "sBert:0\n",
      "sBert:1\n",
      "sBert:2\n",
      "sBert:3\n",
      "sBert:4\n",
      "sBert:5\n",
      "sBert:6\n",
      "sBert:7\n",
      "sBert:8\n",
      "sBert:9\n",
      "sBert:10\n",
      "sBert:11\n",
      "sBert:12\n",
      "sBert:13\n",
      "sBert:14\n",
      "sBert:15\n",
      "sBert:16\n",
      "sBert:17\n",
      "sBert:18\n",
      "sBert:19\n",
      "sBert:20\n",
      "sBert:21\n",
      "sBert:22\n",
      "sBert:23\n",
      "sBert:24\n",
      "sBert:25\n",
      "sBert:26\n",
      "sBert:27\n",
      "sBert:28\n",
      "sBert:29\n",
      "sBert:30\n",
      "sBert:31\n",
      "m:icustayid\n",
      "sepsis_label\n",
      "hour\n",
      "o:age\n",
      "o:gender\n"
     ]
    }
   ],
   "source": [
    "for i in rows.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>o:Arterial_BE</th>\n",
       "      <td>4.469890e-18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o:Arterial_lactate</th>\n",
       "      <td>-2.599263e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o:Arterial_pH</th>\n",
       "      <td>2.502550e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o:BUN</th>\n",
       "      <td>2.199586e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o:Calcium</th>\n",
       "      <td>-8.757626e-18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sBert:5</th>\n",
       "      <td>6.894529e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sBert:6</th>\n",
       "      <td>1.767813e-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sBert:7</th>\n",
       "      <td>7.081313e-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sBert:8</th>\n",
       "      <td>-8.126365e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sBert:9</th>\n",
       "      <td>-2.498749e-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean  std\n",
       "variable                             \n",
       "o:Arterial_BE       4.469890e-18  1.0\n",
       "o:Arterial_lactate -2.599263e-17  1.0\n",
       "o:Arterial_pH       2.502550e-17  1.0\n",
       "o:BUN               2.199586e-17  1.0\n",
       "o:Calcium          -8.757626e-18  1.0\n",
       "...                          ...  ...\n",
       "sBert:5             6.894529e-17  1.0\n",
       "sBert:6             1.767813e-16  1.0\n",
       "sBert:7             7.081313e-16  1.0\n",
       "sBert:8            -8.126365e-17  1.0\n",
       "sBert:9            -2.498749e-16  1.0\n",
       "\n",
       "[73 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strats_data = (rows.melt(id_vars=['hour', 'm:icustayid', 'sepsis_label'], var_name='variable',value_name='value', ignore_index=False)\n",
    "       .sort_values(['m:icustayid', 'hour'])\n",
    "       .reset_index(drop=True))\n",
    "mean_stds = strats_data.groupby('variable').agg({'value':['mean', 'std']})\n",
    "mean_stds.columns = [col[1] for col in mean_stds.columns]\n",
    "mean_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>m:icustayid</th>\n",
       "      <th>sepsis_label</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>ts_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>200003</td>\n",
       "      <td>1</td>\n",
       "      <td>o:Arterial_BE</td>\n",
       "      <td>1.071196</td>\n",
       "      <td>4.469890e-18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>200003</td>\n",
       "      <td>1</td>\n",
       "      <td>o:Arterial_lactate</td>\n",
       "      <td>-0.560318</td>\n",
       "      <td>-2.599263e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>200003</td>\n",
       "      <td>1</td>\n",
       "      <td>o:Arterial_pH</td>\n",
       "      <td>1.078780</td>\n",
       "      <td>2.502550e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>200003</td>\n",
       "      <td>1</td>\n",
       "      <td>o:BUN</td>\n",
       "      <td>-0.381145</td>\n",
       "      <td>2.199586e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>200003</td>\n",
       "      <td>1</td>\n",
       "      <td>o:Calcium</td>\n",
       "      <td>0.095615</td>\n",
       "      <td>-8.757626e-18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144405529</th>\n",
       "      <td>38.0</td>\n",
       "      <td>299999</td>\n",
       "      <td>0</td>\n",
       "      <td>sBert:29</td>\n",
       "      <td>0.391223</td>\n",
       "      <td>4.413519e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144405530</th>\n",
       "      <td>38.0</td>\n",
       "      <td>299999</td>\n",
       "      <td>0</td>\n",
       "      <td>sBert:30</td>\n",
       "      <td>-0.636355</td>\n",
       "      <td>5.293132e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144405531</th>\n",
       "      <td>38.0</td>\n",
       "      <td>299999</td>\n",
       "      <td>0</td>\n",
       "      <td>sBert:31</td>\n",
       "      <td>-0.439726</td>\n",
       "      <td>-2.048425e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144405532</th>\n",
       "      <td>38.0</td>\n",
       "      <td>299999</td>\n",
       "      <td>0</td>\n",
       "      <td>o:age</td>\n",
       "      <td>-0.849940</td>\n",
       "      <td>4.296106e-04</td>\n",
       "      <td>0.999406</td>\n",
       "      <td>41773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144405533</th>\n",
       "      <td>38.0</td>\n",
       "      <td>299999</td>\n",
       "      <td>0</td>\n",
       "      <td>o:gender</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-6.837219e-02</td>\n",
       "      <td>0.495303</td>\n",
       "      <td>41773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144405534 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hour  m:icustayid  sepsis_label            variable     value  \\\n",
       "0           0.0       200003             1       o:Arterial_BE  1.071196   \n",
       "1           0.0       200003             1  o:Arterial_lactate -0.560318   \n",
       "2           0.0       200003             1       o:Arterial_pH  1.078780   \n",
       "3           0.0       200003             1               o:BUN -0.381145   \n",
       "4           0.0       200003             1           o:Calcium  0.095615   \n",
       "...         ...          ...           ...                 ...       ...   \n",
       "144405529  38.0       299999             0            sBert:29  0.391223   \n",
       "144405530  38.0       299999             0            sBert:30 -0.636355   \n",
       "144405531  38.0       299999             0            sBert:31 -0.439726   \n",
       "144405532  38.0       299999             0               o:age -0.849940   \n",
       "144405533  38.0       299999             0            o:gender -0.500000   \n",
       "\n",
       "                   mean       std  ts_ind  \n",
       "0          4.469890e-18  1.000000       0  \n",
       "1         -2.599263e-17  1.000000       0  \n",
       "2          2.502550e-17  1.000000       0  \n",
       "3          2.199586e-17  1.000000       0  \n",
       "4         -8.757626e-18  1.000000       0  \n",
       "...                 ...       ...     ...  \n",
       "144405529  4.413519e-17  1.000000   41773  \n",
       "144405530  5.293132e-16  1.000000   41773  \n",
       "144405531 -2.048425e-16  1.000000   41773  \n",
       "144405532  4.296106e-04  0.999406   41773  \n",
       "144405533 -6.837219e-02  0.495303   41773  \n",
       "\n",
       "[144405534 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strats_data = strats_data.merge(mean_stds.reset_index(), on='variable', how='left')\n",
    "strats_data['ts_ind'] = strats_data.groupby(['m:icustayid']).ngroup()\n",
    "strats_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m:icustayid</th>\n",
       "      <th>sepsis_label</th>\n",
       "      <th>hour</th>\n",
       "      <th>o:age</th>\n",
       "      <th>o:gender</th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202134</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.494919</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>889</td>\n",
       "      <td>202134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>293407</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462969</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>39010</td>\n",
       "      <td>293407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469747</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9303</td>\n",
       "      <td>222148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>293525</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.866752</td>\n",
       "      <td>0.5</td>\n",
       "      <td>39051</td>\n",
       "      <td>293525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>246035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.879073</td>\n",
       "      <td>0.5</td>\n",
       "      <td>19215</td>\n",
       "      <td>246035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41769</th>\n",
       "      <td>280210</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>33538</td>\n",
       "      <td>280210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41770</th>\n",
       "      <td>216102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.151317</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6788</td>\n",
       "      <td>216102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41771</th>\n",
       "      <td>252411</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.746649</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21926</td>\n",
       "      <td>252411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41772</th>\n",
       "      <td>202836</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.851900</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1192</td>\n",
       "      <td>202836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41773</th>\n",
       "      <td>234115</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.053482</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>14269</td>\n",
       "      <td>234115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41774 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       m:icustayid  sepsis_label  hour     o:age  o:gender  ts_ind  SUBJECT_ID\n",
       "0           202134             1   0.0 -0.494919      -0.5     889      202134\n",
       "1           293407             1   0.0  0.462969      -0.5   39010      293407\n",
       "2           222148             0   0.0  0.469747       0.5    9303      222148\n",
       "3           293525             1   0.0 -1.866752       0.5   39051      293525\n",
       "4           246035             0   0.0 -0.879073       0.5   19215      246035\n",
       "...            ...           ...   ...       ...       ...     ...         ...\n",
       "41769       280210             1   0.0  0.001012      -0.5   33538      280210\n",
       "41770       216102             0   0.0 -0.151317       0.5    6788      216102\n",
       "41771       252411             0   0.0 -0.746649       0.5   21926      252411\n",
       "41772       202836             0   0.0  0.851900      -0.5    1192      202836\n",
       "41773       234115             1   0.0 -0.053482      -0.5   14269      234115\n",
       "\n",
       "[41774 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build oc\n",
    "oc = targets.groupby('m:icustayid').head(1).reset_index(drop=True)\n",
    "oc['ts_ind'] = oc.groupby(['m:icustayid']).ngroup()\n",
    "oc[\"SUBJECT_ID\"] = oc[\"m:icustayid\"]\n",
    "#targets_oc = targets.loc[targets.SUBJECT_ID.isin(train_val_IDs)]\n",
    "oc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = oc['SUBJECT_ID'].tolist()\n",
    "labels = oc['sepsis_label'].tolist()\n",
    "\n",
    "new_patient_ids = []\n",
    "new_labels = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "  # print(i)\n",
    "  if ids[i] in new_patient_ids:\n",
    "    continue\n",
    "  else:\n",
    "    new_patient_ids.append(ids[i])\n",
    "    new_labels.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 23801, 1: 17973})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# data ratio\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26735\n",
      "26735\n",
      "8355\n",
      "8355\n",
      "6684\n",
      "6684\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>hour</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>o:Arterial_BE</td>\n",
       "      <td>1.071196</td>\n",
       "      <td>4.469890e-18</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>o:Arterial_lactate</td>\n",
       "      <td>-0.560318</td>\n",
       "      <td>-2.599263e-17</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>o:Arterial_pH</td>\n",
       "      <td>1.078780</td>\n",
       "      <td>2.502550e-17</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>o:BUN</td>\n",
       "      <td>-0.381145</td>\n",
       "      <td>2.199586e-17</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>o:Calcium</td>\n",
       "      <td>0.095615</td>\n",
       "      <td>-8.757626e-18</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144405529</th>\n",
       "      <td>41773</td>\n",
       "      <td>38.0</td>\n",
       "      <td>sBert:29</td>\n",
       "      <td>0.391223</td>\n",
       "      <td>4.413519e-17</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144405530</th>\n",
       "      <td>41773</td>\n",
       "      <td>38.0</td>\n",
       "      <td>sBert:30</td>\n",
       "      <td>-0.636355</td>\n",
       "      <td>5.293132e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144405531</th>\n",
       "      <td>41773</td>\n",
       "      <td>38.0</td>\n",
       "      <td>sBert:31</td>\n",
       "      <td>-0.439726</td>\n",
       "      <td>-2.048425e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144405532</th>\n",
       "      <td>41773</td>\n",
       "      <td>38.0</td>\n",
       "      <td>o:age</td>\n",
       "      <td>-0.849940</td>\n",
       "      <td>4.296106e-04</td>\n",
       "      <td>0.999406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144405533</th>\n",
       "      <td>41773</td>\n",
       "      <td>38.0</td>\n",
       "      <td>o:gender</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-6.837219e-02</td>\n",
       "      <td>0.495303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144405534 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ts_ind  hour            variable     value          mean       std\n",
       "0               0   0.0       o:Arterial_BE  1.071196  4.469890e-18  1.000000\n",
       "1               0   0.0  o:Arterial_lactate -0.560318 -2.599263e-17  1.000000\n",
       "2               0   0.0       o:Arterial_pH  1.078780  2.502550e-17  1.000000\n",
       "3               0   0.0               o:BUN -0.381145  2.199586e-17  1.000000\n",
       "4               0   0.0           o:Calcium  0.095615 -8.757626e-18  1.000000\n",
       "...           ...   ...                 ...       ...           ...       ...\n",
       "144405529   41773  38.0            sBert:29  0.391223  4.413519e-17  1.000000\n",
       "144405530   41773  38.0            sBert:30 -0.636355  5.293132e-16  1.000000\n",
       "144405531   41773  38.0            sBert:31 -0.439726 -2.048425e-16  1.000000\n",
       "144405532   41773  38.0               o:age -0.849940  4.296106e-04  0.999406\n",
       "144405533   41773  38.0            o:gender -0.500000 -6.837219e-02  0.495303\n",
       "\n",
       "[144405534 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, x_test, y, y_test = train_test_split(new_patient_ids, new_labels, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "# train\n",
    "train_ind = []\n",
    "\n",
    "ts_ind = oc['ts_ind'].tolist()\n",
    "# ids = ids\n",
    "\n",
    "for i in range(len(ts_ind)):\n",
    "  if ids[i] in x_train:\n",
    "    train_ind.append(ts_ind[i])\n",
    "\n",
    "# number of train patients\n",
    "print(len(x_train))\n",
    "# number of train instances\n",
    "print(len(train_ind))\n",
    "# to np.array\n",
    "train_ind = np.array(train_ind)\n",
    "\n",
    "test_ind = []\n",
    "\n",
    "for i in range(len(ts_ind)):\n",
    "  if ids[i] in x_test:\n",
    "    test_ind.append(ts_ind[i])\n",
    "\n",
    "# number of test patients\n",
    "print(len(x_test))\n",
    "# number of test instances\n",
    "print(len(test_ind))\n",
    "# to np.array\n",
    "test_ind = np.array(test_ind)\n",
    "\n",
    "valid_ind = []\n",
    "\n",
    "for i in range(len(ts_ind)):\n",
    "  if ids[i] in x_val:\n",
    "    valid_ind.append(ts_ind[i])\n",
    "\n",
    "# number of test patients\n",
    "print(len(x_val))\n",
    "# number of test instances\n",
    "print(len(valid_ind))\n",
    "# to np.array\n",
    "valid_ind = np.array(valid_ind)\n",
    "\n",
    "strats_data = strats_data.drop(columns=\"sepsis_label\")\n",
    "strats_data = strats_data.dropna()\n",
    "\n",
    "data = strats_data[[\"ts_ind\", \"hour\",\"variable\", \"value\", \"mean\", \"std\"]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_window = 1 # hours that the output vector represents. 1 because i want to learn to predict 1 hour many times\n",
    "obs_windows = [16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3160776it [00:01, 1709811.20it/s]\n",
      "100%|██████████| 1/1 [00:18<00:00, 18.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# Remove test patients.\n",
    "data = data.merge(oc[['ts_ind', 'SUBJECT_ID']], on='ts_ind', how='left')\n",
    "test_sub = oc.loc[oc.ts_ind.isin(test_ind)].SUBJECT_ID.unique()\n",
    "data = data.loc[~data.SUBJECT_ID.isin(test_sub)]\n",
    "oc = oc.loc[~oc.SUBJECT_ID.isin(test_sub)]\n",
    "data.drop(columns=['SUBJECT_ID'], inplace=True)\n",
    "# Fix age.\n",
    "#data.loc[(data.variable=='o:age')&(data.value>200), 'value'] = 91.4\n",
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['o:age', 'o:gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "N = data.ts_ind.max()+1\n",
    "demo = np.zeros((N, D))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[row.ts_ind, static_var_to_ind[row.variable]] = row.value\n",
    "# Normalize static data.\n",
    "#means = demo.mean(axis=0, keepdims=True)\n",
    "#stds = demo.std(axis=0, keepdims=True)\n",
    "#stds = (stds==0)*1 + (stds!=0)*stds\n",
    "#demo = (demo-means)/stds\n",
    "# Get variable indices.\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Find max_len.\n",
    "fore_max_len = 880\n",
    "# Get forecast inputs and outputs.\n",
    "fore_times_ip = []\n",
    "fore_values_ip = []\n",
    "fore_varis_ip = []\n",
    "fore_op = []\n",
    "fore_inds = []\n",
    "def f(x):\n",
    "    mask = [0 for i in range(V)]\n",
    "    values = [0 for i in range(V)]\n",
    "    for vv in x:\n",
    "        v = int(vv[0])-1\n",
    "        mask[v] = 1\n",
    "        values[v] = vv[1]\n",
    "    return values+mask\n",
    "def pad(x):\n",
    "    return x+[0]*(fore_max_len-len(x))\n",
    "for w in tqdm(obs_windows):\n",
    "    pred_data = data.loc[(data.hour>=w)&(data.hour<=w+pred_window)]\n",
    "    pred_data = pred_data.groupby(['ts_ind', 'vind']).agg({'value':'first'}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data[['vind', 'value']].values.tolist()\n",
    "    pred_data = pred_data.groupby('ts_ind').agg({'vind_value':list}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data['vind_value'].apply(f)\n",
    "    obs_data = data.loc[(data.hour<w)&(data.hour>=w-24)]\n",
    "    obs_data = obs_data.loc[obs_data.ts_ind.isin(pred_data.ts_ind)]\n",
    "    obs_data = obs_data.groupby('ts_ind').head(fore_max_len)\n",
    "    obs_data = obs_data.groupby('ts_ind').agg({'vind':list, 'hour':list, 'value':list}).reset_index()\n",
    "    obs_data = obs_data.merge(pred_data, on='ts_ind')\n",
    "    for col in ['vind', 'hour', 'value']:\n",
    "        obs_data[col] = obs_data[col].apply(pad)\n",
    "    fore_op.append(np.array(list(obs_data.vind_value)))\n",
    "    fore_inds.append(np.array(list(obs_data.ts_ind)))\n",
    "    fore_times_ip.append(np.array(list(obs_data.hour)))\n",
    "    fore_values_ip.append(np.array(list(obs_data.value)))\n",
    "    fore_varis_ip.append(np.array(list(obs_data.vind)))\n",
    "del data\n",
    "fore_times_ip = np.concatenate(fore_times_ip, axis=0)\n",
    "fore_values_ip = np.concatenate(fore_values_ip, axis=0)\n",
    "fore_varis_ip = np.concatenate(fore_varis_ip, axis=0)\n",
    "fore_op = np.concatenate(fore_op, axis=0)\n",
    "fore_inds = np.concatenate(fore_inds, axis=0)\n",
    "fore_demo = demo[fore_inds]\n",
    "# Get train and valid ts_ind for forecast task.\n",
    "train_sub = oc.loc[oc.ts_ind.isin(train_ind)].SUBJECT_ID.unique()\n",
    "valid_sub = oc.loc[oc.ts_ind.isin(valid_ind)].SUBJECT_ID.unique()\n",
    "rem_sub = oc.loc[~oc.SUBJECT_ID.isin(np.concatenate((train_ind, valid_ind)))].SUBJECT_ID.unique()\n",
    "bp = int(0.8*len(rem_sub))\n",
    "train_sub = np.concatenate((train_sub, rem_sub[:bp]))\n",
    "valid_sub = np.concatenate((valid_sub, rem_sub[bp:]))\n",
    "train_ind = oc.loc[oc.SUBJECT_ID.isin(train_sub)].ts_ind.unique() # Add remaining ts_ind s of train subjects.\n",
    "valid_ind = oc.loc[oc.SUBJECT_ID.isin(valid_sub)].ts_ind.unique() # Add remaining ts_ind s of train subjects.\n",
    "# Generate 3 sets of inputs and outputs.\n",
    "train_ind = np.argwhere(np.in1d(fore_inds, train_ind)).flatten()\n",
    "valid_ind = np.argwhere(np.in1d(fore_inds, valid_ind)).flatten()\n",
    "fore_train_ip = [ip[train_ind] for ip in [fore_demo, fore_times_ip, fore_values_ip, fore_varis_ip]]\n",
    "fore_valid_ip = [ip[valid_ind] for ip in [fore_demo, fore_times_ip, fore_values_ip, fore_varis_ip]]\n",
    "del fore_times_ip, fore_values_ip, fore_varis_ip, demo, fore_demo\n",
    "fore_train_op = fore_op[train_ind]\n",
    "fore_valid_op = fore_op[valid_ind]\n",
    "del fore_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26735\n",
      "26735\n",
      "8355\n",
      "8355\n",
      "6684\n",
      "6684\n"
     ]
    }
   ],
   "source": [
    "data = strats_data[[\"ts_ind\", \"hour\",\"variable\", \"value\", \"mean\", \"std\"]]\n",
    "oc = targets.groupby('m:icustayid').head(1).reset_index(drop=True)\n",
    "oc['ts_ind'] = oc.groupby(['m:icustayid']).ngroup()\n",
    "oc[\"SUBJECT_ID\"] = oc[\"m:icustayid\"]\n",
    "#targets_oc = targets.loc[targets.SUBJECT_ID.isin(train_val_IDs)]\n",
    "data = data.dropna()\n",
    "oc = oc.dropna()\n",
    "\n",
    "# train\n",
    "train_ind = []\n",
    "ts_ind = oc['ts_ind'].tolist()\n",
    "# ids = ids\n",
    "for i in range(len(ts_ind)):\n",
    "  if ids[i] in x_train:\n",
    "    train_ind.append(ts_ind[i])\n",
    "# number of train patients\n",
    "print(len(x_train))\n",
    "# number of train instances\n",
    "print(len(train_ind))\n",
    "# to np.array\n",
    "train_ind = np.array(train_ind)\n",
    "test_ind = []\n",
    "for i in range(len(ts_ind)):\n",
    "  if ids[i] in x_test:\n",
    "    test_ind.append(ts_ind[i])\n",
    "# number of test patients\n",
    "print(len(x_test))\n",
    "# number of test instances\n",
    "print(len(test_ind))\n",
    "# to np.array\n",
    "test_ind = np.array(test_ind)\n",
    "valid_ind = []\n",
    "for i in range(len(ts_ind)):\n",
    "  if ids[i] in x_val:\n",
    "    valid_ind.append(ts_ind[i])\n",
    "# number of test patients\n",
    "print(len(x_val))\n",
    "# number of test instances\n",
    "print(len(valid_ind))\n",
    "# to np.array\n",
    "valid_ind = np.array(valid_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1707398it [00:00, 1732178.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len 880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35635143it [00:27, 1298101.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Read data.\n",
    "# data_path = './../mimic_iii_preprocessed.pkl'\n",
    "# data, oc, train_ind, valid_ind, test_ind = pickle.load(open(data_path, 'rb'))\n",
    "# Filter labeled data in first 24h.\n",
    "data = data.loc[data.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "data = data.loc[(data.hour>=0)&(data.hour<=24)]\n",
    "oc = oc.loc[oc.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "# Fix age.\n",
    "#data.loc[(data.variable=='o:age')&(data.value>200), 'value'] = 91.4\n",
    "# Get y and N.\n",
    "y = np.array(oc.sort_values(by='ts_ind')['sepsis_label']).astype('float32')\n",
    "N = data.ts_ind.max() + 1\n",
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['o:age', 'o:gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "demo = np.zeros((N, D))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[row.ts_ind, static_var_to_ind[row.variable]] = row.value\n",
    "# Normalize static data.\n",
    "#means = demo.mean(axis=0, keepdims=True)\n",
    "#stds = demo.std(axis=0, keepdims=True)\n",
    "#stds = (stds==0)*1 + (stds!=0)*stds\n",
    "#demo = (demo-means)/stds\n",
    "# Trim to max len.\n",
    "#data = data.sample(frac=1)\n",
    "data = data.groupby('ts_ind').head(880)\n",
    "# Get N, V, var_to_ind.\n",
    "N = data.ts_ind.max() + 1\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Add obs index.\n",
    "data = data.sort_values(by=['ts_ind']).reset_index(drop=True)\n",
    "data = data.reset_index().rename(columns={'index':'obs_ind'})\n",
    "data = data.merge(data.groupby('ts_ind').agg({'obs_ind':'min'}).reset_index().rename(columns={ \\\n",
    "                                                            'obs_ind':'first_obs_ind'}), on='ts_ind')\n",
    "data['obs_ind'] = data['obs_ind'] - data['first_obs_ind']\n",
    "# Find max_len.\n",
    "max_len = data.obs_ind.max()+1\n",
    "print ('max_len', max_len)\n",
    "# Generate times_ip and values_ip matrices.\n",
    "times_inp = np.zeros((N, max_len), dtype='float32')\n",
    "values_inp = np.zeros((N, max_len), dtype='float32')\n",
    "varis_inp = np.zeros((N, max_len), dtype='int32')\n",
    "for row in tqdm(data.itertuples()):\n",
    "    ts_ind = row.ts_ind\n",
    "    l = row.obs_ind\n",
    "    times_inp[ts_ind, l] = row.hour\n",
    "    values_inp[ts_ind, l] = row.value\n",
    "    varis_inp[ts_ind, l] = row.vind\n",
    "data.drop(columns=['obs_ind', 'first_obs_ind'], inplace=True)\n",
    "# Generate 3 sets of inputs and outputs.\n",
    "train_ip = [ip[train_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "valid_ip = [ip[valid_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "test_ip = [ip[test_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "del times_inp, values_inp, varis_inp\n",
    "train_op = y[train_ind]\n",
    "valid_op = y[valid_ind]\n",
    "test_op = y[test_ind]\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "def get_res(y_true, y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    minrp = np.minimum(precision, recall).max()\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    return [roc_auc, pr_auc, minrp]\n",
    "\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=[0,1], y=train_op)\n",
    "def mortality_loss(y_true, y_pred):\n",
    "    sample_weights = (1-y_true)*class_weights[0] + y_true*class_weights[1]\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "    return K.mean(sample_weights*bce, axis=-1)\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "# var_weights = np.sum(fore_train_op[:, V:], axis=0)\n",
    "# var_weights[var_weights==0] = var_weights.max()\n",
    "# var_weights = var_weights.max()/var_weights\n",
    "# var_weights = var_weights.reshape((1, V))\n",
    "def forecast_loss(y_true, y_pred):\n",
    "    return K.sum(y_true[:,V:]*(y_true[:,:V]-y_pred)**2, axis=-1)\n",
    "\n",
    "def mape_fore(y_true, y_pred):\n",
    "    truth = y_true[:,V:]\n",
    "    pred = y_pred\n",
    "    return mape(truth, pred)\n",
    "\n",
    "                                          \n",
    "def get_min_loss(weight):\n",
    "    def min_loss(y_true, y_pred):\n",
    "        return weight*y_pred\n",
    "    return min_loss\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def __init__(self, validation_data, batch_size):\n",
    "        self.val_x, self.val_y = validation_data\n",
    "        self.batch_size = batch_size\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.val_x, verbose=0, batch_size=self.batch_size)\n",
    "        if type(y_pred)==type([]):\n",
    "            y_pred = y_pred[0]\n",
    "        precision, recall, thresholds = precision_recall_curve(self.val_y, y_pred)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        roc_auc = roc_auc_score(self.val_y, y_pred)\n",
    "        logs['custom_metric'] = pr_auc + roc_auc\n",
    "        print ('val_aucs:', pr_auc, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Embedding, Activation, Dropout, Softmax, Layer, InputSpec, Input, Dense, Lambda, TimeDistributed, Concatenate, Add\n",
    "from tensorflow.keras import initializers, regularizers, constraints, Model\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow import nn\n",
    "import smart_cond_mod as sc\n",
    "\n",
    "\n",
    "class CVE(Layer):\n",
    "    def __init__(self, hid_units, output_dim):\n",
    "        self.hid_units = hid_units\n",
    "        self.output_dim = output_dim\n",
    "        super(CVE, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W1 = self.add_weight(name='CVE_W1',\n",
    "                            shape=(1, self.hid_units),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        self.b1 = self.add_weight(name='CVE_b1',\n",
    "                            shape=(self.hid_units,),\n",
    "                            initializer='zeros',\n",
    "                            trainable=True)\n",
    "        self.W2 = self.add_weight(name='CVE_W2',\n",
    "                            shape=(self.hid_units, self.output_dim),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        super(CVE, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = K.expand_dims(x, axis=-1)\n",
    "        x = K.dot(K.tanh(K.bias_add(K.dot(x, self.W1), self.b1)), self.W2)\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape + (self.output_dim,)\n",
    "\n",
    "\n",
    "class Attention(Layer):\n",
    "\n",
    "    def __init__(self, hid_dim):\n",
    "        self.hid_dim = hid_dim\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        self.W = self.add_weight(shape=(d, self.hid_dim), name='Att_W',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hid_dim,), name='Att_b',\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        self.u = self.add_weight(shape=(self.hid_dim,1), name='Att_u',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask, mask_value=-1e30):\n",
    "        attn_weights = K.dot(K.tanh(K.bias_add(K.dot(x,self.W), self.b)), self.u)\n",
    "        mask = K.expand_dims(mask, axis=-1)\n",
    "        attn_weights = mask*attn_weights + (1-mask)*mask_value\n",
    "        attn_weights = K.softmax(attn_weights, axis=-2)\n",
    "        return attn_weights\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1] + (1,)\n",
    "\n",
    "\n",
    "class Transformer(Layer):\n",
    "\n",
    "    def __init__(self, N=2, h=8, dk=None, dv=None, dff=None, dropout=0):\n",
    "        self.N, self.h, self.dk, self.dv, self.dff, self.dropout = N, h, dk, dv, dff, dropout\n",
    "        self.epsilon = K.epsilon() * K.epsilon()\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        if self.dk==None:\n",
    "            self.dk = d//self.h\n",
    "        if self.dv==None:\n",
    "            self.dv = d//self.h\n",
    "        if self.dff==None:\n",
    "            self.dff = 2*d\n",
    "        #self.Wq = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wq',\n",
    "         #                        initializer='glorot_uniform', trainable=True)\n",
    "        #self.Wk = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wk',\n",
    "         #                        initializer='glorot_uniform', trainable=True)\n",
    "        #self.Wv = self.add_weight(shape=(self.N, self.h, d, self.dv), name='Wv',\n",
    "         #                        initializer='glorot_uniform', trainable=True)\n",
    "        #self.Wo = self.add_weight(shape=(self.N, self.dv*self.h, d), name='Wo',\n",
    "         #                        initializer='glorot_uniform', trainable=True)\n",
    "        self.W1 = self.add_weight(shape=(self.N, d, self.dff), name='W1',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b1 = self.add_weight(shape=(self.N, self.dff), name='b1',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.W2 = self.add_weight(shape=(self.N, self.dff, d), name='W2',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b2 = self.add_weight(shape=(self.N, d), name='b2',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.gamma = self.add_weight(shape=(2*self.N,), name='gamma',\n",
    "                                 initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(shape=(2*self.N,), name='beta',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        super(Transformer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask, mask_value=-1e-30):\n",
    "        mask = K.expand_dims(mask, axis=-2)\n",
    "        for i in range(self.N):\n",
    "            # MHA\n",
    "            mha_ops = []\n",
    "            \"\"\"for j in range(self.h):\n",
    "                q = K.dot(x, self.Wq[i,j,:,:])\n",
    "                k = K.permute_dimensions(K.dot(x, self.Wk[i,j,:,:]), (0,2,1))\n",
    "                v = K.dot(x, self.Wv[i,j,:,:])\n",
    "                A = K.batch_dot(q,k)\n",
    "                # Mask unobserved steps.\n",
    "                A = mask*A + (1-mask)*mask_value\n",
    "                # Mask for attention dropout.\n",
    "                def dropped_A():\n",
    "                    dp_mask = K.cast((K.random_uniform(shape=array_ops.shape(A))>=self.dropout), K.floatx())\n",
    "                    return A*dp_mask + (1-dp_mask)*mask_value\n",
    "                A = sc.smart_cond(K.learning_phase(), dropped_A, lambda: array_ops.identity(A))\n",
    "                A = K.softmax(A, axis=-1)\n",
    "                print(A.shape) # 880,880\"\"\"\n",
    "            x_complex = tf.cast(x, tf.complex64)\n",
    "            fft_hidden = tf.signal.fft(x_complex)\n",
    "            fft_seq = tf.math.real(tf.signal.fft(fft_hidden))\n",
    "            #print(fft_seq.shape)\n",
    "                #mha_ops.append(fft_seq) #jeder teil von mha_ops hat shape 880,12 -> 880,48\n",
    "            #print(len(mha_ops))\n",
    "            #conc = K.concatenate(mha_ops, axis=-1)\n",
    "            #conc (None, 880, 48)\n",
    "            #proj = K.dot(conc, self.Wo[i,:,:])\n",
    "            #proj (None, 880, 50)\n",
    "            # Dropout.\n",
    "            proj = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(fft_seq, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(fft_seq))\n",
    "            # Add & LN\n",
    "            #print(x.shape, proj.shape) #orig x 880,50 proj 880,50\n",
    "            x = x+proj\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i] + self.beta[2*i]\n",
    "            # FFN\n",
    "            ffn_op = K.bias_add(K.dot(K.relu(K.bias_add(K.dot(x, self.W1[i,:,:]), self.b1[i,:])),\n",
    "                           self.W2[i,:,:]), self.b2[i,:,])\n",
    "            # Dropout.\n",
    "            ffn_op = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(ffn_op, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(ffn_op))\n",
    "            # Add & LN\n",
    "            x = x+ffn_op\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i+1] + self.beta[2*i+1]\n",
    "        return x\n",
    "\n",
    "    \"\"\"def call(self, x, mask, mask_value=-1e-30):\n",
    "        print(x.shape)\n",
    "        tf.math.real(tf.signal.fft2d(x))\n",
    "        fft_hidden = torch.fft.fft(x, dim=2)\n",
    "        fft_seq = torch.fft.fft(fft_hidden, dim=0)\n",
    "        return torch.real(fft_seq)\"\"\"\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "def build_strats(D, max_len, V, d, N, he, dropout, forecast=False):\n",
    "    demo = Input(shape=(D,))\n",
    "    demo_enc = Dense(2*d, activation='tanh')(demo)\n",
    "    demo_enc = Dense(d, activation='tanh')(demo_enc)\n",
    "    varis = Input(shape=(max_len,))\n",
    "    values = Input(shape=(max_len,))\n",
    "    times = Input(shape=(max_len,))\n",
    "    varis_emb = Embedding(V+1, d)(varis)\n",
    "    cve_units = int(np.sqrt(d))\n",
    "    values_emb = CVE(cve_units, d)(values)\n",
    "    times_emb = CVE(cve_units, d)(times)\n",
    "    comb_emb = Add()([varis_emb, values_emb, times_emb]) # b, L, d\n",
    "#     demo_enc = Lambda(lambda x:K.expand_dims(x, axis=-2))(demo_enc) # b, 1, d\n",
    "#     comb_emb = Concatenate(axis=-2)([demo_enc, comb_emb]) # b, L+1, d\n",
    "    mask = Lambda(lambda x:K.clip(x,0,1))(varis) # b, L\n",
    "#     mask = Lambda(lambda x:K.concatenate((K.ones_like(x)[:,0:1], x), axis=-1))(mask) # b, L+1\n",
    "    cont_emb = Transformer(N, he, dk=None, dv=None, dff=None, dropout=dropout)(comb_emb, mask=mask)\n",
    "    attn_weights = Attention(2*d)(cont_emb, mask=mask)\n",
    "    fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([cont_emb, attn_weights])\n",
    "    #cont_emb_complex = tf.cast(cont_emb, tf.complex64)\n",
    "    #fourier = tf.math.real(tf.signal.fft2d(cont_emb_complex)) \n",
    "    #fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([cont_emb, fourier])\n",
    "    conc = Concatenate(axis=-1)([fused_emb, demo_enc])\n",
    "    fore_op = Dense(V)(conc)\n",
    "    op = Dense(1, activation='sigmoid')(fore_op)\n",
    "    model = Model([demo, times, values, varis], op)\n",
    "    if forecast:\n",
    "        fore_model = Model([demo, times, values, varis], fore_op)\n",
    "        return [model, fore_model]\n",
    "    return model\n",
    "\n",
    "# To tune:\n",
    "# 1. Transformer parameters. (N, h, dropout)\n",
    "# 2. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 880)]                0         []                            \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)        [(None, 880)]                0         []                            \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, 880)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 880, 50)              3600      ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " cve_2 (CVE)                 (None, 880, 50)              364       ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " cve_3 (CVE)                 (None, 880, 50)              364       ['input_8[0][0]']             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 880, 50)              0         ['embedding_1[0][0]',         \n",
      "                                                                     'cve_2[0][0]',               \n",
      "                                                                     'cve_3[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)           (None, 880)                  0         ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " transformer_1 (Transformer  (None, 880, 50)              20308     ['add_1[0][0]',               \n",
      " )                                                                   'lambda_2[0][0]']            \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, 880, 1)               5200      ['transformer_1[0][0]',       \n",
      "                                                                     'lambda_2[0][0]']            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 100)                  300       ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)           (None, 50)                   0         ['transformer_1[0][0]',       \n",
      "                                                                     'attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 50)                   5050      ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 100)                  0         ['lambda_3[0][0]',            \n",
      " )                                                                   'dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 71)                   7171      ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 42357 (165.46 KB)\n",
      "Trainable params: 42357 (165.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/939 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      "2.121915: 100%|█████████▉| 938/939 [18:14<00:01,  1.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      "2.121894: 100%|██████████| 939/939 [18:16<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 200s 565ms/step - loss: 64.9375\n",
      "Epoch 0 loss 67.83506395337045 val loss 64.93750762939453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.071180:   5%|▍         | 43/939 [00:51<17:52,  1.20s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     ind \u001b[38;5;241m=\u001b[39m e_indices[start:start\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# pre-train data\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     e_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mfore_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mip\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfore_train_ip\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfore_train_op\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(e_loss\u001b[38;5;241m/\u001b[39m(start\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m     25\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m fore_model\u001b[38;5;241m.\u001b[39mevaluate(fore_valid_ip, fore_valid_op, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/microsoft_sepsis/lib/python3.9/site-packages/keras/src/engine/training.py:2684\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2680\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[1;32m   2681\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[1;32m   2682\u001b[0m     )\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[0;32m-> 2684\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2686\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/.conda/envs/microsoft_sepsis/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/microsoft_sepsis/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/microsoft_sepsis/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/microsoft_sepsis/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/microsoft_sepsis/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/microsoft_sepsis/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/.conda/envs/microsoft_sepsis/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/.conda/envs/microsoft_sepsis/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# lr, batch_size, samples_per_epoch, patience = 0.0005, 32, 102400, 5\n",
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 32, len(fore_train_op), 5\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "model, fore_model =  build_strats(D, fore_max_len, V, d, N, he, dropout, forecast=True)\n",
    "print(fore_model.summary())\n",
    "# fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "lossfunction = mape_fore #forecast_loss\n",
    "fore_model.compile(loss=lossfunction, optimizer=Adam(lr))\n",
    "\n",
    "# Pretrain fore_model.\n",
    "best_val_loss = np.inf\n",
    "N_fore = len(fore_train_op)\n",
    "fore_savepath = 'STraTSBERT_microsoft_data_Fourier.h5'\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for e in range(1000):\n",
    "    e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "    e_loss = 0\n",
    "    pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "    for start in pbar:\n",
    "        ind = e_indices[start:start+batch_size]\n",
    "        # pre-train data\n",
    "        e_loss += fore_model.train_on_batch([ip[ind] for ip in fore_train_ip], fore_train_op[ind])\n",
    "        pbar.set_description('%f'%(e_loss/(start+1)))\n",
    "    val_loss = fore_model.evaluate(fore_valid_ip, fore_valid_op, batch_size=batch_size, verbose=1)\n",
    "    print ('Epoch', e, 'loss', e_loss*batch_size/samples_per_epoch, 'val loss', val_loss)\n",
    "    train_losses.append(e_loss*batch_size/samples_per_epoch)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        fore_model.save_weights(fore_savepath)\n",
    "        best_epoch = e\n",
    "    if (e-best_epoch)>patience:\n",
    "        losses = pd.DataFrame({'train_loss': train_losses,'val_loss': val_losses})\n",
    "        losses.to_csv(f\"losses_{fore_savepath}.csv\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe bad performance expected cause bert embeddings not representable feature cause meant for downstream task, however sentence bert embeddings should represent text e.g. similar text similar embedding vector space, maybe thats why tfidf better. because it actually represents words e.g. probabilities of septic texts etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microsoft_sepsis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
