{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from SepsisCheck import sepsischeck_utilities_for_pkl as su\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "#from sklearn.metrics import average_precision_score as score\n",
    "from sklearn.metrics import classification_report as report\n",
    "from sklearn.metrics import roc_auc_score as auroc\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data, mean_stds, predictions, feature mappings\n",
    "path = \"../data/exp1/forecasting_exp1/mimic_iii_preprocessed_forecasting1.pkl\"\n",
    "preds = \"../data/exp1/forecasting_preds/forecasting_preds_test/content/4OBS12forecasting_preds_test.pkl\"\n",
    "data = pd.read_pickle(path)\n",
    "mean_stds = data[0][[\"variable\", \"mean\", \"std\"]].drop_duplicates(\"variable\")\n",
    "preds = pd.read_pickle(preds)\n",
    "map = list(preds[1].keys())\n",
    "#sort by ts_ind as that is how the results are sorted\n",
    "data2 = preds[0].sort_values(by=[\"ts_ind\"]).drop_duplicates(\"ts_ind\")\n",
    "data1 = data2\n",
    "IDs = list(data1[\"ts_ind\"].unique())\n",
    "#make ground truth for scoring, reset index after sorting. Index 0 -> ts_ind 0\n",
    "ground_truth = data1[[\"sepsis_label\", \"ts_ind\"]].reset_index(drop=True) #10498 labels sorted by ts_ind from low to high\n",
    "\n",
    "ground_truth = ground_truth.sort_values(by=[\"ts_ind\"])\n",
    "\n",
    "# df for holding results\n",
    "col = [\"experiment\", \"t_sepsis_mean\", \"24_hour_window\", \"t_ident\", \"AUROC\", \"AUROC_adj\",\"precision_raw\", \"precision_adj\", \"recall_raw\", \"recall_adj\", \"f1_raw\", \"f1_adj\", \"support\", \"support_adj\", \"cm\", \"cm_adj\"]\n",
    "df = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SepsisCheck_forecast import sepsischeck_utilities_for_pkl_forecast_pred_cutoff as scu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALP',\n",
       " 'ALT',\n",
       " 'AST',\n",
       " 'Albumin',\n",
       " 'Albumin 25%',\n",
       " 'Albumin 5%',\n",
       " 'Amiodarone',\n",
       " 'Anion Gap',\n",
       " 'Antibiotics',\n",
       " 'BUN',\n",
       " 'Base Excess',\n",
       " 'Basophils',\n",
       " 'Bicarbonate',\n",
       " 'Bilirubin (Direct)',\n",
       " 'Bilirubin (Indirect)',\n",
       " 'Bilirubin (Total)',\n",
       " 'Blood Culture',\n",
       " 'CRR',\n",
       " 'Calcium Free',\n",
       " 'Calcium Gluconate',\n",
       " 'Calcium Total',\n",
       " 'Cefazolin',\n",
       " 'Chest Tube',\n",
       " 'Chloride',\n",
       " 'Colloid',\n",
       " 'Creatinine Blood',\n",
       " 'Creatinine Urine',\n",
       " 'D5W',\n",
       " 'DBP',\n",
       " 'Dextrose Other',\n",
       " 'Dopamine',\n",
       " 'EBL',\n",
       " 'Emesis',\n",
       " 'Eoisinophils',\n",
       " 'Epinephrine',\n",
       " 'Famotidine',\n",
       " 'Fentanyl',\n",
       " 'FiO2',\n",
       " 'Fiber',\n",
       " 'Free Water',\n",
       " 'Fresh Frozen Plasma',\n",
       " 'Furosemide',\n",
       " 'GCS_eye',\n",
       " 'GCS_motor',\n",
       " 'GCS_verbal',\n",
       " 'GT Flush',\n",
       " 'Gastric',\n",
       " 'Gastric Meds',\n",
       " 'Glucose (Blood)',\n",
       " 'Glucose (Serum)',\n",
       " 'Glucose (Whole Blood)',\n",
       " 'HR',\n",
       " 'Half Normal Saline',\n",
       " 'Hct',\n",
       " 'Height',\n",
       " 'Heparin',\n",
       " 'Hgb',\n",
       " 'Hydralazine',\n",
       " 'Hydromorphone',\n",
       " 'INR',\n",
       " 'Insulin Humalog',\n",
       " 'Insulin NPH',\n",
       " 'Insulin Regular',\n",
       " 'Insulin largine',\n",
       " 'Intubated',\n",
       " 'Jackson-Pratt',\n",
       " 'KCl',\n",
       " 'KCl (Bolus)',\n",
       " 'LDH',\n",
       " 'Lactate',\n",
       " 'Lactated Ringers',\n",
       " 'Levofloxacin',\n",
       " 'Lorazepam',\n",
       " 'Lymphocytes',\n",
       " 'Lymphocytes (Absolute)',\n",
       " 'MBP',\n",
       " 'MCH',\n",
       " 'MCHC',\n",
       " 'MCV',\n",
       " 'Magnesium',\n",
       " 'Magnesium Sulfate (Bolus)',\n",
       " 'Magnesium Sulphate',\n",
       " 'Mechanically ventilated',\n",
       " 'Metoprolol',\n",
       " 'Midazolam',\n",
       " 'Milrinone',\n",
       " 'Monocytes',\n",
       " 'Morphine Sulfate',\n",
       " 'Neosynephrine',\n",
       " 'Neutrophils',\n",
       " 'Nitroglycerine',\n",
       " 'Nitroprusside',\n",
       " 'Norepinephrine',\n",
       " 'Normal Saline',\n",
       " 'O2 Saturation',\n",
       " 'OR/PACU Crystalloid',\n",
       " 'PCO2',\n",
       " 'PO intake',\n",
       " 'PO2',\n",
       " 'PT',\n",
       " 'PTT',\n",
       " 'Packed RBC',\n",
       " 'Pantoprazole',\n",
       " 'Phosphate',\n",
       " 'Piggyback',\n",
       " 'Piperacillin',\n",
       " 'Platelet Count',\n",
       " 'Potassium',\n",
       " 'Pre-admission Intake',\n",
       " 'Pre-admission Output',\n",
       " 'Propofol',\n",
       " 'RBC',\n",
       " 'RDW',\n",
       " 'RR',\n",
       " 'Residual',\n",
       " 'SBP',\n",
       " 'SG Urine',\n",
       " 'Sodium',\n",
       " 'Solution',\n",
       " 'Sterile Water',\n",
       " 'Stool',\n",
       " 'TPN',\n",
       " 'Temperature',\n",
       " 'Total CO2',\n",
       " 'Ultrafiltrate',\n",
       " 'Unknown',\n",
       " 'Urine',\n",
       " 'Vancomycin',\n",
       " 'Vasopressin',\n",
       " 'WBC',\n",
       " 'Weight',\n",
       " 'pH Blood',\n",
       " 'pH Urine',\n",
       " 'Dobutamine']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = []\n",
    "with open(\"./features.txt\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        feats.append(line)\n",
    "feats.append(\"Dobutamine\")\n",
    "IDs = scu.get_unique_admissions(preds)\n",
    "\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>hour</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>TABLE</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Age</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>64.053647</td>\n",
       "      <td>56.625699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Gender</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.438951</td>\n",
       "      <td>0.496263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>DBP</td>\n",
       "      <td>-0.517967</td>\n",
       "      <td>chart</td>\n",
       "      <td>59.766756</td>\n",
       "      <td>14.994705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>GCS_eye</td>\n",
       "      <td>0.679313</td>\n",
       "      <td>chart</td>\n",
       "      <td>3.274060</td>\n",
       "      <td>1.068640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>GCS_motor</td>\n",
       "      <td>0.515191</td>\n",
       "      <td>chart</td>\n",
       "      <td>5.271144</td>\n",
       "      <td>1.414728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81478793</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>MBP</td>\n",
       "      <td>0.195381</td>\n",
       "      <td>chart</td>\n",
       "      <td>78.552377</td>\n",
       "      <td>17.645628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81478794</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>O2 Saturation</td>\n",
       "      <td>-0.678068</td>\n",
       "      <td>chart</td>\n",
       "      <td>96.820961</td>\n",
       "      <td>4.160290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81478795</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>RR</td>\n",
       "      <td>0.179866</td>\n",
       "      <td>chart</td>\n",
       "      <td>26.278501</td>\n",
       "      <td>15.130729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81478796</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>SBP</td>\n",
       "      <td>-0.404061</td>\n",
       "      <td>chart</td>\n",
       "      <td>120.239648</td>\n",
       "      <td>25.341836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81478797</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>Urine</td>\n",
       "      <td>-0.242960</td>\n",
       "      <td>output</td>\n",
       "      <td>123.393012</td>\n",
       "      <td>137.442433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81478798 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ts_ind       hour       variable      value   TABLE        mean  \\\n",
       "0              0   0.000000            Age  66.000000     N/A   64.053647   \n",
       "1              0   0.000000         Gender   1.000000     N/A    0.438951   \n",
       "2              0   0.033333            DBP  -0.517967   chart   59.766756   \n",
       "3              0   0.033333        GCS_eye   0.679313   chart    3.274060   \n",
       "4              0   0.033333      GCS_motor   0.515191   chart    5.271144   \n",
       "...          ...        ...            ...        ...     ...         ...   \n",
       "81478793   57281  20.400000            MBP   0.195381   chart   78.552377   \n",
       "81478794   57281  20.400000  O2 Saturation  -0.678068   chart   96.820961   \n",
       "81478795   57281  20.400000             RR   0.179866   chart   26.278501   \n",
       "81478796   57281  20.400000            SBP  -0.404061   chart  120.239648   \n",
       "81478797   57281  20.400000          Urine  -0.242960  output  123.393012   \n",
       "\n",
       "                 std  \n",
       "0          56.625699  \n",
       "1           0.496263  \n",
       "2          14.994705  \n",
       "3           1.068640  \n",
       "4           1.414728  \n",
       "...              ...  \n",
       "81478793   17.645628  \n",
       "81478794    4.160290  \n",
       "81478795   15.130729  \n",
       "81478796   25.341836  \n",
       "81478797  137.442433  \n",
       "\n",
       "[81478798 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = scu.get_features_for_sepsischeck()\n",
    "#only run on ids that we have predictions for\n",
    "IDs = scu.get_unique_admissions(preds)\n",
    "feats = ['GCS_motor',\n",
    " 'GCS_eye',\n",
    " 'GCS_verbal','Platelet Count',\n",
    " 'Bilirubin (Total)',\n",
    " 'Creatinine Urine',\n",
    " 'DBP',\n",
    " 'SBP',\n",
    " 'Urine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ground_truth[\"sepsis_label\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_values(normalized, mean, std):\n",
    "    \"\"\"\n",
    "    the preprocessing script normalizes values by '(ts.loc[ii, 'value']-ts.loc[ii, 'mean'])/ts.loc[ii, 'std'] -> normalized = (value - mean) / std -> value = normalized * std + mean'\n",
    "    \"\"\"\n",
    "    return (normalized * std) + mean\n",
    "\n",
    "def restore_predictions(predictions, mapping=map, mean_stds=mean_stds):\n",
    "    l = []\n",
    "    #print(len(predictions[0]), len(predictions[0]) / 133 )\n",
    "    leng = len(predictions.iloc[0]) / 133\n",
    "    #reshape the predictions into sets of 133 variables per hour\n",
    "    for i in range(len(predictions)):\n",
    "        arr = np.asarray(predictions.iloc[i]).reshape((int(leng),133))\n",
    "        l.append(arr)\n",
    "    df = pd.concat([pd.DataFrame(arr) for arr in l], keys=np.arange(len(l)))\n",
    "    \n",
    "    \"\"\"#renormalize values per variable\n",
    "    for j in range(133):#, value in enumerate(pred): #for each predicted variable within predicted hour within observation window\n",
    "        var = mapping[j]\n",
    "        #print(var)\n",
    "        mean = mean_stds[\"mean\"].loc[mean_stds[\"variable\"] == var].item()\n",
    "        std = mean_stds[\"std\"].loc[mean_stds[\"variable\"] == var].item()\n",
    "        df[j] = df[j].apply(restore_values, args=(mean, std))\"\"\"\n",
    "    df.columns=mapping\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7000/7000 [00:08<00:00, 833.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin 25%</th>\n",
       "      <th>Albumin 5%</th>\n",
       "      <th>Amiodarone</th>\n",
       "      <th>Anion Gap</th>\n",
       "      <th>Antibiotics</th>\n",
       "      <th>BUN</th>\n",
       "      <th>...</th>\n",
       "      <th>Total CO2</th>\n",
       "      <th>Ultrafiltrate</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Urine</th>\n",
       "      <th>Vancomycin</th>\n",
       "      <th>Vasopressin</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH Blood</th>\n",
       "      <th>pH Urine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>-1.101284</td>\n",
       "      <td>-1.014427</td>\n",
       "      <td>-0.523730</td>\n",
       "      <td>0.420757</td>\n",
       "      <td>1.200858</td>\n",
       "      <td>-0.988420</td>\n",
       "      <td>2.510878</td>\n",
       "      <td>-0.371443</td>\n",
       "      <td>0.998616</td>\n",
       "      <td>-0.415810</td>\n",
       "      <td>...</td>\n",
       "      <td>1.056103</td>\n",
       "      <td>8.694890</td>\n",
       "      <td>-0.052206</td>\n",
       "      <td>0.681915</td>\n",
       "      <td>0.028165</td>\n",
       "      <td>1.427152</td>\n",
       "      <td>-0.534683</td>\n",
       "      <td>-0.450255</td>\n",
       "      <td>-1.153070</td>\n",
       "      <td>0.518613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.002865</td>\n",
       "      <td>-0.663647</td>\n",
       "      <td>-0.386386</td>\n",
       "      <td>0.313671</td>\n",
       "      <td>0.604375</td>\n",
       "      <td>-0.974044</td>\n",
       "      <td>2.235154</td>\n",
       "      <td>-0.820001</td>\n",
       "      <td>0.998133</td>\n",
       "      <td>-0.795485</td>\n",
       "      <td>...</td>\n",
       "      <td>1.209445</td>\n",
       "      <td>7.175538</td>\n",
       "      <td>-0.431301</td>\n",
       "      <td>0.850762</td>\n",
       "      <td>-0.073725</td>\n",
       "      <td>0.924427</td>\n",
       "      <td>-0.358182</td>\n",
       "      <td>-0.393979</td>\n",
       "      <td>-0.834589</td>\n",
       "      <td>0.390203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.991415</td>\n",
       "      <td>-0.574903</td>\n",
       "      <td>-0.346113</td>\n",
       "      <td>0.329304</td>\n",
       "      <td>0.562178</td>\n",
       "      <td>-1.014654</td>\n",
       "      <td>2.154635</td>\n",
       "      <td>-0.900549</td>\n",
       "      <td>0.998101</td>\n",
       "      <td>-0.939810</td>\n",
       "      <td>...</td>\n",
       "      <td>1.296959</td>\n",
       "      <td>7.102904</td>\n",
       "      <td>-0.577562</td>\n",
       "      <td>0.868316</td>\n",
       "      <td>-0.084471</td>\n",
       "      <td>0.757153</td>\n",
       "      <td>-0.362649</td>\n",
       "      <td>-0.479172</td>\n",
       "      <td>-0.787350</td>\n",
       "      <td>0.423409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.993957</td>\n",
       "      <td>-0.486125</td>\n",
       "      <td>-0.275525</td>\n",
       "      <td>0.393127</td>\n",
       "      <td>0.537117</td>\n",
       "      <td>-1.022254</td>\n",
       "      <td>2.143289</td>\n",
       "      <td>-0.917201</td>\n",
       "      <td>0.998004</td>\n",
       "      <td>-1.022066</td>\n",
       "      <td>...</td>\n",
       "      <td>1.359658</td>\n",
       "      <td>6.794025</td>\n",
       "      <td>-0.643185</td>\n",
       "      <td>0.809240</td>\n",
       "      <td>-0.089363</td>\n",
       "      <td>0.698698</td>\n",
       "      <td>-0.346855</td>\n",
       "      <td>-0.537914</td>\n",
       "      <td>-0.790834</td>\n",
       "      <td>0.440414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.003973</td>\n",
       "      <td>-0.401307</td>\n",
       "      <td>-0.198228</td>\n",
       "      <td>0.474632</td>\n",
       "      <td>0.524170</td>\n",
       "      <td>-1.003469</td>\n",
       "      <td>2.149922</td>\n",
       "      <td>-0.885611</td>\n",
       "      <td>0.997850</td>\n",
       "      <td>-1.080612</td>\n",
       "      <td>...</td>\n",
       "      <td>1.452738</td>\n",
       "      <td>6.319776</td>\n",
       "      <td>-0.700040</td>\n",
       "      <td>0.710715</td>\n",
       "      <td>-0.089702</td>\n",
       "      <td>0.671520</td>\n",
       "      <td>-0.325992</td>\n",
       "      <td>-0.573125</td>\n",
       "      <td>-0.810235</td>\n",
       "      <td>0.419267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.960633</td>\n",
       "      <td>-0.320211</td>\n",
       "      <td>-0.124473</td>\n",
       "      <td>0.447396</td>\n",
       "      <td>0.533642</td>\n",
       "      <td>-0.961801</td>\n",
       "      <td>2.123804</td>\n",
       "      <td>-0.834386</td>\n",
       "      <td>0.997721</td>\n",
       "      <td>-1.081393</td>\n",
       "      <td>...</td>\n",
       "      <td>1.486663</td>\n",
       "      <td>5.664063</td>\n",
       "      <td>-0.736140</td>\n",
       "      <td>0.537817</td>\n",
       "      <td>-0.091880</td>\n",
       "      <td>0.697553</td>\n",
       "      <td>-0.378090</td>\n",
       "      <td>-0.578080</td>\n",
       "      <td>-0.780137</td>\n",
       "      <td>0.332772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.907821</td>\n",
       "      <td>-0.269046</td>\n",
       "      <td>-0.083177</td>\n",
       "      <td>0.330920</td>\n",
       "      <td>0.512093</td>\n",
       "      <td>-0.961738</td>\n",
       "      <td>2.069494</td>\n",
       "      <td>-0.877621</td>\n",
       "      <td>0.997663</td>\n",
       "      <td>-1.060831</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480301</td>\n",
       "      <td>5.401171</td>\n",
       "      <td>-0.725700</td>\n",
       "      <td>0.428626</td>\n",
       "      <td>-0.104321</td>\n",
       "      <td>0.671695</td>\n",
       "      <td>-0.415848</td>\n",
       "      <td>-0.552633</td>\n",
       "      <td>-0.706082</td>\n",
       "      <td>0.278089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.839953</td>\n",
       "      <td>-0.286512</td>\n",
       "      <td>-0.071055</td>\n",
       "      <td>0.297109</td>\n",
       "      <td>0.484002</td>\n",
       "      <td>-0.986740</td>\n",
       "      <td>2.074739</td>\n",
       "      <td>-0.895762</td>\n",
       "      <td>0.997681</td>\n",
       "      <td>-1.109492</td>\n",
       "      <td>...</td>\n",
       "      <td>1.507592</td>\n",
       "      <td>5.466467</td>\n",
       "      <td>-0.727590</td>\n",
       "      <td>0.403497</td>\n",
       "      <td>-0.121525</td>\n",
       "      <td>0.587974</td>\n",
       "      <td>-0.415917</td>\n",
       "      <td>-0.556024</td>\n",
       "      <td>-0.648932</td>\n",
       "      <td>0.292267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.772487</td>\n",
       "      <td>-0.311277</td>\n",
       "      <td>-0.054677</td>\n",
       "      <td>0.270687</td>\n",
       "      <td>0.492043</td>\n",
       "      <td>-0.991954</td>\n",
       "      <td>2.132844</td>\n",
       "      <td>-0.884255</td>\n",
       "      <td>0.997691</td>\n",
       "      <td>-1.145228</td>\n",
       "      <td>...</td>\n",
       "      <td>1.505033</td>\n",
       "      <td>5.502867</td>\n",
       "      <td>-0.737237</td>\n",
       "      <td>0.366669</td>\n",
       "      <td>-0.133018</td>\n",
       "      <td>0.541133</td>\n",
       "      <td>-0.424946</td>\n",
       "      <td>-0.549634</td>\n",
       "      <td>-0.499363</td>\n",
       "      <td>0.298909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.734242</td>\n",
       "      <td>-0.314998</td>\n",
       "      <td>0.015088</td>\n",
       "      <td>0.223051</td>\n",
       "      <td>0.513029</td>\n",
       "      <td>-0.965527</td>\n",
       "      <td>2.157679</td>\n",
       "      <td>-0.830218</td>\n",
       "      <td>0.997652</td>\n",
       "      <td>-1.145533</td>\n",
       "      <td>...</td>\n",
       "      <td>1.423444</td>\n",
       "      <td>5.414445</td>\n",
       "      <td>-0.727740</td>\n",
       "      <td>0.346196</td>\n",
       "      <td>-0.128901</td>\n",
       "      <td>0.511965</td>\n",
       "      <td>-0.427956</td>\n",
       "      <td>-0.480494</td>\n",
       "      <td>-0.315350</td>\n",
       "      <td>0.262295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.700026</td>\n",
       "      <td>-0.285782</td>\n",
       "      <td>0.121232</td>\n",
       "      <td>0.178182</td>\n",
       "      <td>0.557459</td>\n",
       "      <td>-0.923823</td>\n",
       "      <td>2.147175</td>\n",
       "      <td>-0.720350</td>\n",
       "      <td>0.997498</td>\n",
       "      <td>-1.176003</td>\n",
       "      <td>...</td>\n",
       "      <td>1.283389</td>\n",
       "      <td>5.128377</td>\n",
       "      <td>-0.770632</td>\n",
       "      <td>0.352779</td>\n",
       "      <td>-0.090829</td>\n",
       "      <td>0.412980</td>\n",
       "      <td>-0.437785</td>\n",
       "      <td>-0.516366</td>\n",
       "      <td>-0.191074</td>\n",
       "      <td>0.169472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.601077</td>\n",
       "      <td>-0.230489</td>\n",
       "      <td>0.176465</td>\n",
       "      <td>0.153736</td>\n",
       "      <td>0.548477</td>\n",
       "      <td>-0.912955</td>\n",
       "      <td>2.115512</td>\n",
       "      <td>-0.594216</td>\n",
       "      <td>0.997329</td>\n",
       "      <td>-1.213855</td>\n",
       "      <td>...</td>\n",
       "      <td>1.199252</td>\n",
       "      <td>4.788076</td>\n",
       "      <td>-0.927917</td>\n",
       "      <td>0.225547</td>\n",
       "      <td>-0.087615</td>\n",
       "      <td>0.201405</td>\n",
       "      <td>-0.414104</td>\n",
       "      <td>-0.574904</td>\n",
       "      <td>-0.011200</td>\n",
       "      <td>0.065014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ALP       ALT       AST   Albumin  Albumin 25%  Albumin 5%  \\\n",
       "0 0  -1.101284 -1.014427 -0.523730  0.420757     1.200858   -0.988420   \n",
       "  1  -1.002865 -0.663647 -0.386386  0.313671     0.604375   -0.974044   \n",
       "  2  -0.991415 -0.574903 -0.346113  0.329304     0.562178   -1.014654   \n",
       "  3  -0.993957 -0.486125 -0.275525  0.393127     0.537117   -1.022254   \n",
       "  4  -1.003973 -0.401307 -0.198228  0.474632     0.524170   -1.003469   \n",
       "  5  -0.960633 -0.320211 -0.124473  0.447396     0.533642   -0.961801   \n",
       "  6  -0.907821 -0.269046 -0.083177  0.330920     0.512093   -0.961738   \n",
       "  7  -0.839953 -0.286512 -0.071055  0.297109     0.484002   -0.986740   \n",
       "  8  -0.772487 -0.311277 -0.054677  0.270687     0.492043   -0.991954   \n",
       "  9  -0.734242 -0.314998  0.015088  0.223051     0.513029   -0.965527   \n",
       "  10 -0.700026 -0.285782  0.121232  0.178182     0.557459   -0.923823   \n",
       "  11 -0.601077 -0.230489  0.176465  0.153736     0.548477   -0.912955   \n",
       "\n",
       "      Amiodarone  Anion Gap  Antibiotics       BUN  ...  Total CO2  \\\n",
       "0 0     2.510878  -0.371443     0.998616 -0.415810  ...   1.056103   \n",
       "  1     2.235154  -0.820001     0.998133 -0.795485  ...   1.209445   \n",
       "  2     2.154635  -0.900549     0.998101 -0.939810  ...   1.296959   \n",
       "  3     2.143289  -0.917201     0.998004 -1.022066  ...   1.359658   \n",
       "  4     2.149922  -0.885611     0.997850 -1.080612  ...   1.452738   \n",
       "  5     2.123804  -0.834386     0.997721 -1.081393  ...   1.486663   \n",
       "  6     2.069494  -0.877621     0.997663 -1.060831  ...   1.480301   \n",
       "  7     2.074739  -0.895762     0.997681 -1.109492  ...   1.507592   \n",
       "  8     2.132844  -0.884255     0.997691 -1.145228  ...   1.505033   \n",
       "  9     2.157679  -0.830218     0.997652 -1.145533  ...   1.423444   \n",
       "  10    2.147175  -0.720350     0.997498 -1.176003  ...   1.283389   \n",
       "  11    2.115512  -0.594216     0.997329 -1.213855  ...   1.199252   \n",
       "\n",
       "      Ultrafiltrate   Unknown     Urine  Vancomycin  Vasopressin       WBC  \\\n",
       "0 0        8.694890 -0.052206  0.681915    0.028165     1.427152 -0.534683   \n",
       "  1        7.175538 -0.431301  0.850762   -0.073725     0.924427 -0.358182   \n",
       "  2        7.102904 -0.577562  0.868316   -0.084471     0.757153 -0.362649   \n",
       "  3        6.794025 -0.643185  0.809240   -0.089363     0.698698 -0.346855   \n",
       "  4        6.319776 -0.700040  0.710715   -0.089702     0.671520 -0.325992   \n",
       "  5        5.664063 -0.736140  0.537817   -0.091880     0.697553 -0.378090   \n",
       "  6        5.401171 -0.725700  0.428626   -0.104321     0.671695 -0.415848   \n",
       "  7        5.466467 -0.727590  0.403497   -0.121525     0.587974 -0.415917   \n",
       "  8        5.502867 -0.737237  0.366669   -0.133018     0.541133 -0.424946   \n",
       "  9        5.414445 -0.727740  0.346196   -0.128901     0.511965 -0.427956   \n",
       "  10       5.128377 -0.770632  0.352779   -0.090829     0.412980 -0.437785   \n",
       "  11       4.788076 -0.927917  0.225547   -0.087615     0.201405 -0.414104   \n",
       "\n",
       "        Weight  pH Blood  pH Urine  \n",
       "0 0  -0.450255 -1.153070  0.518613  \n",
       "  1  -0.393979 -0.834589  0.390203  \n",
       "  2  -0.479172 -0.787350  0.423409  \n",
       "  3  -0.537914 -0.790834  0.440414  \n",
       "  4  -0.573125 -0.810235  0.419267  \n",
       "  5  -0.578080 -0.780137  0.332772  \n",
       "  6  -0.552633 -0.706082  0.278089  \n",
       "  7  -0.556024 -0.648932  0.292267  \n",
       "  8  -0.549634 -0.499363  0.298909  \n",
       "  9  -0.480494 -0.315350  0.262295  \n",
       "  10 -0.516366 -0.191074  0.169472  \n",
       "  11 -0.574904 -0.011200  0.065014  \n",
       "\n",
       "[12 rows x 133 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data full patient data as singular sequence of variables (for classification on time series) \n",
    "datalist2 = []\n",
    "for ts_ind in scu.tqdm(IDs[:7000], leave=True):\n",
    "    # get patient data\n",
    "    df_raw = data[0].loc[data[0][\"ts_ind\"] == ts_ind]   \n",
    "    predicted = df_raw[[\"obs_window\", \"forecasting_pred\"]]\n",
    "    predictions = restore_predictions(\n",
    "            predicted[\"forecasting_pred\"], mapping=map, mean_stds=mean_stds\n",
    "        )\n",
    "    \n",
    "    #df = scu.prepare_strats_for_sepsis(df_raw, feats)\n",
    "    #df = scu.fill_data(df, False)\n",
    "    #df = df.drop([\"blood_culture\", \"anti\", \"mech\", \"text\"], axis=1)\n",
    "    #df = df.reindex(sorted(df.columns), axis=1)\n",
    "    #df.index = np.rint(df.index)\n",
    "    #df.groupby(\"hour\").mean()\n",
    "    #datalist2.append(list(df.values.flatten()))\n",
    "    predictions = predictions.reindex(sorted(predictions.columns), axis=1)\n",
    "    datalist2.append(list(predictions.values.flatten()))\n",
    "# deal with true and false    \n",
    "mapping = {\"True\": 1, \"False\": 0}\n",
    "datalist = []\n",
    "for string in datalist2:\n",
    "    datalist.append([mapping.get(x, x) for x in string])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(predictions.columns)\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1596, 100.0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count lengths and show percentages to find suitable cutoff (all data needs to be same length): The lenghts are all features * all timesteps, since it is flattened for classification of time series\n",
    "list_of_lengths = (lambda x:[len(i) for i in x])(datalist)\n",
    "c = Counter(list_of_lengths)\n",
    "[(i, c[i] / len(list_of_lengths) * 100.0) for i in c]\n",
    "[(i, c[i] / len(list_of_lengths) * 100.0) for i, count in c.most_common()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick cutoff based on above, trim patient data and ground truths accordingly (only keep relevant)\n",
    "thresh = 12*len(cols) #length of forecast * number of features\n",
    "cutoff = list(filter(lambda i: len(i) >= thresh, datalist))\n",
    "ground_truth_cutoff = [ground_truth[\"sepsis_label\"][x] for x, i in enumerate(datalist) if len(i) >= thresh]\n",
    "\n",
    "datalist_trimmed = [element[:thresh] for element in cutoff]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 7000\n"
     ]
    }
   ],
   "source": [
    "print(len(datalist_trimmed),len(ground_truth_cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1596"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that min len is what we intended\n",
    "list_of_lengths2 = (lambda x:[len(i) for i in x])(datalist_trimmed)\n",
    "min_len2 = min(list_of_lengths2)\n",
    "min_len2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# data splitting\n",
    "# Shuffle two lists with same order\n",
    "# Using zip() + * operator + shuffle()\n",
    "temp = list(zip(datalist_trimmed, ground_truth_cutoff))\n",
    "random.shuffle(temp)\n",
    "dataset, truths = zip(*temp)\n",
    "# res1 and res2 come out as tuples, and so must be converted to lists.\n",
    "dataset, truths = list(dataset), list(truths)\n",
    "# remove x% data from dataset and truths for testing\n",
    "train = dataset[:5500]\n",
    "train_Y = truths[:5500]\n",
    "\n",
    "test = dataset[len(train):]\n",
    "test_Y = truths[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_Y) + len(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3557/3557 [00:05<00:00, 676.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# load forecast data full patient as singular sequence of variables (for classification on time series) \n",
    "pdatalist2 = []\n",
    "for ts_ind in scu.tqdm(IDs[7000:], leave=True):\n",
    "    # get prediction\n",
    "    pre = preds[0].loc[preds[0][\"ts_ind\"] == ts_ind]\n",
    "    # get all observation windows and forecasting predictions\n",
    "    predicted = pre[[\"obs_window\", \"forecasting_pred\"]]\n",
    "    predictions = restore_predictions(\n",
    "            predicted[\"forecasting_pred\"], mapping=map, mean_stds=mean_stds\n",
    "        )\n",
    "    \n",
    "    predictions = predictions[predictions.columns.intersection(cols)]\n",
    "    #print(predictions)\n",
    "    #predictions = predictions.drop([\"Dobutamine\"], axis=1)\n",
    "    predictions = predictions.reindex(sorted(predictions.columns), axis=1)\n",
    "    pdatalist2.append(list(predictions.values.flatten()))\n",
    "# deal with true and false    \n",
    "mapping = {\"True\": 1, \"False\": 0}\n",
    "pdatalist = []\n",
    "for string in pdatalist2:\n",
    "    pdatalist.append([mapping.get(x, x) for x in string])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1596, 100.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count lengths and show percentages to find suitable cutoff (all data needs to be same length): The lenghts are all features * all timesteps, since it is flattened for classification of time series\n",
    "list_of_lengths = (lambda x:[len(i) for i in x])(pdatalist)\n",
    "c = Counter(list_of_lengths)\n",
    "[(i, c[i] / len(list_of_lengths) * 100.0) for i in c]\n",
    "[(i, c[i] / len(list_of_lengths) * 100.0) for i, count in c.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macro f1: 0.56\n",
    "#clf = make_pipeline(StandardScaler(),HistGradientBoostingClassifier(class_weight=\"balanced\", max_iter=1500, min_samples_leaf=50, max_leaf_nodes=150, random_state=100, validation_fraction=0.1, verbose=1, l2_regularization=0.01, early_stopping=\"auto\"))\n",
    "\n",
    "# macro f1: .57\n",
    "#clf1 = make_pipeline(StandardScaler(),HistGradientBoostingClassifier(class_weight=\"balanced\", max_iter=1500, min_samples_leaf=50, max_leaf_nodes=150, random_state=100, validation_fraction=0.1, verbose=1, l2_regularization=0.05, early_stopping=\"auto\"))\n",
    "\n",
    "########## train on forecasts\n",
    "# macro f1: .6\n",
    "#clf = make_pipeline(StandardScaler(),HistGradientBoostingClassifier(class_weight=\"balanced\", max_iter=1500, min_samples_leaf=50, max_leaf_nodes=150, random_state=100, validation_fraction=0.1, verbose=1, l2_regularization=0.01, early_stopping=\"auto\"))\n",
    "\n",
    "# macro f1: .6\n",
    "clf = make_pipeline(StandardScaler(),HistGradientBoostingClassifier(class_weight=\"balanced\", max_iter=500, min_samples_leaf=100, max_leaf_nodes=250, scoring='f1_macro',random_state=100, validation_fraction=0.1, verbose=1, l2_regularization=0.05, early_stopping=\"auto\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.070 GB of training data: 1.107 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/500] 1 tree, 36 leaves, max depth = 8, in 0.307s\n",
      "[2/500] 1 tree, 31 leaves, max depth = 10, in 0.254s\n",
      "[3/500] 1 tree, 34 leaves, max depth = 9, in 0.253s\n",
      "[4/500] 1 tree, 34 leaves, max depth = 9, in 0.253s\n",
      "[5/500] 1 tree, 36 leaves, max depth = 8, in 0.294s\n",
      "[6/500] 1 tree, 37 leaves, max depth = 9, in 0.319s\n",
      "[7/500] 1 tree, 37 leaves, max depth = 9, in 0.277s\n",
      "[8/500] 1 tree, 37 leaves, max depth = 10, in 0.306s\n",
      "[9/500] 1 tree, 36 leaves, max depth = 10, in 0.294s\n",
      "[10/500] 1 tree, 39 leaves, max depth = 11, in 0.306s\n",
      "[11/500] 1 tree, 35 leaves, max depth = 12, in 0.284s\n",
      "[12/500] 1 tree, 43 leaves, max depth = 10, in 0.327s\n",
      "[13/500] 1 tree, 37 leaves, max depth = 11, in 0.290s\n",
      "[14/500] 1 tree, 38 leaves, max depth = 9, in 0.279s\n",
      "[15/500] 1 tree, 39 leaves, max depth = 13, in 0.320s\n",
      "[16/500] 1 tree, 40 leaves, max depth = 11, in 0.322s\n",
      "[17/500] 1 tree, 40 leaves, max depth = 11, in 0.321s\n",
      "[18/500] 1 tree, 43 leaves, max depth = 11, in 0.350s\n",
      "[19/500] 1 tree, 38 leaves, max depth = 10, in 0.340s\n",
      "[20/500] 1 tree, 38 leaves, max depth = 10, in 0.346s\n",
      "[21/500] 1 tree, 40 leaves, max depth = 13, in 0.319s\n",
      "[22/500] 1 tree, 41 leaves, max depth = 12, in 0.352s\n",
      "[23/500] 1 tree, 42 leaves, max depth = 12, in 0.339s\n",
      "[24/500] 1 tree, 40 leaves, max depth = 13, in 0.330s\n",
      "[25/500] 1 tree, 39 leaves, max depth = 12, in 0.317s\n",
      "[26/500] 1 tree, 45 leaves, max depth = 15, in 0.330s\n",
      "[27/500] 1 tree, 41 leaves, max depth = 11, in 0.329s\n",
      "[28/500] 1 tree, 44 leaves, max depth = 18, in 0.325s\n",
      "[29/500] 1 tree, 41 leaves, max depth = 14, in 0.329s\n",
      "[30/500] 1 tree, 40 leaves, max depth = 12, in 0.290s\n",
      "[31/500] 1 tree, 42 leaves, max depth = 15, in 0.329s\n",
      "[32/500] 1 tree, 39 leaves, max depth = 19, in 0.314s\n",
      "[33/500] 1 tree, 44 leaves, max depth = 19, in 0.332s\n",
      "[34/500] 1 tree, 41 leaves, max depth = 18, in 0.304s\n",
      "[35/500] 1 tree, 42 leaves, max depth = 11, in 0.313s\n",
      "[36/500] 1 tree, 42 leaves, max depth = 20, in 0.327s\n",
      "[37/500] 1 tree, 40 leaves, max depth = 17, in 0.293s\n",
      "[38/500] 1 tree, 43 leaves, max depth = 13, in 0.304s\n",
      "[39/500] 1 tree, 40 leaves, max depth = 22, in 0.311s\n",
      "[40/500] 1 tree, 42 leaves, max depth = 21, in 0.311s\n",
      "[41/500] 1 tree, 41 leaves, max depth = 15, in 0.301s\n",
      "[42/500] 1 tree, 40 leaves, max depth = 10, in 0.291s\n",
      "[43/500] 1 tree, 41 leaves, max depth = 15, in 0.281s\n",
      "[44/500] 1 tree, 43 leaves, max depth = 15, in 0.319s\n",
      "[45/500] 1 tree, 42 leaves, max depth = 20, in 0.311s\n",
      "[46/500] 1 tree, 42 leaves, max depth = 16, in 0.324s\n",
      "[47/500] 1 tree, 42 leaves, max depth = 15, in 0.316s\n",
      "[48/500] 1 tree, 40 leaves, max depth = 17, in 0.305s\n",
      "[49/500] 1 tree, 40 leaves, max depth = 13, in 0.311s\n",
      "[50/500] 1 tree, 44 leaves, max depth = 18, in 0.343s\n",
      "[51/500] 1 tree, 42 leaves, max depth = 23, in 0.308s\n",
      "[52/500] 1 tree, 40 leaves, max depth = 19, in 0.292s\n",
      "[53/500] 1 tree, 42 leaves, max depth = 14, in 0.314s\n",
      "[54/500] 1 tree, 40 leaves, max depth = 15, in 0.302s\n",
      "[55/500] 1 tree, 44 leaves, max depth = 21, in 0.337s\n",
      "[56/500] 1 tree, 40 leaves, max depth = 18, in 0.303s\n",
      "[57/500] 1 tree, 37 leaves, max depth = 20, in 0.296s\n",
      "[58/500] 1 tree, 42 leaves, max depth = 21, in 0.339s\n",
      "[59/500] 1 tree, 41 leaves, max depth = 15, in 0.322s\n",
      "[60/500] 1 tree, 37 leaves, max depth = 17, in 0.280s\n",
      "[61/500] 1 tree, 41 leaves, max depth = 17, in 0.325s\n",
      "[62/500] 1 tree, 41 leaves, max depth = 20, in 0.299s\n",
      "[63/500] 1 tree, 42 leaves, max depth = 16, in 0.354s\n",
      "[64/500] 1 tree, 41 leaves, max depth = 16, in 0.281s\n",
      "[65/500] 1 tree, 42 leaves, max depth = 16, in 0.300s\n",
      "[66/500] 1 tree, 39 leaves, max depth = 21, in 0.291s\n",
      "[67/500] 1 tree, 42 leaves, max depth = 21, in 0.316s\n",
      "[68/500] 1 tree, 41 leaves, max depth = 17, in 0.329s\n",
      "[69/500] 1 tree, 41 leaves, max depth = 10, in 0.340s\n",
      "[70/500] 1 tree, 41 leaves, max depth = 20, in 0.329s\n",
      "[71/500] 1 tree, 38 leaves, max depth = 26, in 0.351s\n",
      "[72/500] 1 tree, 44 leaves, max depth = 14, in 0.299s\n",
      "[73/500] 1 tree, 41 leaves, max depth = 19, in 0.333s\n",
      "[74/500] 1 tree, 42 leaves, max depth = 21, in 0.331s\n",
      "[75/500] 1 tree, 40 leaves, max depth = 13, in 0.295s\n",
      "[76/500] 1 tree, 42 leaves, max depth = 19, in 0.343s\n",
      "[77/500] 1 tree, 43 leaves, max depth = 15, in 0.295s\n",
      "[78/500] 1 tree, 41 leaves, max depth = 21, in 0.329s\n",
      "[79/500] 1 tree, 43 leaves, max depth = 18, in 0.330s\n",
      "[80/500] 1 tree, 41 leaves, max depth = 17, in 0.293s\n",
      "[81/500] 1 tree, 41 leaves, max depth = 15, in 0.311s\n",
      "[82/500] 1 tree, 40 leaves, max depth = 21, in 0.313s\n",
      "[83/500] 1 tree, 40 leaves, max depth = 11, in 0.295s\n",
      "[84/500] 1 tree, 37 leaves, max depth = 18, in 0.283s\n",
      "[85/500] 1 tree, 39 leaves, max depth = 17, in 0.311s\n",
      "[86/500] 1 tree, 39 leaves, max depth = 15, in 0.308s\n",
      "[87/500] 1 tree, 41 leaves, max depth = 17, in 0.298s\n",
      "[88/500] 1 tree, 40 leaves, max depth = 18, in 0.300s\n",
      "[89/500] 1 tree, 40 leaves, max depth = 15, in 0.292s\n",
      "[90/500] 1 tree, 40 leaves, max depth = 25, in 0.310s\n",
      "[91/500] 1 tree, 39 leaves, max depth = 22, in 0.313s\n",
      "[92/500] 1 tree, 41 leaves, max depth = 21, in 0.327s\n",
      "[93/500] 1 tree, 44 leaves, max depth = 15, in 0.319s\n",
      "[94/500] 1 tree, 40 leaves, max depth = 15, in 0.304s\n",
      "[95/500] 1 tree, 40 leaves, max depth = 20, in 0.321s\n",
      "[96/500] 1 tree, 40 leaves, max depth = 15, in 0.318s\n",
      "[97/500] 1 tree, 40 leaves, max depth = 17, in 0.307s\n",
      "[98/500] 1 tree, 41 leaves, max depth = 12, in 0.335s\n",
      "[99/500] 1 tree, 41 leaves, max depth = 14, in 0.281s\n",
      "[100/500] 1 tree, 42 leaves, max depth = 22, in 0.327s\n",
      "[101/500] 1 tree, 40 leaves, max depth = 20, in 0.297s\n",
      "[102/500] 1 tree, 41 leaves, max depth = 20, in 0.331s\n",
      "[103/500] 1 tree, 38 leaves, max depth = 9, in 0.272s\n",
      "[104/500] 1 tree, 41 leaves, max depth = 11, in 0.301s\n",
      "[105/500] 1 tree, 39 leaves, max depth = 22, in 0.293s\n",
      "[106/500] 1 tree, 42 leaves, max depth = 16, in 0.302s\n",
      "[107/500] 1 tree, 39 leaves, max depth = 18, in 0.309s\n",
      "[108/500] 1 tree, 42 leaves, max depth = 26, in 0.313s\n",
      "[109/500] 1 tree, 41 leaves, max depth = 21, in 0.311s\n",
      "[110/500] 1 tree, 39 leaves, max depth = 23, in 0.322s\n",
      "[111/500] 1 tree, 40 leaves, max depth = 11, in 0.349s\n",
      "[112/500] 1 tree, 40 leaves, max depth = 16, in 0.282s\n",
      "[113/500] 1 tree, 40 leaves, max depth = 13, in 0.297s\n",
      "[114/500] 1 tree, 41 leaves, max depth = 26, in 0.321s\n",
      "[115/500] 1 tree, 37 leaves, max depth = 17, in 0.294s\n",
      "[116/500] 1 tree, 42 leaves, max depth = 21, in 0.340s\n",
      "[117/500] 1 tree, 40 leaves, max depth = 17, in 0.309s\n",
      "[118/500] 1 tree, 43 leaves, max depth = 18, in 0.310s\n",
      "[119/500] 1 tree, 40 leaves, max depth = 14, in 0.337s\n",
      "[120/500] 1 tree, 39 leaves, max depth = 20, in 0.309s\n",
      "[121/500] 1 tree, 41 leaves, max depth = 19, in 0.304s\n",
      "[122/500] 1 tree, 40 leaves, max depth = 21, in 0.294s\n",
      "[123/500] 1 tree, 40 leaves, max depth = 19, in 0.290s\n",
      "[124/500] 1 tree, 39 leaves, max depth = 15, in 0.308s\n",
      "[125/500] 1 tree, 41 leaves, max depth = 22, in 0.312s\n",
      "[126/500] 1 tree, 41 leaves, max depth = 18, in 0.310s\n",
      "[127/500] 1 tree, 36 leaves, max depth = 13, in 0.305s\n",
      "[128/500] 1 tree, 43 leaves, max depth = 16, in 0.309s\n",
      "[129/500] 1 tree, 40 leaves, max depth = 12, in 0.322s\n",
      "[130/500] 1 tree, 40 leaves, max depth = 13, in 0.302s\n",
      "[131/500] 1 tree, 44 leaves, max depth = 18, in 0.322s\n",
      "[132/500] 1 tree, 41 leaves, max depth = 15, in 0.299s\n",
      "[133/500] 1 tree, 41 leaves, max depth = 19, in 0.292s\n",
      "[134/500] 1 tree, 40 leaves, max depth = 19, in 0.262s\n",
      "[135/500] 1 tree, 41 leaves, max depth = 19, in 0.303s\n",
      "[136/500] 1 tree, 42 leaves, max depth = 25, in 0.313s\n",
      "[137/500] 1 tree, 41 leaves, max depth = 23, in 0.310s\n",
      "[138/500] 1 tree, 41 leaves, max depth = 21, in 0.342s\n",
      "[139/500] 1 tree, 40 leaves, max depth = 11, in 0.290s\n",
      "[140/500] 1 tree, 42 leaves, max depth = 12, in 0.292s\n",
      "[141/500] 1 tree, 38 leaves, max depth = 21, in 0.292s\n",
      "[142/500] 1 tree, 41 leaves, max depth = 16, in 0.312s\n",
      "[143/500] 1 tree, 44 leaves, max depth = 18, in 0.333s\n",
      "[144/500] 1 tree, 41 leaves, max depth = 15, in 0.303s\n",
      "[145/500] 1 tree, 40 leaves, max depth = 19, in 0.299s\n",
      "[146/500] 1 tree, 40 leaves, max depth = 16, in 0.298s\n",
      "[147/500] 1 tree, 37 leaves, max depth = 18, in 0.292s\n",
      "[148/500] 1 tree, 41 leaves, max depth = 19, in 0.320s\n",
      "[149/500] 1 tree, 43 leaves, max depth = 10, in 0.321s\n",
      "[150/500] 1 tree, 39 leaves, max depth = 13, in 0.309s\n",
      "[151/500] 1 tree, 42 leaves, max depth = 11, in 0.292s\n",
      "[152/500] 1 tree, 40 leaves, max depth = 14, in 0.309s\n",
      "[153/500] 1 tree, 41 leaves, max depth = 16, in 0.301s\n",
      "[154/500] 1 tree, 37 leaves, max depth = 18, in 0.300s\n",
      "[155/500] 1 tree, 41 leaves, max depth = 13, in 0.301s\n",
      "[156/500] 1 tree, 39 leaves, max depth = 18, in 0.300s\n",
      "[157/500] 1 tree, 42 leaves, max depth = 15, in 0.324s\n",
      "[158/500] 1 tree, 42 leaves, max depth = 16, in 0.295s\n",
      "[159/500] 1 tree, 41 leaves, max depth = 17, in 0.321s\n",
      "[160/500] 1 tree, 40 leaves, max depth = 10, in 0.290s\n",
      "[161/500] 1 tree, 38 leaves, max depth = 20, in 0.295s\n",
      "[162/500] 1 tree, 42 leaves, max depth = 18, in 0.329s\n",
      "[163/500] 1 tree, 39 leaves, max depth = 11, in 0.278s\n",
      "[164/500] 1 tree, 40 leaves, max depth = 11, in 0.309s\n",
      "[165/500] 1 tree, 39 leaves, max depth = 13, in 0.259s\n",
      "[166/500] 1 tree, 43 leaves, max depth = 19, in 0.304s\n",
      "[167/500] 1 tree, 40 leaves, max depth = 18, in 0.281s\n",
      "[168/500] 1 tree, 38 leaves, max depth = 16, in 0.308s\n",
      "[169/500] 1 tree, 43 leaves, max depth = 15, in 0.334s\n",
      "[170/500] 1 tree, 40 leaves, max depth = 12, in 0.293s\n",
      "[171/500] 1 tree, 40 leaves, max depth = 18, in 0.290s\n",
      "[172/500] 1 tree, 40 leaves, max depth = 16, in 0.301s\n",
      "[173/500] 1 tree, 41 leaves, max depth = 17, in 0.299s\n",
      "[174/500] 1 tree, 41 leaves, max depth = 16, in 0.301s\n",
      "[175/500] 1 tree, 42 leaves, max depth = 14, in 0.288s\n",
      "[176/500] 1 tree, 41 leaves, max depth = 16, in 0.283s\n",
      "[177/500] 1 tree, 42 leaves, max depth = 16, in 0.289s\n",
      "[178/500] 1 tree, 39 leaves, max depth = 18, in 0.298s\n",
      "[179/500] 1 tree, 43 leaves, max depth = 13, in 0.313s\n",
      "[180/500] 1 tree, 37 leaves, max depth = 19, in 0.301s\n",
      "[181/500] 1 tree, 41 leaves, max depth = 10, in 0.314s\n",
      "[182/500] 1 tree, 40 leaves, max depth = 12, in 0.279s\n",
      "[183/500] 1 tree, 40 leaves, max depth = 13, in 0.297s\n",
      "[184/500] 1 tree, 39 leaves, max depth = 18, in 0.291s\n",
      "[185/500] 1 tree, 40 leaves, max depth = 12, in 0.267s\n",
      "[186/500] 1 tree, 38 leaves, max depth = 11, in 0.302s\n",
      "[187/500] 1 tree, 41 leaves, max depth = 22, in 0.290s\n",
      "[188/500] 1 tree, 41 leaves, max depth = 20, in 0.298s\n",
      "[189/500] 1 tree, 39 leaves, max depth = 14, in 0.318s\n",
      "[190/500] 1 tree, 40 leaves, max depth = 13, in 0.342s\n",
      "[191/500] 1 tree, 41 leaves, max depth = 15, in 0.292s\n",
      "[192/500] 1 tree, 39 leaves, max depth = 21, in 0.322s\n",
      "[193/500] 1 tree, 39 leaves, max depth = 20, in 0.284s\n",
      "[194/500] 1 tree, 39 leaves, max depth = 17, in 0.305s\n",
      "[195/500] 1 tree, 41 leaves, max depth = 14, in 0.312s\n",
      "[196/500] 1 tree, 41 leaves, max depth = 15, in 0.326s\n",
      "[197/500] 1 tree, 42 leaves, max depth = 19, in 0.313s\n",
      "[198/500] 1 tree, 42 leaves, max depth = 14, in 0.308s\n",
      "[199/500] 1 tree, 37 leaves, max depth = 16, in 0.300s\n",
      "[200/500] 1 tree, 39 leaves, max depth = 16, in 0.298s\n",
      "[201/500] 1 tree, 39 leaves, max depth = 17, in 0.309s\n",
      "[202/500] 1 tree, 40 leaves, max depth = 10, in 0.301s\n",
      "[203/500] 1 tree, 38 leaves, max depth = 12, in 0.269s\n",
      "[204/500] 1 tree, 42 leaves, max depth = 21, in 0.301s\n",
      "[205/500] 1 tree, 36 leaves, max depth = 12, in 0.271s\n",
      "[206/500] 1 tree, 39 leaves, max depth = 15, in 0.308s\n",
      "[207/500] 1 tree, 40 leaves, max depth = 11, in 0.291s\n",
      "[208/500] 1 tree, 39 leaves, max depth = 13, in 0.292s\n",
      "[209/500] 1 tree, 38 leaves, max depth = 10, in 0.285s\n",
      "[210/500] 1 tree, 39 leaves, max depth = 10, in 0.307s\n",
      "[211/500] 1 tree, 40 leaves, max depth = 10, in 0.283s\n",
      "[212/500] 1 tree, 37 leaves, max depth = 17, in 0.294s\n",
      "[213/500] 1 tree, 39 leaves, max depth = 16, in 0.291s\n",
      "[214/500] 1 tree, 41 leaves, max depth = 13, in 0.298s\n",
      "[215/500] 1 tree, 42 leaves, max depth = 11, in 0.313s\n",
      "[216/500] 1 tree, 38 leaves, max depth = 10, in 0.258s\n",
      "[217/500] 1 tree, 41 leaves, max depth = 9, in 0.325s\n",
      "[218/500] 1 tree, 39 leaves, max depth = 12, in 0.288s\n",
      "[219/500] 1 tree, 40 leaves, max depth = 8, in 0.275s\n",
      "[220/500] 1 tree, 40 leaves, max depth = 11, in 0.263s\n",
      "[221/500] 1 tree, 40 leaves, max depth = 11, in 0.292s\n",
      "[222/500] 1 tree, 38 leaves, max depth = 10, in 0.291s\n",
      "[223/500] 1 tree, 40 leaves, max depth = 12, in 0.296s\n",
      "[224/500] 1 tree, 38 leaves, max depth = 10, in 0.320s\n",
      "[225/500] 1 tree, 40 leaves, max depth = 11, in 0.282s\n",
      "[226/500] 1 tree, 40 leaves, max depth = 15, in 0.315s\n",
      "[227/500] 1 tree, 38 leaves, max depth = 10, in 0.326s\n",
      "[228/500] 1 tree, 36 leaves, max depth = 16, in 0.270s\n",
      "[229/500] 1 tree, 38 leaves, max depth = 11, in 0.270s\n",
      "[230/500] 1 tree, 38 leaves, max depth = 10, in 0.314s\n",
      "[231/500] 1 tree, 35 leaves, max depth = 10, in 0.252s\n",
      "[232/500] 1 tree, 38 leaves, max depth = 12, in 0.318s\n",
      "[233/500] 1 tree, 38 leaves, max depth = 8, in 0.275s\n",
      "[234/500] 1 tree, 38 leaves, max depth = 12, in 0.291s\n",
      "[235/500] 1 tree, 39 leaves, max depth = 15, in 0.273s\n",
      "[236/500] 1 tree, 40 leaves, max depth = 11, in 0.303s\n",
      "[237/500] 1 tree, 41 leaves, max depth = 14, in 0.283s\n",
      "[238/500] 1 tree, 39 leaves, max depth = 9, in 0.292s\n",
      "[239/500] 1 tree, 40 leaves, max depth = 10, in 0.281s\n",
      "[240/500] 1 tree, 40 leaves, max depth = 15, in 0.291s\n",
      "[241/500] 1 tree, 40 leaves, max depth = 11, in 0.272s\n",
      "[242/500] 1 tree, 41 leaves, max depth = 10, in 0.273s\n",
      "[243/500] 1 tree, 40 leaves, max depth = 9, in 0.300s\n",
      "[244/500] 1 tree, 37 leaves, max depth = 8, in 0.271s\n",
      "[245/500] 1 tree, 37 leaves, max depth = 11, in 0.286s\n",
      "[246/500] 1 tree, 40 leaves, max depth = 11, in 0.323s\n",
      "[247/500] 1 tree, 36 leaves, max depth = 11, in 0.289s\n",
      "[248/500] 1 tree, 41 leaves, max depth = 10, in 0.301s\n",
      "[249/500] 1 tree, 37 leaves, max depth = 12, in 0.279s\n",
      "[250/500] 1 tree, 40 leaves, max depth = 14, in 0.340s\n",
      "[251/500] 1 tree, 41 leaves, max depth = 14, in 0.307s\n",
      "[252/500] 1 tree, 38 leaves, max depth = 10, in 0.290s\n",
      "[253/500] 1 tree, 41 leaves, max depth = 10, in 0.323s\n",
      "[254/500] 1 tree, 38 leaves, max depth = 14, in 0.320s\n",
      "[255/500] 1 tree, 37 leaves, max depth = 9, in 0.325s\n",
      "[256/500] 1 tree, 39 leaves, max depth = 13, in 0.293s\n",
      "[257/500] 1 tree, 36 leaves, max depth = 11, in 0.270s\n",
      "[258/500] 1 tree, 38 leaves, max depth = 11, in 0.297s\n",
      "[259/500] 1 tree, 38 leaves, max depth = 8, in 0.323s\n",
      "[260/500] 1 tree, 38 leaves, max depth = 13, in 0.291s\n",
      "[261/500] 1 tree, 37 leaves, max depth = 9, in 0.270s\n",
      "[262/500] 1 tree, 41 leaves, max depth = 12, in 0.340s\n",
      "[263/500] 1 tree, 39 leaves, max depth = 10, in 0.287s\n",
      "[264/500] 1 tree, 38 leaves, max depth = 14, in 0.312s\n",
      "[265/500] 1 tree, 38 leaves, max depth = 10, in 0.291s\n",
      "[266/500] 1 tree, 38 leaves, max depth = 9, in 0.296s\n",
      "[267/500] 1 tree, 39 leaves, max depth = 10, in 0.297s\n",
      "[268/500] 1 tree, 37 leaves, max depth = 10, in 0.331s\n",
      "[269/500] 1 tree, 39 leaves, max depth = 10, in 0.310s\n",
      "[270/500] 1 tree, 36 leaves, max depth = 11, in 0.291s\n",
      "[271/500] 1 tree, 36 leaves, max depth = 9, in 0.294s\n",
      "[272/500] 1 tree, 39 leaves, max depth = 15, in 0.272s\n",
      "[273/500] 1 tree, 37 leaves, max depth = 11, in 0.294s\n",
      "[274/500] 1 tree, 37 leaves, max depth = 10, in 0.279s\n",
      "[275/500] 1 tree, 38 leaves, max depth = 10, in 0.283s\n",
      "[276/500] 1 tree, 37 leaves, max depth = 10, in 0.329s\n",
      "[277/500] 1 tree, 40 leaves, max depth = 10, in 0.305s\n",
      "[278/500] 1 tree, 38 leaves, max depth = 10, in 0.316s\n",
      "[279/500] 1 tree, 39 leaves, max depth = 12, in 0.291s\n",
      "[280/500] 1 tree, 38 leaves, max depth = 9, in 0.305s\n",
      "[281/500] 1 tree, 39 leaves, max depth = 11, in 0.306s\n",
      "[282/500] 1 tree, 35 leaves, max depth = 10, in 0.250s\n",
      "[283/500] 1 tree, 39 leaves, max depth = 12, in 0.329s\n",
      "[284/500] 1 tree, 35 leaves, max depth = 9, in 0.293s\n",
      "[285/500] 1 tree, 39 leaves, max depth = 12, in 0.332s\n",
      "[286/500] 1 tree, 39 leaves, max depth = 10, in 0.303s\n",
      "[287/500] 1 tree, 35 leaves, max depth = 8, in 0.279s\n",
      "[288/500] 1 tree, 37 leaves, max depth = 10, in 0.294s\n",
      "[289/500] 1 tree, 38 leaves, max depth = 10, in 0.281s\n",
      "[290/500] 1 tree, 37 leaves, max depth = 10, in 0.320s\n",
      "[291/500] 1 tree, 37 leaves, max depth = 8, in 0.289s\n",
      "[292/500] 1 tree, 38 leaves, max depth = 11, in 0.261s\n",
      "[293/500] 1 tree, 39 leaves, max depth = 9, in 0.322s\n",
      "[294/500] 1 tree, 34 leaves, max depth = 10, in 0.308s\n",
      "[295/500] 1 tree, 38 leaves, max depth = 8, in 0.285s\n",
      "[296/500] 1 tree, 36 leaves, max depth = 13, in 0.262s\n",
      "[297/500] 1 tree, 37 leaves, max depth = 13, in 0.333s\n",
      "[298/500] 1 tree, 39 leaves, max depth = 11, in 0.291s\n",
      "[299/500] 1 tree, 35 leaves, max depth = 11, in 0.296s\n",
      "[300/500] 1 tree, 36 leaves, max depth = 9, in 0.321s\n",
      "[301/500] 1 tree, 38 leaves, max depth = 13, in 0.281s\n",
      "[302/500] 1 tree, 39 leaves, max depth = 10, in 0.285s\n",
      "[303/500] 1 tree, 39 leaves, max depth = 10, in 0.303s\n",
      "[304/500] 1 tree, 36 leaves, max depth = 12, in 0.296s\n",
      "[305/500] 1 tree, 36 leaves, max depth = 13, in 0.302s\n",
      "[306/500] 1 tree, 38 leaves, max depth = 12, in 0.349s\n",
      "[307/500] 1 tree, 41 leaves, max depth = 10, in 0.323s\n",
      "[308/500] 1 tree, 36 leaves, max depth = 11, in 0.281s\n",
      "[309/500] 1 tree, 37 leaves, max depth = 9, in 0.318s\n",
      "[310/500] 1 tree, 37 leaves, max depth = 8, in 0.320s\n",
      "[311/500] 1 tree, 37 leaves, max depth = 11, in 0.281s\n",
      "[312/500] 1 tree, 35 leaves, max depth = 8, in 0.308s\n",
      "[313/500] 1 tree, 37 leaves, max depth = 10, in 0.323s\n",
      "[314/500] 1 tree, 39 leaves, max depth = 14, in 0.319s\n",
      "[315/500] 1 tree, 37 leaves, max depth = 9, in 0.295s\n",
      "[316/500] 1 tree, 37 leaves, max depth = 9, in 0.273s\n",
      "[317/500] 1 tree, 39 leaves, max depth = 10, in 0.311s\n",
      "[318/500] 1 tree, 37 leaves, max depth = 9, in 0.299s\n",
      "[319/500] 1 tree, 35 leaves, max depth = 12, in 0.310s\n",
      "[320/500] 1 tree, 36 leaves, max depth = 9, in 0.319s\n",
      "[321/500] 1 tree, 38 leaves, max depth = 9, in 0.274s\n",
      "[322/500] 1 tree, 36 leaves, max depth = 9, in 0.273s\n",
      "[323/500] 1 tree, 38 leaves, max depth = 9, in 0.282s\n",
      "[324/500] 1 tree, 35 leaves, max depth = 11, in 0.259s\n",
      "[325/500] 1 tree, 35 leaves, max depth = 8, in 0.256s\n",
      "[326/500] 1 tree, 36 leaves, max depth = 9, in 0.289s\n",
      "[327/500] 1 tree, 36 leaves, max depth = 10, in 0.288s\n",
      "[328/500] 1 tree, 33 leaves, max depth = 9, in 0.273s\n",
      "[329/500] 1 tree, 36 leaves, max depth = 8, in 0.310s\n",
      "[330/500] 1 tree, 34 leaves, max depth = 10, in 0.289s\n",
      "[331/500] 1 tree, 37 leaves, max depth = 11, in 0.299s\n",
      "[332/500] 1 tree, 34 leaves, max depth = 8, in 0.281s\n",
      "[333/500] 1 tree, 37 leaves, max depth = 10, in 0.324s\n",
      "[334/500] 1 tree, 33 leaves, max depth = 10, in 0.280s\n",
      "[335/500] 1 tree, 37 leaves, max depth = 11, in 0.279s\n",
      "[336/500] 1 tree, 37 leaves, max depth = 9, in 0.321s\n",
      "[337/500] 1 tree, 38 leaves, max depth = 10, in 0.324s\n",
      "[338/500] 1 tree, 38 leaves, max depth = 11, in 0.312s\n",
      "[339/500] 1 tree, 36 leaves, max depth = 11, in 0.331s\n",
      "[340/500] 1 tree, 36 leaves, max depth = 8, in 0.299s\n",
      "[341/500] 1 tree, 37 leaves, max depth = 10, in 0.341s\n",
      "[342/500] 1 tree, 36 leaves, max depth = 10, in 0.341s\n",
      "[343/500] 1 tree, 37 leaves, max depth = 10, in 0.294s\n",
      "[344/500] 1 tree, 34 leaves, max depth = 9, in 0.270s\n",
      "[345/500] 1 tree, 33 leaves, max depth = 8, in 0.275s\n",
      "[346/500] 1 tree, 37 leaves, max depth = 14, in 0.329s\n",
      "[347/500] 1 tree, 35 leaves, max depth = 9, in 0.281s\n",
      "[348/500] 1 tree, 35 leaves, max depth = 12, in 0.293s\n",
      "[349/500] 1 tree, 34 leaves, max depth = 8, in 0.270s\n",
      "[350/500] 1 tree, 38 leaves, max depth = 8, in 0.316s\n",
      "[351/500] 1 tree, 36 leaves, max depth = 9, in 0.269s\n",
      "[352/500] 1 tree, 37 leaves, max depth = 8, in 0.306s\n",
      "[353/500] 1 tree, 36 leaves, max depth = 10, in 0.312s\n",
      "[354/500] 1 tree, 36 leaves, max depth = 10, in 0.352s\n",
      "[355/500] 1 tree, 39 leaves, max depth = 9, in 0.321s\n",
      "[356/500] 1 tree, 38 leaves, max depth = 8, in 0.262s\n",
      "[357/500] 1 tree, 38 leaves, max depth = 11, in 0.320s\n",
      "[358/500] 1 tree, 34 leaves, max depth = 10, in 0.317s\n",
      "[359/500] 1 tree, 32 leaves, max depth = 9, in 0.278s\n",
      "[360/500] 1 tree, 37 leaves, max depth = 8, in 0.272s\n",
      "[361/500] 1 tree, 37 leaves, max depth = 10, in 0.351s\n",
      "[362/500] 1 tree, 32 leaves, max depth = 9, in 0.291s\n",
      "[363/500] 1 tree, 36 leaves, max depth = 8, in 0.293s\n",
      "[364/500] 1 tree, 38 leaves, max depth = 10, in 0.311s\n",
      "[365/500] 1 tree, 37 leaves, max depth = 9, in 0.291s\n",
      "[366/500] 1 tree, 33 leaves, max depth = 9, in 0.307s\n",
      "[367/500] 1 tree, 35 leaves, max depth = 9, in 0.308s\n",
      "[368/500] 1 tree, 37 leaves, max depth = 11, in 0.308s\n",
      "[369/500] 1 tree, 34 leaves, max depth = 9, in 0.267s\n",
      "[370/500] 1 tree, 33 leaves, max depth = 10, in 0.261s\n",
      "[371/500] 1 tree, 37 leaves, max depth = 9, in 0.314s\n",
      "[372/500] 1 tree, 36 leaves, max depth = 8, in 0.271s\n",
      "[373/500] 1 tree, 34 leaves, max depth = 12, in 0.284s\n",
      "[374/500] 1 tree, 35 leaves, max depth = 10, in 0.310s\n",
      "[375/500] 1 tree, 35 leaves, max depth = 8, in 0.311s\n",
      "[376/500] 1 tree, 34 leaves, max depth = 9, in 0.270s\n",
      "[377/500] 1 tree, 37 leaves, max depth = 9, in 0.292s\n",
      "[378/500] 1 tree, 37 leaves, max depth = 10, in 0.311s\n",
      "[379/500] 1 tree, 36 leaves, max depth = 12, in 0.289s\n",
      "[380/500] 1 tree, 37 leaves, max depth = 8, in 0.308s\n",
      "[381/500] 1 tree, 35 leaves, max depth = 10, in 0.299s\n",
      "[382/500] 1 tree, 36 leaves, max depth = 10, in 0.311s\n",
      "[383/500] 1 tree, 33 leaves, max depth = 8, in 0.307s\n",
      "[384/500] 1 tree, 33 leaves, max depth = 9, in 0.278s\n",
      "[385/500] 1 tree, 34 leaves, max depth = 8, in 0.299s\n",
      "[386/500] 1 tree, 36 leaves, max depth = 10, in 0.297s\n",
      "[387/500] 1 tree, 36 leaves, max depth = 8, in 0.310s\n",
      "[388/500] 1 tree, 35 leaves, max depth = 13, in 0.309s\n",
      "[389/500] 1 tree, 38 leaves, max depth = 12, in 0.313s\n",
      "[390/500] 1 tree, 38 leaves, max depth = 9, in 0.297s\n",
      "[391/500] 1 tree, 34 leaves, max depth = 9, in 0.310s\n",
      "[392/500] 1 tree, 35 leaves, max depth = 10, in 0.288s\n",
      "[393/500] 1 tree, 36 leaves, max depth = 9, in 0.293s\n",
      "[394/500] 1 tree, 33 leaves, max depth = 8, in 0.271s\n",
      "[395/500] 1 tree, 37 leaves, max depth = 9, in 0.334s\n",
      "[396/500] 1 tree, 35 leaves, max depth = 9, in 0.337s\n",
      "[397/500] 1 tree, 38 leaves, max depth = 10, in 0.346s\n",
      "[398/500] 1 tree, 32 leaves, max depth = 8, in 0.274s\n",
      "[399/500] 1 tree, 33 leaves, max depth = 8, in 0.295s\n",
      "[400/500] 1 tree, 37 leaves, max depth = 8, in 0.309s\n",
      "[401/500] 1 tree, 37 leaves, max depth = 10, in 0.347s\n",
      "[402/500] 1 tree, 36 leaves, max depth = 9, in 0.303s\n",
      "[403/500] 1 tree, 33 leaves, max depth = 11, in 0.311s\n",
      "[404/500] 1 tree, 34 leaves, max depth = 10, in 0.293s\n",
      "[405/500] 1 tree, 29 leaves, max depth = 10, in 0.242s\n",
      "[406/500] 1 tree, 35 leaves, max depth = 9, in 0.311s\n",
      "[407/500] 1 tree, 36 leaves, max depth = 11, in 0.290s\n",
      "[408/500] 1 tree, 34 leaves, max depth = 10, in 0.320s\n",
      "[409/500] 1 tree, 37 leaves, max depth = 8, in 0.320s\n",
      "[410/500] 1 tree, 34 leaves, max depth = 9, in 0.277s\n",
      "[411/500] 1 tree, 35 leaves, max depth = 15, in 0.315s\n",
      "[412/500] 1 tree, 36 leaves, max depth = 9, in 0.294s\n",
      "[413/500] 1 tree, 36 leaves, max depth = 9, in 0.304s\n",
      "[414/500] 1 tree, 36 leaves, max depth = 13, in 0.298s\n",
      "[415/500] 1 tree, 33 leaves, max depth = 10, in 0.302s\n",
      "[416/500] 1 tree, 37 leaves, max depth = 9, in 0.297s\n",
      "[417/500] 1 tree, 33 leaves, max depth = 9, in 0.312s\n",
      "[418/500] 1 tree, 35 leaves, max depth = 11, in 0.295s\n",
      "[419/500] 1 tree, 34 leaves, max depth = 13, in 0.299s\n",
      "[420/500] 1 tree, 36 leaves, max depth = 9, in 0.323s\n",
      "[421/500] 1 tree, 34 leaves, max depth = 10, in 0.301s\n",
      "[422/500] 1 tree, 38 leaves, max depth = 8, in 0.353s\n",
      "[423/500] 1 tree, 32 leaves, max depth = 12, in 0.261s\n",
      "[424/500] 1 tree, 35 leaves, max depth = 11, in 0.314s\n",
      "[425/500] 1 tree, 36 leaves, max depth = 10, in 0.320s\n",
      "[426/500] 1 tree, 34 leaves, max depth = 10, in 0.302s\n",
      "[427/500] 1 tree, 35 leaves, max depth = 9, in 0.327s\n",
      "[428/500] 1 tree, 36 leaves, max depth = 8, in 0.322s\n",
      "[429/500] 1 tree, 35 leaves, max depth = 8, in 0.321s\n",
      "[430/500] 1 tree, 36 leaves, max depth = 10, in 0.279s\n",
      "[431/500] 1 tree, 34 leaves, max depth = 15, in 0.302s\n",
      "[432/500] 1 tree, 35 leaves, max depth = 10, in 0.290s\n",
      "[433/500] 1 tree, 32 leaves, max depth = 8, in 0.271s\n",
      "[434/500] 1 tree, 34 leaves, max depth = 8, in 0.273s\n",
      "[435/500] 1 tree, 35 leaves, max depth = 9, in 0.326s\n",
      "[436/500] 1 tree, 32 leaves, max depth = 9, in 0.270s\n",
      "[437/500] 1 tree, 32 leaves, max depth = 10, in 0.277s\n",
      "[438/500] 1 tree, 34 leaves, max depth = 13, in 0.334s\n",
      "[439/500] 1 tree, 31 leaves, max depth = 9, in 0.249s\n",
      "[440/500] 1 tree, 33 leaves, max depth = 8, in 0.298s\n",
      "[441/500] 1 tree, 34 leaves, max depth = 9, in 0.296s\n",
      "[442/500] 1 tree, 32 leaves, max depth = 9, in 0.251s\n",
      "[443/500] 1 tree, 33 leaves, max depth = 8, in 0.311s\n",
      "[444/500] 1 tree, 36 leaves, max depth = 12, in 0.294s\n",
      "[445/500] 1 tree, 31 leaves, max depth = 8, in 0.288s\n",
      "[446/500] 1 tree, 32 leaves, max depth = 7, in 0.312s\n",
      "[447/500] 1 tree, 36 leaves, max depth = 9, in 0.280s\n",
      "[448/500] 1 tree, 33 leaves, max depth = 8, in 0.310s\n",
      "[449/500] 1 tree, 33 leaves, max depth = 12, in 0.314s\n",
      "[450/500] 1 tree, 36 leaves, max depth = 8, in 0.290s\n",
      "[451/500] 1 tree, 34 leaves, max depth = 10, in 0.322s\n",
      "[452/500] 1 tree, 34 leaves, max depth = 10, in 0.293s\n",
      "[453/500] 1 tree, 33 leaves, max depth = 10, in 0.296s\n",
      "[454/500] 1 tree, 33 leaves, max depth = 8, in 0.326s\n",
      "[455/500] 1 tree, 36 leaves, max depth = 10, in 0.292s\n",
      "[456/500] 1 tree, 32 leaves, max depth = 10, in 0.287s\n",
      "[457/500] 1 tree, 33 leaves, max depth = 8, in 0.279s\n",
      "[458/500] 1 tree, 34 leaves, max depth = 8, in 0.283s\n",
      "[459/500] 1 tree, 34 leaves, max depth = 12, in 0.285s\n",
      "[460/500] 1 tree, 32 leaves, max depth = 7, in 0.254s\n",
      "[461/500] 1 tree, 36 leaves, max depth = 8, in 0.314s\n",
      "[462/500] 1 tree, 33 leaves, max depth = 11, in 0.285s\n",
      "[463/500] 1 tree, 33 leaves, max depth = 8, in 0.297s\n",
      "[464/500] 1 tree, 33 leaves, max depth = 8, in 0.284s\n",
      "[465/500] 1 tree, 36 leaves, max depth = 8, in 0.289s\n",
      "[466/500] 1 tree, 34 leaves, max depth = 9, in 0.278s\n",
      "[467/500] 1 tree, 37 leaves, max depth = 10, in 0.328s\n",
      "[468/500] 1 tree, 35 leaves, max depth = 9, in 0.302s\n",
      "[469/500] 1 tree, 33 leaves, max depth = 11, in 0.271s\n",
      "[470/500] 1 tree, 32 leaves, max depth = 9, in 0.295s\n",
      "[471/500] 1 tree, 31 leaves, max depth = 8, in 0.276s\n",
      "[472/500] 1 tree, 32 leaves, max depth = 10, in 0.270s\n",
      "[473/500] 1 tree, 34 leaves, max depth = 8, in 0.282s\n",
      "[474/500] 1 tree, 33 leaves, max depth = 10, in 0.269s\n",
      "[475/500] 1 tree, 32 leaves, max depth = 9, in 0.292s\n",
      "[476/500] 1 tree, 34 leaves, max depth = 11, in 0.308s\n",
      "[477/500] 1 tree, 34 leaves, max depth = 9, in 0.290s\n",
      "[478/500] 1 tree, 31 leaves, max depth = 10, in 0.275s\n",
      "[479/500] 1 tree, 36 leaves, max depth = 9, in 0.292s\n",
      "[480/500] 1 tree, 33 leaves, max depth = 11, in 0.289s\n",
      "[481/500] 1 tree, 29 leaves, max depth = 8, in 0.251s\n",
      "[482/500] 1 tree, 34 leaves, max depth = 9, in 0.309s\n",
      "[483/500] 1 tree, 33 leaves, max depth = 9, in 0.303s\n",
      "[484/500] 1 tree, 31 leaves, max depth = 11, in 0.278s\n",
      "[485/500] 1 tree, 35 leaves, max depth = 12, in 0.332s\n",
      "[486/500] 1 tree, 32 leaves, max depth = 9, in 0.279s\n",
      "[487/500] 1 tree, 34 leaves, max depth = 9, in 0.270s\n",
      "[488/500] 1 tree, 33 leaves, max depth = 9, in 0.280s\n",
      "[489/500] 1 tree, 32 leaves, max depth = 10, in 0.273s\n",
      "[490/500] 1 tree, 32 leaves, max depth = 12, in 0.298s\n",
      "[491/500] 1 tree, 32 leaves, max depth = 9, in 0.298s\n",
      "[492/500] 1 tree, 33 leaves, max depth = 11, in 0.309s\n",
      "[493/500] 1 tree, 33 leaves, max depth = 8, in 0.273s\n",
      "[494/500] 1 tree, 34 leaves, max depth = 11, in 0.297s\n",
      "[495/500] 1 tree, 30 leaves, max depth = 9, in 0.291s\n",
      "[496/500] 1 tree, 32 leaves, max depth = 10, in 0.296s\n",
      "[497/500] 1 tree, 34 leaves, max depth = 8, in 0.277s\n",
      "[498/500] 1 tree, 33 leaves, max depth = 7, in 0.280s\n",
      "[499/500] 1 tree, 30 leaves, max depth = 11, in 0.272s\n",
      "[500/500] 1 tree, 31 leaves, max depth = 10, in 0.295s\n",
      "Fit 500 trees in 151.892 s, (18866 total leaves)\n",
      "Time spent computing histograms: 125.425s\n",
      "Time spent finding best splits:  7.813s\n",
      "Time spent applying splits:      1.312s\n",
      "Time spent predicting:           0.031s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;histgradientboostingclassifier&#x27;,\n",
       "                 HistGradientBoostingClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                l2_regularization=0.05,\n",
       "                                                max_iter=500,\n",
       "                                                max_leaf_nodes=250,\n",
       "                                                min_samples_leaf=100,\n",
       "                                                random_state=100,\n",
       "                                                scoring=&#x27;f1_macro&#x27;,\n",
       "                                                verbose=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;histgradientboostingclassifier&#x27;,\n",
       "                 HistGradientBoostingClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                l2_regularization=0.05,\n",
       "                                                max_iter=500,\n",
       "                                                max_leaf_nodes=250,\n",
       "                                                min_samples_leaf=100,\n",
       "                                                random_state=100,\n",
       "                                                scoring=&#x27;f1_macro&#x27;,\n",
       "                                                verbose=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(class_weight=&#x27;balanced&#x27;, l2_regularization=0.05,\n",
       "                               max_iter=500, max_leaf_nodes=250,\n",
       "                               min_samples_leaf=100, random_state=100,\n",
       "                               scoring=&#x27;f1_macro&#x27;, verbose=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('histgradientboostingclassifier',\n",
       "                 HistGradientBoostingClassifier(class_weight='balanced',\n",
       "                                                l2_regularization=0.05,\n",
       "                                                max_iter=500,\n",
       "                                                max_leaf_nodes=250,\n",
       "                                                min_samples_leaf=100,\n",
       "                                                random_state=100,\n",
       "                                                scoring='f1_macro',\n",
       "                                                verbose=1))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#parameters = {'scoring':['f1_macro'],'class_weight':['balanced'], 'max_iter':[250, 500, 750], 'min_samples_leaf':[20, 50, 100, 150], 'max_leaf_nodes':[31, 50, 100, 200], 'l2_regularization':[0.1, 0.01], 'random_state':[100], 'learning_rate':[0.1, 0.01, 0.001]}\n",
    "#hGB =  HistGradientBoostingClassifier()\n",
    "#clf = GridSearchCV(hGB, parameters, verbose=1)\n",
    "clf.fit(train, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_l2_regularization</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>param_scoring</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.957123</td>\n",
       "      <td>0.010389</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>{'class_weight': 'balanced', 'l2_regularizatio...</td>\n",
       "      <td>0.893491</td>\n",
       "      <td>0.890533</td>\n",
       "      <td>0.896450</td>\n",
       "      <td>0.893175</td>\n",
       "      <td>0.893175</td>\n",
       "      <td>0.893365</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.751053</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>{'class_weight': 'balanced', 'l2_regularizatio...</td>\n",
       "      <td>0.905325</td>\n",
       "      <td>0.878698</td>\n",
       "      <td>0.872781</td>\n",
       "      <td>0.878338</td>\n",
       "      <td>0.878338</td>\n",
       "      <td>0.882696</td>\n",
       "      <td>0.011527</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998498</td>\n",
       "      <td>0.008124</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>{'class_weight': 'balanced', 'l2_regularizatio...</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.878698</td>\n",
       "      <td>0.869822</td>\n",
       "      <td>0.860534</td>\n",
       "      <td>0.857567</td>\n",
       "      <td>0.870247</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.554790</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>{'class_weight': 'balanced', 'l2_regularizatio...</td>\n",
       "      <td>0.881657</td>\n",
       "      <td>0.857988</td>\n",
       "      <td>0.837278</td>\n",
       "      <td>0.804154</td>\n",
       "      <td>0.824926</td>\n",
       "      <td>0.841201</td>\n",
       "      <td>0.026725</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.387840</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>{'class_weight': 'balanced', 'l2_regularizatio...</td>\n",
       "      <td>0.816568</td>\n",
       "      <td>0.834320</td>\n",
       "      <td>0.792899</td>\n",
       "      <td>0.780415</td>\n",
       "      <td>0.771513</td>\n",
       "      <td>0.799143</td>\n",
       "      <td>0.023213</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>9.159856</td>\n",
       "      <td>0.225768</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.001</td>\n",
       "      <td>750</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>{'class_weight': 'balanced', 'l2_regularizatio...</td>\n",
       "      <td>0.899408</td>\n",
       "      <td>0.890533</td>\n",
       "      <td>0.887574</td>\n",
       "      <td>0.905045</td>\n",
       "      <td>0.899110</td>\n",
       "      <td>0.896334</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>8.640234</td>\n",
       "      <td>0.177233</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.001</td>\n",
       "      <td>750</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>{'class_weight': 'balanced', 'l2_regularizatio...</td>\n",
       "      <td>0.896450</td>\n",
       "      <td>0.890533</td>\n",
       "      <td>0.890533</td>\n",
       "      <td>0.910979</td>\n",
       "      <td>0.893175</td>\n",
       "      <td>0.896334</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>7.549422</td>\n",
       "      <td>0.107907</td>\n",
       "      <td>0.016539</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.001</td>\n",
       "      <td>750</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>{'class_weight': 'balanced', 'l2_regularizatio...</td>\n",
       "      <td>0.905325</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.878698</td>\n",
       "      <td>0.899110</td>\n",
       "      <td>0.887240</td>\n",
       "      <td>0.890998</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>5.016244</td>\n",
       "      <td>0.122234</td>\n",
       "      <td>0.018847</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.001</td>\n",
       "      <td>750</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>{'class_weight': 'balanced', 'l2_regularizatio...</td>\n",
       "      <td>0.905325</td>\n",
       "      <td>0.890533</td>\n",
       "      <td>0.893491</td>\n",
       "      <td>0.872404</td>\n",
       "      <td>0.872404</td>\n",
       "      <td>0.886831</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>3.407923</td>\n",
       "      <td>0.086789</td>\n",
       "      <td>0.017412</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.001</td>\n",
       "      <td>750</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>{'class_weight': 'balanced', 'l2_regularizatio...</td>\n",
       "      <td>0.902367</td>\n",
       "      <td>0.875740</td>\n",
       "      <td>0.872781</td>\n",
       "      <td>0.878338</td>\n",
       "      <td>0.869436</td>\n",
       "      <td>0.879732</td>\n",
       "      <td>0.011701</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         1.957123      0.010389         0.004400        0.000491   \n",
       "1         1.751053      0.010186         0.004611        0.000499   \n",
       "2         0.998498      0.008124         0.004200        0.000749   \n",
       "3         0.554790      0.006007         0.003796        0.000752   \n",
       "4         0.387840      0.009159         0.004202        0.000398   \n",
       "..             ...           ...              ...             ...   \n",
       "295       9.159856      0.225768         0.019000        0.002281   \n",
       "296       8.640234      0.177233         0.018328        0.002044   \n",
       "297       7.549422      0.107907         0.016539        0.001766   \n",
       "298       5.016244      0.122234         0.018847        0.005627   \n",
       "299       3.407923      0.086789         0.017412        0.001338   \n",
       "\n",
       "    param_class_weight param_l2_regularization param_max_iter  \\\n",
       "0             balanced                     0.1            100   \n",
       "1             balanced                     0.1            100   \n",
       "2             balanced                     0.1            100   \n",
       "3             balanced                     0.1            100   \n",
       "4             balanced                     0.1            100   \n",
       "..                 ...                     ...            ...   \n",
       "295           balanced                   0.001            750   \n",
       "296           balanced                   0.001            750   \n",
       "297           balanced                   0.001            750   \n",
       "298           balanced                   0.001            750   \n",
       "299           balanced                   0.001            750   \n",
       "\n",
       "    param_max_leaf_nodes param_min_samples_leaf param_random_state  \\\n",
       "0                     31                     10                100   \n",
       "1                     31                     20                100   \n",
       "2                     31                     50                100   \n",
       "3                     31                    100                100   \n",
       "4                     31                    150                100   \n",
       "..                   ...                    ...                ...   \n",
       "295                  200                     10                100   \n",
       "296                  200                     20                100   \n",
       "297                  200                     50                100   \n",
       "298                  200                    100                100   \n",
       "299                  200                    150                100   \n",
       "\n",
       "    param_scoring                                             params  \\\n",
       "0        f1_macro  {'class_weight': 'balanced', 'l2_regularizatio...   \n",
       "1        f1_macro  {'class_weight': 'balanced', 'l2_regularizatio...   \n",
       "2        f1_macro  {'class_weight': 'balanced', 'l2_regularizatio...   \n",
       "3        f1_macro  {'class_weight': 'balanced', 'l2_regularizatio...   \n",
       "4        f1_macro  {'class_weight': 'balanced', 'l2_regularizatio...   \n",
       "..            ...                                                ...   \n",
       "295      f1_macro  {'class_weight': 'balanced', 'l2_regularizatio...   \n",
       "296      f1_macro  {'class_weight': 'balanced', 'l2_regularizatio...   \n",
       "297      f1_macro  {'class_weight': 'balanced', 'l2_regularizatio...   \n",
       "298      f1_macro  {'class_weight': 'balanced', 'l2_regularizatio...   \n",
       "299      f1_macro  {'class_weight': 'balanced', 'l2_regularizatio...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0             0.893491           0.890533           0.896450   \n",
       "1             0.905325           0.878698           0.872781   \n",
       "2             0.884615           0.878698           0.869822   \n",
       "3             0.881657           0.857988           0.837278   \n",
       "4             0.816568           0.834320           0.792899   \n",
       "..                 ...                ...                ...   \n",
       "295           0.899408           0.890533           0.887574   \n",
       "296           0.896450           0.890533           0.890533   \n",
       "297           0.905325           0.884615           0.878698   \n",
       "298           0.905325           0.890533           0.893491   \n",
       "299           0.902367           0.875740           0.872781   \n",
       "\n",
       "     split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.893175           0.893175         0.893365        0.001878   \n",
       "1             0.878338           0.878338         0.882696        0.011527   \n",
       "2             0.860534           0.857567         0.870247        0.010326   \n",
       "3             0.804154           0.824926         0.841201        0.026725   \n",
       "4             0.780415           0.771513         0.799143        0.023213   \n",
       "..                 ...                ...              ...             ...   \n",
       "295           0.905045           0.899110         0.896334        0.006378   \n",
       "296           0.910979           0.893175         0.896334        0.007639   \n",
       "297           0.899110           0.887240         0.890998        0.009770   \n",
       "298           0.872404           0.872404         0.886831        0.012778   \n",
       "299           0.878338           0.869436         0.879732        0.011701   \n",
       "\n",
       "     rank_test_score  \n",
       "0                 39  \n",
       "1                185  \n",
       "2                231  \n",
       "3                271  \n",
       "4                296  \n",
       "..               ...  \n",
       "295                9  \n",
       "296                3  \n",
       "297               73  \n",
       "298              142  \n",
       "299              201  \n",
       "\n",
       "[300 rows x 20 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = pd.DataFrame(clf.cv_results_)\n",
    "grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'l2_regularization': 0.001,\n",
       " 'max_iter': 500,\n",
       " 'max_leaf_nodes': 31,\n",
       " 'min_samples_leaf': 20,\n",
       " 'random_state': 100,\n",
       " 'scoring': 'f1_macro'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_['params'][clf.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      1367\n",
      "           1       0.46      0.10      0.16       133\n",
      "\n",
      "    accuracy                           0.91      1500\n",
      "   macro avg       0.69      0.54      0.56      1500\n",
      "weighted avg       0.88      0.91      0.88      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#h = clf.best_estimator_\n",
    "print(\"Score:\", clf.score(test, test_Y))\n",
    "pr = clf.predict(test)\n",
    "print(report(y_true=test_Y, y_pred=pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9111610908068597\n",
      "Prediction Preview:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      3244\n",
      "           1       0.49      0.16      0.24       313\n",
      "\n",
      "    accuracy                           0.91      3557\n",
      "   macro avg       0.70      0.57      0.60      3557\n",
      "weighted avg       0.89      0.91      0.89      3557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr = clf.predict(pdatalist)\n",
    "print(\"Score:\",clf.score(pdatalist, list(ground_truth[\"sepsis_label\"][7000:])))\n",
    "print(\"Prediction Preview:\\n\",pr[:100])\n",
    "print(report(y_true=list(ground_truth[\"sepsis_label\"][7000:]), y_pred=pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91722849, 0.08277151]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(np.array(test[5]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ground_truth[\"sepsis_label\"][8557:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riezler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adcf29403019cc8afef7c3f69778d761e88d1965778ac01ff67c0278c52e66ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
